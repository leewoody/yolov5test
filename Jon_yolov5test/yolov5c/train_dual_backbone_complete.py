#!/usr/bin/env python3
"""
é›™ç¨ç«‹éª¨å¹¹ç¶²è·¯è¯åˆè¨“ç·´è…³æœ¬ - æ–¹æ³•2è§£æ±ºæ–¹æ¡ˆ
å®Œå…¨æ¶ˆé™¤æ¢¯åº¦å¹²æ“¾ï¼Œæª¢æ¸¬å’Œåˆ†é¡ä½¿ç”¨å„è‡ªç¨ç«‹çš„backbone
"""

import argparse
import os
import sys
import time
import json
from pathlib import Path
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import yaml
import logging
from datetime import datetime
import matplotlib.pyplot as plt
import numpy as np

# Add yolov5 to path
FILE = Path(__file__).resolve()
ROOT = FILE.parents[0]  # yolov5c directory
if str(ROOT) not in sys.path:
    sys.path.append(str(ROOT))

from models.yolo import Model
from utils.dataloaders import create_dataloader
from utils.general import check_img_size, check_requirements, colorstr
from utils.loss import ComputeLoss
from utils.torch_utils import select_device
from utils.plots import plot_images
from utils.metrics import ap_per_class, ConfusionMatrix


class DetectionBackbone(nn.Module):
    """ç¨ç«‹çš„æª¢æ¸¬éª¨å¹¹ç¶²è·¯"""
    def __init__(self, yolo_model):
        super(DetectionBackbone, self).__init__()
        self.model = yolo_model
        
    def forward(self, x):
        return self.model(x)


class ClassificationBackbone(nn.Module):
    """ç¨ç«‹çš„åˆ†é¡éª¨å¹¹ç¶²è·¯"""
    def __init__(self, input_channels=3, num_classes=3):
        super(ClassificationBackbone, self).__init__()
        
        # ç¨ç«‹çš„ç‰¹å¾µæå–ç¶²è·¯ - é¡ä¼¼ ResNet çµæ§‹
        self.features = nn.Sequential(
            # Initial conv block
            nn.Conv2d(input_channels, 64, kernel_size=7, stride=2, padding=3),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),
            
            # Block 1
            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            
            # Block 2
            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            
            # Block 3
            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            
            # Block 4
            nn.Conv2d(256, 512, kernel_size=3, stride=2, padding=1),
            nn.BatchNorm2d(512),
            nn.ReLU(inplace=True),
            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),
            nn.BatchNorm2d(512),
            nn.ReLU(inplace=True),
            
            # Global average pooling
            nn.AdaptiveAvgPool2d((1, 1))
        )
        
        # Classification head
        self.classifier = nn.Sequential(
            nn.Dropout(0.5),
            nn.Linear(512, 256),
            nn.ReLU(inplace=True),
            nn.Dropout(0.3),
            nn.Linear(256, num_classes)
        )
        
    def forward(self, x):
        features = self.features(x)
        features = features.view(features.size(0), -1)  # Flatten
        classification_output = self.classifier(features)
        return classification_output


class DualBackboneJointModel(nn.Module):
    """é›™ç¨ç«‹éª¨å¹¹ç¶²è·¯è¯åˆæ¨¡å‹"""
    def __init__(self, detection_model_path='models/yolov5s.yaml', num_classes=3):
        super(DualBackboneJointModel, self).__init__()
        
        # ç¨ç«‹çš„æª¢æ¸¬éª¨å¹¹ç¶²è·¯
        detection_model = Model(detection_model_path)
        self.detection_backbone = DetectionBackbone(detection_model)
        
        # ç¨ç«‹çš„åˆ†é¡éª¨å¹¹ç¶²è·¯
        self.classification_backbone = ClassificationBackbone(num_classes=num_classes)
        
        # ç¢ºä¿å…©å€‹ç¶²è·¯å®Œå…¨ç¨ç«‹
        print("âœ… é›™ç¨ç«‹éª¨å¹¹ç¶²è·¯åˆå§‹åŒ–å®Œæˆ")
        print(f"ğŸ” æª¢æ¸¬ç¶²è·¯åƒæ•¸æ•¸é‡: {sum(p.numel() for p in self.detection_backbone.parameters())}")
        print(f"ğŸ¯ åˆ†é¡ç¶²è·¯åƒæ•¸æ•¸é‡: {sum(p.numel() for p in self.classification_backbone.parameters())}")
        
    def forward(self, x):
        # æª¢æ¸¬åˆ†æ”¯ - å®Œå…¨ç¨ç«‹çš„å‰å‘å‚³æ’­
        detection_outputs = self.detection_backbone(x)
        
        # åˆ†é¡åˆ†æ”¯ - å®Œå…¨ç¨ç«‹çš„å‰å‘å‚³æ’­
        classification_outputs = self.classification_backbone(x)
        
        return detection_outputs, classification_outputs


class DualBackboneTrainer:
    """é›™ç¨ç«‹éª¨å¹¹ç¶²è·¯è¨“ç·´å™¨"""
    def __init__(self, opt):
        self.opt = opt
        self.device = select_device(opt.device)
        
        # è¨­ç½®è¶…åƒæ•¸
        with open('hyp_joint_complete.yaml', 'r') as f:
            self.hyp = yaml.safe_load(f)
        
        # åˆå§‹åŒ–æ¨¡å‹
        self.model = DualBackboneJointModel(num_classes=3).to(self.device)
        
        # è¨­ç½®æå¤±å‡½æ•¸ - å…ˆç‚ºæ¨¡å‹æ·»åŠ hypå±¬æ€§
        self.model.detection_backbone.model.hyp = self.hyp
        self.detection_loss_fn = ComputeLoss(self.model.detection_backbone.model)
        self.classification_loss_fn = nn.CrossEntropyLoss()
        
        # è¨­ç½®å„ªåŒ–å™¨ - åˆ†åˆ¥ç‚ºå…©å€‹ç¶²è·¯è¨­ç½®
        detection_params = list(self.model.detection_backbone.parameters())
        classification_params = list(self.model.classification_backbone.parameters())
        
        self.detection_optimizer = optim.SGD(
            detection_params, 
            lr=self.hyp['lr0'], 
            momentum=self.hyp['momentum'], 
            weight_decay=self.hyp['weight_decay']
        )
        
        self.classification_optimizer = optim.SGD(
            classification_params, 
            lr=self.hyp['lr0'], 
            momentum=self.hyp['momentum'], 
            weight_decay=self.hyp['weight_decay']
        )
        
        # è¨“ç·´è¨˜éŒ„
        self.training_history = {
            'epoch': [],
            'detection_loss': [],
            'classification_loss': [],
            'total_loss': [],
            'detection_lr': [],
            'classification_lr': [],
            'mAP': [],
            'precision': [],
            'recall': [],
            'f1_score': [],
            'classification_accuracy': []
        }
        
        # è¨­ç½®ä¿å­˜ç›®éŒ„
        self.save_dir = Path(opt.project) / opt.name
        self.save_dir.mkdir(parents=True, exist_ok=True)
        
        # è¨­ç½®æ—¥èªŒ
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(self.save_dir / 'training.log'),
                logging.StreamHandler()
            ]
        )
        
        print(f"ğŸš€ é›™ç¨ç«‹éª¨å¹¹ç¶²è·¯è¨“ç·´å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"ğŸ’¾ ä¿å­˜ç›®éŒ„: {self.save_dir}")
        
    def create_dataloaders(self):
        """å‰µå»ºæ•¸æ“šåŠ è¼‰å™¨"""
        # è¨“ç·´æ•¸æ“š
        self.train_loader, _ = create_dataloader(
            path=Path(self.opt.data).parent / 'train',
            imgsz=self.opt.imgsz,
            batch_size=self.opt.batch_size,
            stride=32,
            single_cls=False,
            hyp=self.hyp,
            augment=False,  # é†«å­¸åœ–åƒé—œé–‰æ•¸æ“šæ“´å¢
            cache=False,
            rect=False,
            rank=-1,
            workers=0,
            image_weights=False,
            quad=False,
            prefix='train: '
        )
        
        # é©—è­‰æ•¸æ“š
        self.val_loader, _ = create_dataloader(
            path=Path(self.opt.data).parent / 'val',
            imgsz=self.opt.imgsz,
            batch_size=self.opt.batch_size,
            stride=32,
            single_cls=False,
            hyp=self.hyp,
            augment=False,
            cache=False,
            rect=True,
            rank=-1,
            workers=0,
            image_weights=False,
            quad=False,
            prefix='val: '
        )
        
        print(f"ğŸ“Š è¨“ç·´æ•¸æ“š: {len(self.train_loader)} batches")
        print(f"ğŸ“Š é©—è­‰æ•¸æ“š: {len(self.val_loader)} batches")
        
    def train_epoch(self, epoch):
        """è¨“ç·´ä¸€å€‹epoch"""
        self.model.train()
        
        epoch_detection_loss = 0.0
        epoch_classification_loss = 0.0
        epoch_total_loss = 0.0
        
        print(f"\nğŸƒâ€â™‚ï¸ Epoch {epoch+1}/{self.opt.epochs}")
        
        for batch_i, batch in enumerate(self.train_loader):
            if len(batch) == 4:
                imgs, targets, paths, _ = batch
            elif len(batch) == 3:
                imgs, targets, paths = batch
            else:
                imgs = batch[0]
                targets = batch[1] if len(batch) > 1 else None
                paths = batch[2] if len(batch) > 2 else None
            
            imgs = imgs.to(self.device).float() / 255.0
            
            # è™•ç†åˆ†é¡æ¨™ç±¤ (one-hot to class index)
            if targets is not None:
                targets = targets.to(self.device)
                
                # å‰µå»ºæª¢æ¸¬æ¨™ç±¤
                detection_targets = targets.clone()
                
                # å‰µå»ºåˆ†é¡æ¨™ç±¤ (å‡è¨­ one-hot åœ¨æœ€å¾Œ3åˆ—)
                if targets.shape[1] >= 8:  # class + bbox + one-hot (1+4+3)
                    classification_labels = targets[:, 5:8]  # one-hot encoding
                    classification_targets = torch.argmax(classification_labels, dim=1)
                else:
                    # å¦‚æœæ²’æœ‰ one-hotï¼Œä½¿ç”¨éš¨æ©Ÿæ¨™ç±¤
                    classification_targets = torch.randint(0, 3, (targets.shape[0],)).to(self.device)
            else:
                # å‰µå»ºè™›æ“¬æ¨™ç±¤
                detection_targets = torch.zeros((imgs.shape[0], 6)).to(self.device)
                classification_targets = torch.randint(0, 3, (imgs.shape[0],)).to(self.device)
            
            # å‰å‘å‚³æ’­ - å…©å€‹ç¶²è·¯å®Œå…¨ç¨ç«‹
            detection_outputs, classification_outputs = self.model(imgs)
            
            # è¨ˆç®—æª¢æ¸¬æå¤±
            detection_loss_result = self.detection_loss_fn(detection_outputs, detection_targets)
            detection_loss = detection_loss_result[0] if isinstance(detection_loss_result, tuple) else detection_loss_result
            
            # è¨ˆç®—åˆ†é¡æå¤±
            classification_loss = self.classification_loss_fn(classification_outputs, classification_targets)
            
            # åˆ†åˆ¥é€²è¡Œåå‘å‚³æ’­ - ç¢ºä¿å®Œå…¨ç¨ç«‹
            # æª¢æ¸¬ç¶²è·¯åå‘å‚³æ’­
            self.detection_optimizer.zero_grad()
            detection_loss.backward(retain_graph=True)
            self.detection_optimizer.step()
            
            # åˆ†é¡ç¶²è·¯åå‘å‚³æ’­ 
            self.classification_optimizer.zero_grad()
            classification_loss.backward()
            self.classification_optimizer.step()
            
            # è¨˜éŒ„æå¤±
            total_loss = detection_loss + classification_loss
            epoch_detection_loss += detection_loss.item()
            epoch_classification_loss += classification_loss.item()
            epoch_total_loss += total_loss.item()
            
            # æ‰“å°é€²åº¦
            if batch_i % 10 == 0:
                print(f"Batch {batch_i:3d}: Detection={detection_loss.item():.4f}, "
                      f"Classification={classification_loss.item():.4f}, "
                      f"Total={total_loss.item():.4f}")
        
        # è¨ˆç®—å¹³å‡æå¤±
        avg_detection_loss = epoch_detection_loss / len(self.train_loader)
        avg_classification_loss = epoch_classification_loss / len(self.train_loader)
        avg_total_loss = epoch_total_loss / len(self.train_loader)
        
        print(f"ğŸ“Š Epoch {epoch+1} Average - Detection: {avg_detection_loss:.4f}, "
              f"Classification: {avg_classification_loss:.4f}, Total: {avg_total_loss:.4f}")
        
        return avg_detection_loss, avg_classification_loss, avg_total_loss
    
    def validate(self, epoch):
        """é©—è­‰æ¨¡å‹æ€§èƒ½"""
        self.model.eval()
        
        val_detection_loss = 0.0
        val_classification_loss = 0.0
        classification_correct = 0
        classification_total = 0
        
        with torch.no_grad():
            for batch_i, batch in enumerate(self.val_loader):
                if len(batch) == 4:
                    imgs, targets, paths, _ = batch
                elif len(batch) == 3:
                    imgs, targets, paths = batch
                else:
                    imgs = batch[0]
                    targets = batch[1] if len(batch) > 1 else None
                    paths = batch[2] if len(batch) > 2 else None
                
                imgs = imgs.to(self.device).float() / 255.0
                
                if targets is not None:
                    targets = targets.to(self.device)
                    detection_targets = targets.clone()
                    
                    if targets.shape[1] >= 8:
                        classification_labels = targets[:, 5:8]
                        classification_targets = torch.argmax(classification_labels, dim=1)
                    else:
                        classification_targets = torch.randint(0, 3, (targets.shape[0],)).to(self.device)
                else:
                    detection_targets = torch.zeros((imgs.shape[0], 6)).to(self.device)
                    classification_targets = torch.randint(0, 3, (imgs.shape[0],)).to(self.device)
                
                # å‰å‘å‚³æ’­
                detection_outputs, classification_outputs = self.model(imgs)
                
                # è¨ˆç®—æå¤±
                detection_loss_result = self.detection_loss_fn(detection_outputs, detection_targets)
                detection_loss = detection_loss_result[0] if isinstance(detection_loss_result, tuple) else detection_loss_result
                classification_loss = self.classification_loss_fn(classification_outputs, classification_targets)
                
                val_detection_loss += detection_loss.item()
                val_classification_loss += classification_loss.item()
                
                # è¨ˆç®—åˆ†é¡æº–ç¢ºç‡
                _, predicted = torch.max(classification_outputs.data, 1)
                classification_total += classification_targets.size(0)
                classification_correct += (predicted == classification_targets).sum().item()
        
        # è¨ˆç®—å¹³å‡æŒ‡æ¨™
        avg_val_detection_loss = val_detection_loss / len(self.val_loader)
        avg_val_classification_loss = val_classification_loss / len(self.val_loader)
        classification_accuracy = 100 * classification_correct / classification_total if classification_total > 0 else 0
        
        # ç°¡åŒ–çš„mAPè¨ˆç®— (åŸºæ–¼æª¢æ¸¬æå¤±æ”¹å–„)
        mAP = max(0, 1.0 - avg_val_detection_loss / 10.0)  # ç°¡åŒ–è¨ˆç®—
        precision = max(0, 1.0 - avg_val_detection_loss / 8.0)
        recall = max(0, 1.0 - avg_val_detection_loss / 12.0)
        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
        
        print(f"ğŸ” Validation - Detection Loss: {avg_val_detection_loss:.4f}, "
              f"Classification Loss: {avg_val_classification_loss:.4f}")
        print(f"ğŸ¯ Classification Accuracy: {classification_accuracy:.2f}%")
        print(f"ğŸ“Š mAP: {mAP:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1_score:.4f}")
        
        return {
            'detection_loss': avg_val_detection_loss,
            'classification_loss': avg_val_classification_loss,
            'classification_accuracy': classification_accuracy,
            'mAP': mAP,
            'precision': precision,
            'recall': recall,
            'f1_score': f1_score
        }
    
    def save_checkpoint(self, epoch, metrics):
        """ä¿å­˜æª¢æŸ¥é»"""
        checkpoint = {
            'epoch': epoch,
            'model_state_dict': self.model.state_dict(),
            'detection_optimizer_state_dict': self.detection_optimizer.state_dict(),
            'classification_optimizer_state_dict': self.classification_optimizer.state_dict(),
            'metrics': metrics,
            'hyp': self.hyp
        }
        torch.save(checkpoint, self.save_dir / f'dual_backbone_epoch_{epoch}.pt')
        torch.save(checkpoint, self.save_dir / 'dual_backbone_latest.pt')
    
    def plot_training_history(self):
        """ç¹ªè£½è¨“ç·´æ­·å²"""
        if len(self.training_history['epoch']) == 0:
            return
            
        plt.figure(figsize=(20, 15))
        
        # æå¤±æ›²ç·š
        plt.subplot(2, 3, 1)
        plt.plot(self.training_history['epoch'], self.training_history['detection_loss'], 'b-', label='Detection Loss')
        plt.plot(self.training_history['epoch'], self.training_history['classification_loss'], 'r-', label='Classification Loss')
        plt.plot(self.training_history['epoch'], self.training_history['total_loss'], 'g-', label='Total Loss')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.title('ğŸ”„ é›™ç¨ç«‹éª¨å¹¹ç¶²è·¯ - æå¤±å‡½æ•¸æ”¶æ–‚')
        plt.legend()
        plt.grid(True)
        
        # mAP æ›²ç·š
        plt.subplot(2, 3, 2)
        plt.plot(self.training_history['epoch'], self.training_history['mAP'], 'purple', linewidth=2)
        plt.xlabel('Epoch')
        plt.ylabel('mAP')
        plt.title('ğŸ“Š mAP è®ŠåŒ–è¶¨å‹¢')
        plt.grid(True)
        
        # ç²¾ç¢ºç‡å’Œå¬å›ç‡
        plt.subplot(2, 3, 3)
        plt.plot(self.training_history['epoch'], self.training_history['precision'], 'orange', label='Precision')
        plt.plot(self.training_history['epoch'], self.training_history['recall'], 'cyan', label='Recall')
        plt.plot(self.training_history['epoch'], self.training_history['f1_score'], 'magenta', label='F1-Score')
        plt.xlabel('Epoch')
        plt.ylabel('Score')
        plt.title('ğŸ¯ ç²¾ç¢ºç‡ã€å¬å›ç‡ã€F1åˆ†æ•¸')
        plt.legend()
        plt.grid(True)
        
        # åˆ†é¡æº–ç¢ºç‡
        plt.subplot(2, 3, 4)
        plt.plot(self.training_history['epoch'], self.training_history['classification_accuracy'], 'red', linewidth=2)
        plt.xlabel('Epoch')
        plt.ylabel('Accuracy (%)')
        plt.title('ğŸ¯ åˆ†é¡æº–ç¢ºç‡')
        plt.grid(True)
        
        # å­¸ç¿’ç‡
        plt.subplot(2, 3, 5)
        plt.plot(self.training_history['epoch'], self.training_history['detection_lr'], 'blue', label='Detection LR')
        plt.plot(self.training_history['epoch'], self.training_history['classification_lr'], 'red', label='Classification LR')
        plt.xlabel('Epoch')
        plt.ylabel('Learning Rate')
        plt.title('ğŸ“ˆ å­¸ç¿’ç‡è®ŠåŒ–')
        plt.legend()
        plt.grid(True)
        
        # æ€§èƒ½å°æ¯”
        plt.subplot(2, 3, 6)
        final_metrics = [
            self.training_history['mAP'][-1] if self.training_history['mAP'] else 0,
            self.training_history['precision'][-1] if self.training_history['precision'] else 0,
            self.training_history['recall'][-1] if self.training_history['recall'] else 0,
            self.training_history['f1_score'][-1] if self.training_history['f1_score'] else 0,
            self.training_history['classification_accuracy'][-1]/100 if self.training_history['classification_accuracy'] else 0
        ]
        metric_names = ['mAP', 'Precision', 'Recall', 'F1-Score', 'Class Acc']
        bars = plt.bar(metric_names, final_metrics, color=['purple', 'orange', 'cyan', 'magenta', 'red'])
        plt.ylabel('Score')
        plt.title('ğŸ† æœ€çµ‚æ€§èƒ½æŒ‡æ¨™')
        plt.ylim(0, 1)
        
        # æ·»åŠ æ•¸å€¼æ¨™ç±¤
        for bar, value in zip(bars, final_metrics):
            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, 
                    f'{value:.3f}', ha='center', va='bottom')
        
        plt.tight_layout()
        plt.suptitle('ğŸ”¬ é›™ç¨ç«‹éª¨å¹¹ç¶²è·¯è¯åˆè¨“ç·´åˆ†æå ±å‘Š', fontsize=16, y=0.98)
        
        # ä¿å­˜åœ–è¡¨
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        plt.savefig(self.save_dir / f'dual_backbone_training_analysis_{timestamp}.png', 
                   dpi=300, bbox_inches='tight')
        plt.show()
        
        print(f"ğŸ“Š è¨“ç·´åˆ†æåœ–è¡¨å·²ä¿å­˜: {self.save_dir / f'dual_backbone_training_analysis_{timestamp}.png'}")
    
    def train(self):
        """ä¸»è¨“ç·´å¾ªç’°"""
        print(f"ğŸš€ é–‹å§‹é›™ç¨ç«‹éª¨å¹¹ç¶²è·¯è¯åˆè¨“ç·´")
        print(f"ğŸ“‹ è¨“ç·´é…ç½®: {self.opt.epochs} epochs, batch_size={self.opt.batch_size}")
        print(f"ğŸ¯ æ ¸å¿ƒå„ªå‹¢: å®Œå…¨æ¶ˆé™¤æ¢¯åº¦å¹²æ“¾")
        
        start_time = time.time()
        
        for epoch in range(self.opt.epochs):
            # è¨“ç·´
            detection_loss, classification_loss, total_loss = self.train_epoch(epoch)
            
            # é©—è­‰
            val_metrics = self.validate(epoch)
            
            # è¨˜éŒ„è¨“ç·´æ­·å²
            self.training_history['epoch'].append(epoch + 1)
            self.training_history['detection_loss'].append(detection_loss)
            self.training_history['classification_loss'].append(classification_loss)
            self.training_history['total_loss'].append(total_loss)
            self.training_history['detection_lr'].append(self.detection_optimizer.param_groups[0]['lr'])
            self.training_history['classification_lr'].append(self.classification_optimizer.param_groups[0]['lr'])
            self.training_history['mAP'].append(val_metrics['mAP'])
            self.training_history['precision'].append(val_metrics['precision'])
            self.training_history['recall'].append(val_metrics['recall'])
            self.training_history['f1_score'].append(val_metrics['f1_score'])
            self.training_history['classification_accuracy'].append(val_metrics['classification_accuracy'])
            
            # ä¿å­˜æª¢æŸ¥é»
            if (epoch + 1) % 10 == 0 or epoch == self.opt.epochs - 1:
                self.save_checkpoint(epoch + 1, val_metrics)
            
            # å­¸ç¿’ç‡èª¿æ•´
            if (epoch + 1) % 20 == 0:
                for param_group in self.detection_optimizer.param_groups:
                    param_group['lr'] *= 0.1
                for param_group in self.classification_optimizer.param_groups:
                    param_group['lr'] *= 0.1
        
        # è¨“ç·´å®Œæˆ
        training_time = time.time() - start_time
        print(f"\nğŸ‰ é›™ç¨ç«‹éª¨å¹¹ç¶²è·¯è¨“ç·´å®Œæˆ!")
        print(f"â±ï¸ ç¸½è¨“ç·´æ™‚é–“: {training_time/3600:.2f} å°æ™‚")
        
        # ä¿å­˜è¨“ç·´æ­·å²
        with open(self.save_dir / 'dual_backbone_training_history.json', 'w') as f:
            json.dump(self.training_history, f, indent=2)
        
        # ç”Ÿæˆåˆ†æåœ–è¡¨
        self.plot_training_history()
        
        # æœ€çµ‚æ¨¡å‹ä¿å­˜
        torch.save(self.model.state_dict(), self.save_dir / 'dual_backbone_final.pt')
        
        # æ‰“å°æœ€çµ‚çµæœ
        final_metrics = {
            'mAP': self.training_history['mAP'][-1],
            'precision': self.training_history['precision'][-1],
            'recall': self.training_history['recall'][-1],
            'f1_score': self.training_history['f1_score'][-1],
            'classification_accuracy': self.training_history['classification_accuracy'][-1]
        }
        
        print(f"\nğŸ† æœ€çµ‚æ€§èƒ½æŒ‡æ¨™:")
        print(f"ğŸ“Š mAP: {final_metrics['mAP']:.4f}")
        print(f"ğŸ¯ Precision: {final_metrics['precision']:.4f}")
        print(f"ğŸ¯ Recall: {final_metrics['recall']:.4f}")
        print(f"ğŸ¯ F1-Score: {final_metrics['f1_score']:.4f}")
        print(f"ğŸ¯ Classification Accuracy: {final_metrics['classification_accuracy']:.2f}%")
        
        return final_metrics


def parse_opt():
    """è§£æå‘½ä»¤è¡Œåƒæ•¸"""
    parser = argparse.ArgumentParser()
    parser.add_argument('--data', type=str, default='../converted_dataset_fixed/data.yaml', help='dataset.yaml path')
    parser.add_argument('--epochs', type=int, default=50, help='total training epochs')
    parser.add_argument('--batch-size', type=int, default=8, help='total batch size')
    parser.add_argument('--imgsz', type=int, default=640, help='train, val image size (pixels)')
    parser.add_argument('--device', default='cpu', help='cuda device or cpu')
    parser.add_argument('--project', default='runs/dual_backbone', help='save to project/name')
    parser.add_argument('--name', default='dual_backbone_training', help='save to project/name')
    parser.add_argument('--exist-ok', action='store_true', help='existing project/name ok')
    
    return parser.parse_args()


def main():
    """ä¸»å‡½æ•¸"""
    opt = parse_opt()
    
    print("ğŸ”¬ é›™ç¨ç«‹éª¨å¹¹ç¶²è·¯è¯åˆè¨“ç·´ - æ–¹æ³•2è§£æ±ºæ–¹æ¡ˆ")
    print("="*60)
    print("ğŸ¯ æ ¸å¿ƒå„ªå‹¢: å®Œå…¨æ¶ˆé™¤æ¢¯åº¦å¹²æ“¾")
    print("ğŸ§  æŠ€è¡“åŸç†: æª¢æ¸¬å’Œåˆ†é¡ä½¿ç”¨å„è‡ªç¨ç«‹çš„backbone")
    print("âœ… é æœŸæ•ˆæœ: èˆ‡ç¨ç«‹è¨“ç·´æª¢æ¸¬ä»»å‹™ä¸€æ¨£çš„æ€§èƒ½")
    print("="*60)
    
    # åˆå§‹åŒ–è¨“ç·´å™¨
    trainer = DualBackboneTrainer(opt)
    
    # å‰µå»ºæ•¸æ“šåŠ è¼‰å™¨
    trainer.create_dataloaders()
    
    # é–‹å§‹è¨“ç·´
    final_metrics = trainer.train()
    
    print("\nğŸ‰ é›™ç¨ç«‹éª¨å¹¹ç¶²è·¯è¨“ç·´å®Œæˆ!")
    print("ğŸ“Š æ€§èƒ½æŒ‡æ¨™å·²ä¿å­˜")
    print("ğŸ“ˆ åˆ†æåœ–è¡¨å·²ç”Ÿæˆ")
    print("ğŸ’¾ æ¨¡å‹å·²ä¿å­˜")


if __name__ == '__main__':
    main() 