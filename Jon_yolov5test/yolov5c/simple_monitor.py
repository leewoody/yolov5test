#!/usr/bin/env python3
"""
ç°¡åŒ–çš„è¨“ç·´ç›£æ§è…³æœ¬
ç›£æ§ GradNorm å’Œé›™ç¨ç«‹éª¨å¹¹ç¶²è·¯çš„ 50 epoch è¨“ç·´é€²åº¦
"""

import os
import time
import subprocess
from datetime import datetime

def get_log_tail(log_file, lines=10):
    """ç²å–æ—¥èªŒæ–‡ä»¶çš„æœ€å¾Œå¹¾è¡Œ"""
    try:
        if os.path.exists(log_file):
            with open(log_file, 'r', encoding='utf-8', errors='ignore') as f:
                return f.readlines()[-lines:]
        return []
    except:
        return []

def parse_gradnorm_progress(log_file):
    """è§£æ GradNorm è¨“ç·´é€²åº¦"""
    lines = get_log_tail(log_file, 30)
    
    current_epoch = None
    current_batch = None
    latest_loss = None
    detection_weight = None
    classification_weight = None
    has_error = False
    
    for line in lines:
        line = line.strip()
        
        # æª¢æŸ¥éŒ¯èª¤
        if any(keyword in line.lower() for keyword in ['error', 'traceback', 'exception']):
            has_error = True
        
        # è§£æé€²åº¦
        if "Epoch" in line and "/" in line:
            try:
                epoch_part = line.split("Epoch ")[1].split("/")[0]
                current_epoch = int(epoch_part)
            except:
                pass
        
        if "Batch" in line and "Total Loss:" in line:
            try:
                parts = line.split(",")
                # è§£æbatch
                batch_part = [p for p in parts if "Batch" in p][0]
                current_batch = batch_part.split("/")[0].split()[-1]
                
                # è§£æloss
                loss_part = [p for p in parts if "Total Loss:" in p][0]
                latest_loss = float(loss_part.split("Total Loss:")[1].strip())
                
                # è§£ææ¬Šé‡
                det_part = [p for p in parts if "Detection Weight:" in p][0]
                detection_weight = float(det_part.split("Detection Weight:")[1].strip())
                
                cls_part = [p for p in parts if "Classification Weight:" in p][0]
                classification_weight = float(cls_part.split("Classification Weight:")[1].strip())
            except:
                pass
    
    return {
        "epoch": current_epoch,
        "batch": current_batch,
        "loss": latest_loss,
        "detection_weight": detection_weight,
        "classification_weight": classification_weight,
        "has_error": has_error
    }

def parse_dual_backbone_progress(log_file):
    """è§£æé›™ç¨ç«‹éª¨å¹¹ç¶²è·¯è¨“ç·´é€²åº¦"""
    lines = get_log_tail(log_file, 30)
    
    current_epoch = None
    status = "åˆå§‹åŒ–ä¸­"
    has_error = False
    
    for line in lines:
        line = line.strip()
        
        # æª¢æŸ¥éŒ¯èª¤
        if any(keyword in line.lower() for keyword in ['error', 'traceback', 'exception']):
            has_error = True
        
        # æª¢æŸ¥ç‹€æ…‹
        if "è¨“ç·´æ¨£æœ¬" in line or "training samples" in line:
            status = "æ•¸æ“šåŠ è¼‰å®Œæˆ"
        elif "Epoch" in line and "/" in line:
            status = "è¨“ç·´é€²è¡Œä¸­"
            try:
                epoch_part = line.split("Epoch ")[1].split("/")[0]
                current_epoch = int(epoch_part)
            except:
                pass
    
    return {
        "epoch": current_epoch,
        "status": status,
        "has_error": has_error
    }

def check_jobs():
    """æª¢æŸ¥èƒŒæ™¯ä½œæ¥­ç‹€æ…‹"""
    try:
        result = subprocess.run(['jobs'], shell=True, capture_output=True, text=True)
        output = result.stdout
        
        gradnorm_running = "train_joint_gradnorm" in output
        dual_backbone_running = "train_dual_backbone" in output
        
        return gradnorm_running, dual_backbone_running
    except:
        return False, False

def monitor_training():
    """ç›£æ§è¨“ç·´ç‹€æ…‹"""
    gradnorm_log = "gradnorm_complete_50.log"
    dual_backbone_log = "dual_backbone_complete_50.log"
    
    # æª¢æŸ¥ä½œæ¥­ç‹€æ…‹
    gradnorm_running, dual_backbone_running = check_jobs()
    
    # è§£æé€²åº¦
    gradnorm_progress = parse_gradnorm_progress(gradnorm_log)
    dual_backbone_progress = parse_dual_backbone_progress(dual_backbone_log)
    
    # ç”Ÿæˆå ±å‘Š
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    print(f"\n{'='*70}")
    print(f"ğŸ” è¨“ç·´ç›£æ§å ±å‘Š - {timestamp}")
    print(f"{'='*70}")
    
    # GradNorm ç‹€æ…‹
    status_icon = "ğŸŸ¢" if gradnorm_running else "ğŸ”´"
    print(f"GradNorm è¨“ç·´: {status_icon} {'é‹è¡Œä¸­' if gradnorm_running else 'å·²åœæ­¢'}")
    
    if gradnorm_progress["epoch"]:
        print(f"  ğŸ“ˆ é€²åº¦: Epoch {gradnorm_progress['epoch']}/50, Batch {gradnorm_progress['batch']}")
        if gradnorm_progress["loss"]:
            print(f"  ğŸ“‰ ç¸½æå¤±: {gradnorm_progress['loss']:.4f}")
        if gradnorm_progress["detection_weight"] and gradnorm_progress["classification_weight"]:
            print(f"  âš–ï¸  æª¢æ¸¬æ¬Šé‡: {gradnorm_progress['detection_weight']:.4f}")
            print(f"  âš–ï¸  åˆ†é¡æ¬Šé‡: {gradnorm_progress['classification_weight']:.4f}")
            ratio = gradnorm_progress["detection_weight"] / gradnorm_progress["classification_weight"]
            print(f"  ğŸ“ æ¬Šé‡æ¯”ä¾‹: {ratio:.1f}:1")
    
    if gradnorm_progress["has_error"]:
        print(f"  âš ï¸  æª¢æ¸¬åˆ°éŒ¯èª¤")
    
    # é›™ç¨ç«‹éª¨å¹¹ç¶²è·¯ç‹€æ…‹
    status_icon = "ğŸŸ¢" if dual_backbone_running else "ğŸ”´"
    print(f"é›™ç¨ç«‹éª¨å¹¹ç¶²è·¯: {status_icon} {'é‹è¡Œä¸­' if dual_backbone_running else 'å·²åœæ­¢'}")
    print(f"  ğŸ“‹ ç‹€æ…‹: {dual_backbone_progress['status']}")
    
    if dual_backbone_progress["epoch"]:
        print(f"  ğŸ“ˆ é€²åº¦: Epoch {dual_backbone_progress['epoch']}/50")
    
    if dual_backbone_progress["has_error"]:
        print(f"  âš ï¸  æª¢æ¸¬åˆ°éŒ¯èª¤")
    
    # å®Œæˆç‹€æ…‹æª¢æŸ¥
    gradnorm_completed = gradnorm_progress.get("epoch") == 50
    dual_backbone_completed = dual_backbone_progress.get("epoch") == 50
    
    if gradnorm_completed and dual_backbone_completed:
        print("\nğŸ‰ å…©å€‹è¨“ç·´éƒ½å·²å®Œæˆ 50 epochs!")
        return True
    elif not gradnorm_running and not dual_backbone_running:
        print("\nâš ï¸  å…©å€‹è¨“ç·´éƒ½å·²åœæ­¢")
        
    return False

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸš€ é–‹å§‹ç›£æ§ GradNorm å’Œé›™ç¨ç«‹éª¨å¹¹ç¶²è·¯è¨“ç·´...")
    print("ğŸ“‹ æ¯2åˆ†é˜æª¢æŸ¥ä¸€æ¬¡é€²åº¦")
    print("ğŸ’¡ æŒ‰ Ctrl+C åœæ­¢ç›£æ§")
    
    try:
        while True:
            completed = monitor_training()
            if completed:
                break
            time.sleep(120)  # æ¯2åˆ†é˜æª¢æŸ¥ä¸€æ¬¡
    except KeyboardInterrupt:
        print("\nâ¹ï¸  ç›£æ§å·²åœæ­¢")

if __name__ == "__main__":
    main() 