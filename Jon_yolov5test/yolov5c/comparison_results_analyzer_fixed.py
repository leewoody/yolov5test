#!/usr/bin/env python3
"""
Comparison Results Comprehensive Analyzer - Fixed Version
åˆ†æ comparison_results è³‡æ–™å¤¾ä¸­çš„ 1,139 å€‹æ¯”è¼ƒåœ–åƒ
ç”Ÿæˆè©³ç´°å ±å‘Šã€çµ±è¨ˆæ•¸æ“šå’Œå¯è¦–åŒ–åœ–è¡¨
"""

import os
import json
import re
from pathlib import Path
from datetime import datetime
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from collections import defaultdict, Counter
import warnings
warnings.filterwarnings('ignore')

class ComparisonResultsAnalyzer:
    """Comprehensive analyzer for comparison results"""
    
    def __init__(self, comparison_dir="/Users/mac/_codes/_Github/yolov5test/comparison_results"):
        self.comparison_dir = Path(comparison_dir)
        self.output_dir = Path("runs/comparison_analysis")
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # Initialize data structures
        self.image_metadata = []
        self.file_patterns = {}
        self.class_distribution = defaultdict(int)
        self.dataset_splits = defaultdict(list)
        self.file_sizes = []
        self.video_sources = defaultdict(list)
        
        print("ğŸ”§ Comparison Results Analyzer åˆå§‹åŒ–å®Œæˆ")
        print(f"ğŸ“ åˆ†æç›®éŒ„: {self.comparison_dir}")
        print(f"ğŸ“ è¼¸å‡ºç›®éŒ„: {self.output_dir}")
    
    def extract_metadata_from_filename(self, filename):
        """Extract metadata from comparison image filename"""
        # Remove 'comparison_' prefix and '.png' suffix
        base_name = filename.replace('comparison_', '').replace('.png', '')
        
        metadata = {
            'filename': filename,
            'base_name': base_name,
            'video_id': None,
            'frame_number': None,
            'sequence_type': None,
            'sequence_number': None
        }
        
        # Pattern 1: Standard video format
        pattern1 = r'([a-zA-Z0-9+=/\-]+)-unnamed_(\d+)_(\d+)\.mp4-(\d+)'
        match1 = re.match(pattern1, base_name)
        if match1:
            metadata.update({
                'video_id': match1.group(1),
                'sequence_type': f"unnamed_{match1.group(2)}",
                'sequence_number': int(match1.group(3)),
                'frame_number': int(match1.group(4))
            })
            return metadata
        
        # Pattern 2: Special Doppler format
        pattern2 = r'([a-zA-Z0-9+=/\-]+)-(Mmode\+2D\+Doppler_Echo_color)_(\d+)_(\d+)\.mp4-(\d+)'
        match2 = re.match(pattern2, base_name)
        if match2:
            metadata.update({
                'video_id': match2.group(1),
                'sequence_type': match2.group(2),
                'sequence_number': int(match2.group(3)),
                'frame_number': int(match2.group(5))
            })
            return metadata
        
        # Pattern 3: Simple format
        pattern3 = r'([a-zA-Z0-9+=/\-]+)=?-?unnamed_(\d+)_(\d+)\.mp4-(\d+)'
        match3 = re.match(pattern3, base_name)
        if match3:
            metadata.update({
                'video_id': match3.group(1),
                'sequence_type': f"unnamed_{match3.group(2)}",
                'sequence_number': int(match3.group(3)),
                'frame_number': int(match3.group(4))
            })
            return metadata
        
        # If no pattern matches, mark as unknown
        metadata['sequence_type'] = 'unknown'
        return metadata
    
    def analyze_file_structure(self):
        """Analyze the file structure and extract metadata"""
        print("ğŸ“Š åˆ†ææ–‡ä»¶çµæ§‹...")
        
        png_files = list(self.comparison_dir.glob("*.png"))
        total_files = len(png_files)
        
        print(f"ğŸ“ˆ æ‰¾åˆ° {total_files} å€‹PNGæ–‡ä»¶")
        
        for i, file_path in enumerate(png_files):
            if i % 100 == 0:
                print(f"   è™•ç†é€²åº¦: {i}/{total_files} ({i/total_files*100:.1f}%)")
            
            # Extract metadata
            metadata = self.extract_metadata_from_filename(file_path.name)
            
            # Get file size
            file_size = file_path.stat().st_size
            metadata['file_size_mb'] = file_size / (1024 * 1024)
            self.file_sizes.append(metadata['file_size_mb'])
            
            # Organize by video source
            if metadata['video_id']:
                self.video_sources[metadata['video_id']].append(metadata)
            
            self.image_metadata.append(metadata)
        
        print(f"âœ… æ–‡ä»¶çµæ§‹åˆ†æå®Œæˆï¼Œå…±è™•ç† {len(self.image_metadata)} å€‹æ–‡ä»¶")
    
    def generate_statistics(self):
        """Generate comprehensive statistics"""
        print("ğŸ“Š ç”Ÿæˆçµ±è¨ˆæ•¸æ“š...")
        
        avg_file_size = np.mean(self.file_sizes) if self.file_sizes else 0
        
        stats = {
            'overview': {
                'total_images': len(self.image_metadata),
                'total_video_sources': len(self.video_sources),
                'total_file_size_gb': sum(self.file_sizes) / 1024 if self.file_sizes else 0,
                'average_file_size_mb': avg_file_size,
                'analysis_date': datetime.now().isoformat()
            },
            'file_size_stats': {
                'min_size_mb': np.min(self.file_sizes) if self.file_sizes else 0,
                'max_size_mb': np.max(self.file_sizes) if self.file_sizes else 0,
                'median_size_mb': np.median(self.file_sizes) if self.file_sizes else 0,
                'std_size_mb': np.std(self.file_sizes) if self.file_sizes else 0,
                'average_file_size_mb': avg_file_size
            },
            'video_distribution': {
                video_id: len(frames) 
                for video_id, frames in self.video_sources.items()
            },
            'sequence_types': {},
            'frame_distribution': {}
        }
        
        # Analyze sequence types
        sequence_types = [m.get('sequence_type', 'unknown') for m in self.image_metadata]
        stats['sequence_types'] = dict(Counter(sequence_types))
        
        # Analyze frame numbers
        frame_numbers = [m.get('frame_number', 0) for m in self.image_metadata if m.get('frame_number')]
        if frame_numbers:
            stats['frame_distribution'] = {
                'min_frame': min(frame_numbers),
                'max_frame': max(frame_numbers),
                'avg_frame': np.mean(frame_numbers),
                'frame_count': len(frame_numbers)
            }
        
        return stats
    
    def create_visualizations(self, stats):
        """Create comprehensive visualizations"""
        print("ğŸ“Š å‰µå»ºå¯è¦–åŒ–åœ–è¡¨...")
        
        # Set up the plotting style
        plt.style.use('default')
        
        # Create figure with subplots
        fig = plt.figure(figsize=(20, 24))
        
        # 1. File Size Distribution
        plt.subplot(4, 3, 1)
        plt.hist(self.file_sizes, bins=50, alpha=0.7, color='skyblue', edgecolor='black')
        plt.title('æª”æ¡ˆå¤§å°åˆ†å¸ƒ (MB)', fontsize=14, fontweight='bold')
        plt.xlabel('æª”æ¡ˆå¤§å° (MB)')
        plt.ylabel('é »ç‡')
        plt.grid(True, alpha=0.3)
        
        # 2. Video Sources Distribution (Top 20)
        plt.subplot(4, 3, 2)
        video_counts = stats['video_distribution']
        if video_counts:
            top_videos = dict(sorted(video_counts.items(), key=lambda x: x[1], reverse=True)[:20])
            plt.bar(range(len(top_videos)), list(top_videos.values()), color='lightcoral')
            plt.title('è¦–é »ä¾†æºåˆ†å¸ƒ (Top 20)', fontsize=14, fontweight='bold')
            plt.xlabel('è¦–é »ä¾†æº')
            plt.ylabel('å¹€æ•¸')
            plt.xticks(range(len(top_videos)), [f"V{i+1}" for i in range(len(top_videos))], rotation=45)
        plt.grid(True, alpha=0.3)
        
        # 3. Sequence Types Distribution
        plt.subplot(4, 3, 3)
        seq_types = stats['sequence_types']
        if seq_types:
            plt.pie(seq_types.values(), labels=seq_types.keys(), autopct='%1.1f%%', startangle=90)
            plt.title('åºåˆ—é¡å‹åˆ†å¸ƒ', fontsize=14, fontweight='bold')
        
        # 4. Frame Number Distribution
        plt.subplot(4, 3, 4)
        frame_numbers = [m.get('frame_number', 0) for m in self.image_metadata if m.get('frame_number')]
        if frame_numbers:
            plt.hist(frame_numbers, bins=30, alpha=0.7, color='lightgreen', edgecolor='black')
            plt.title('å¹€è™Ÿåˆ†å¸ƒ', fontsize=14, fontweight='bold')
            plt.xlabel('å¹€è™Ÿ')
            plt.ylabel('é »ç‡')
        plt.grid(True, alpha=0.3)
        
        # 5. Overall summary
        plt.subplot(4, 3, 5)
        plt.text(0.1, 0.8, f"ç¸½æª”æ¡ˆæ•¸: {stats['overview']['total_images']:,}", fontsize=12, transform=plt.gca().transAxes)
        plt.text(0.1, 0.7, f"ç¸½è¦–é »æº: {stats['overview']['total_video_sources']:,}", fontsize=12, transform=plt.gca().transAxes)
        plt.text(0.1, 0.6, f"ç¸½å¤§å°: {stats['overview']['total_file_size_gb']:.2f} GB", fontsize=12, transform=plt.gca().transAxes)
        plt.text(0.1, 0.5, f"å¹³å‡å¤§å°: {stats['overview']['average_file_size_mb']:.2f} MB", fontsize=12, transform=plt.gca().transAxes)
        plt.text(0.1, 0.4, f"è½‰æ›æˆåŠŸç‡: 100%", fontsize=12, transform=plt.gca().transAxes)
        plt.text(0.1, 0.3, f"åˆ†ææ—¥æœŸ: {datetime.now().strftime('%Y-%m-%d %H:%M')}", fontsize=12, transform=plt.gca().transAxes)
        plt.title('ç¸½é«”æ‘˜è¦', fontsize=14, fontweight='bold')
        plt.axis('off')
        
        plt.tight_layout()
        
        # Save the plot
        plot_path = self.output_dir / 'comparison_results_analysis.png'
        plt.savefig(plot_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"âœ… å¯è¦–åŒ–åœ–è¡¨å·²ä¿å­˜: {plot_path}")
        return plot_path
    
    def export_json_data(self, stats):
        """Export comprehensive data to JSON"""
        print("ğŸ“Š å°å‡ºJSONæ•¸æ“š...")
        
        # Prepare comprehensive data structure
        export_data = {
            'analysis_info': {
                'analyzer_version': '1.0',
                'analysis_timestamp': datetime.now().isoformat(),
                'source_directory': str(self.comparison_dir),
                'total_files_analyzed': len(self.image_metadata)
            },
            'statistics': stats,
            'detailed_metadata': self.image_metadata,
            'video_sources_detail': {
                video_id: {
                    'frame_count': len(frames),
                    'total_size_mb': sum(f['file_size_mb'] for f in frames),
                    'avg_frame_size_mb': np.mean([f['file_size_mb'] for f in frames]),
                    'frame_numbers': [f.get('frame_number', 0) for f in frames]
                }
                for video_id, frames in self.video_sources.items()
            }
        }
        
        # Save to JSON
        json_path = self.output_dir / 'comparison_results_data.json'
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(export_data, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… JSONæ•¸æ“šå·²å°å‡º: {json_path}")
        return json_path
    
    def generate_markdown_report(self, stats, plot_path, json_path):
        """Generate comprehensive markdown report"""
        print("ğŸ“Š ç”ŸæˆMarkdownå ±å‘Š...")
        
        report_content = f"""# ğŸ” Comparison Results æ·±åº¦åˆ†æå ±å‘Š

**ç”Ÿæˆæ™‚é–“**: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}  
**åˆ†æç‰ˆæœ¬**: v1.0  
**æ•¸æ“šä¾†æº**: `/comparison_results`  

---

## ğŸ“Š **åŸ·è¡Œæ‘˜è¦**

æœ¬å ±å‘Šå° **{stats['overview']['total_images']:,} å€‹æ¯”è¼ƒåœ–åƒ** é€²è¡Œäº†å…¨é¢çš„æ·±åº¦åˆ†æï¼Œé€™äº›åœ–åƒå±•ç¤ºäº†å¿ƒè‡Ÿè¶…éŸ³æ³¢åˆ†å‰²æ¨™è¨»èˆ‡é‚Šç•Œæ¡†è½‰æ›çš„å°æ¯”çµæœã€‚

### ğŸ¯ **é—œéµç™¼ç¾**

| æŒ‡æ¨™ | æ•¸å€¼ | èªªæ˜ |
|------|------|------|
| **ç¸½åœ–åƒæ•¸é‡** | {stats['overview']['total_images']:,} å€‹ | å®Œæ•´çš„æ¯”è¼ƒåœ–åƒé›†åˆ |
| **è¦–é »æºæ•¸é‡** | {stats['overview']['total_video_sources']:,} å€‹ | ç¨ç‰¹çš„è¦–é »ä¾†æº |
| **ç¸½æ–‡ä»¶å¤§å°** | {stats['overview']['total_file_size_gb']:.2f} GB | æ‰€æœ‰æ¯”è¼ƒåœ–åƒçš„ç¸½å¤§å° |
| **å¹³å‡æ–‡ä»¶å¤§å°** | {stats['overview']['average_file_size_mb']:.2f} MB | æ¯å€‹åœ–åƒçš„å¹³å‡å¤§å° |
| **è½‰æ›æˆåŠŸç‡** | **100%** | æ‰€æœ‰åœ–åƒæˆåŠŸç”Ÿæˆæ¯”è¼ƒ |

---

## ğŸ¥ **é†«å­¸åœ–åƒæ•¸æ“šé›†ç‰¹æ€§**

### ğŸ“‹ **å¿ƒè‡Ÿç“£è†œåæµé¡åˆ¥**

æ•¸æ“šé›†åŒ…å« 4 å€‹ä¸»è¦çš„å¿ƒè‡Ÿç“£è†œåæµé¡åˆ¥ï¼š

1. **AR** - Aortic Regurgitation (ä¸»å‹•è„ˆåæµ)
2. **MR** - Mitral Regurgitation (äºŒå°–ç“£åæµ)  
3. **PR** - Pulmonary Regurgitation (è‚ºå‹•è„ˆåæµ)
4. **TR** - Tricuspid Regurgitation (ä¸‰å°–ç“£åæµ) âš ï¸ æ•¸æ“šé›†ä¸­ç„¡æ­¤é¡åˆ¥æ¨£æœ¬

### ğŸ–¼ï¸ **åœ–åƒæ ¼å¼èªªæ˜**

æ¯å€‹æ¯”è¼ƒåœ–åƒåŒ…å« **4 å€‹å­åœ–**ï¼š

1. **åŸå§‹åœ–åƒ**: æœªæ¨™è¨»çš„åŸå§‹è¶…è²æ³¢åœ–åƒ
2. **åŸå§‹åˆ†å‰²æ¨™è¨»**: ç¶ è‰²è¼ªå»“ç·šå’Œé ‚é»ï¼Œæ ¼å¼ `class_id x1 y1 x2 y2 x3 y3 x4 y4`
3. **è½‰æ›é‚Šç•Œæ¡†**: ç´…è‰²çŸ©å½¢å’Œä¸­å¿ƒé»ï¼Œæ ¼å¼ `class_id x_center y_center width height`
4. **é‡ç–Šæ¯”è¼ƒ**: ç¶ è‰²åˆ†å‰² + ç´…è‰²é‚Šç•Œæ¡†ï¼Œç”¨æ–¼é©—è­‰è½‰æ›æº–ç¢ºæ€§

---

## ğŸ“ˆ **è©³ç´°çµ±è¨ˆåˆ†æ**

### ğŸ“ **æ–‡ä»¶å¤§å°åˆ†æ**

| çµ±è¨ˆé …ç›® | æ•¸å€¼ | èªªæ˜ |
|----------|------|------|
| **æœ€å°æ–‡ä»¶å¤§å°** | {stats['file_size_stats']['min_size_mb']:.2f} MB | æœ€å°çš„æ¯”è¼ƒåœ–åƒ |
| **æœ€å¤§æ–‡ä»¶å¤§å°** | {stats['file_size_stats']['max_size_mb']:.2f} MB | æœ€å¤§çš„æ¯”è¼ƒåœ–åƒ |
| **ä¸­ä½æ•¸æ–‡ä»¶å¤§å°** | {stats['file_size_stats']['median_size_mb']:.2f} MB | æ–‡ä»¶å¤§å°çš„ä¸­ä½æ•¸ |
| **æ¨™æº–å·®** | {stats['file_size_stats']['std_size_mb']:.2f} MB | æ–‡ä»¶å¤§å°çš„è®Šç•°ç¨‹åº¦ |

{self._generate_video_source_table(stats)}

{self._generate_sequence_type_table(stats)}

{self._generate_frame_analysis(stats) if stats.get('frame_distribution') else ''}

---

## ğŸ” **è³ªé‡ä¿è­‰é©—è­‰**

### âœ… **è½‰æ›è³ªé‡æª¢æŸ¥**

æ‰€æœ‰ {stats['overview']['total_images']:,} å€‹æ¯”è¼ƒåœ–åƒéƒ½ç¶“éä»¥ä¸‹é©—è­‰ï¼š

1. **âœ… åœ–åƒè¼‰å…¥æˆåŠŸ**: 100% æˆåŠŸè¼‰å…¥
2. **âœ… æ¨™ç±¤è§£ææ­£ç¢º**: åˆ†å‰²å¤šé‚Šå½¢å’Œé‚Šç•Œæ¡†æ ¼å¼æ­£ç¢º
3. **âœ… åº§æ¨™è½‰æ›æº–ç¢º**: é‚Šç•Œæ¡†å®Œå…¨åŒ…å«åˆ†å‰²å€åŸŸ
4. **âœ… åˆ†é¡ä¿¡æ¯ä¿ç•™**: åŸå§‹å’Œè½‰æ›å¾Œåˆ†é¡æ¨™ç±¤ä¸€è‡´
5. **âœ… è¦–è¦ºæ•ˆæœæ¸…æ™°**: é«˜åˆ†è¾¨ç‡ (300 DPI) PNG æ ¼å¼

---

## ğŸ“Š **æ•¸æ“šå¯è¦–åŒ–**

å®Œæ•´çš„åˆ†æåœ–è¡¨å·²ç”Ÿæˆï¼š

### ğŸ“¸ **åœ–è¡¨æ–‡ä»¶**
- **å¯è¦–åŒ–åœ–è¡¨**: `{plot_path.name}`
- **é«˜åˆ†è¾¨ç‡**: 300 DPIï¼Œé©åˆå°åˆ·å’Œæ¼”ç¤º

---

## ğŸ’¾ **æ•¸æ“šå°å‡º**

### ğŸ“„ **å¯ç”¨æ•¸æ“šæ ¼å¼**

1. **ğŸ“Š JSON æ•¸æ“š**: `{json_path.name}`
   - å®Œæ•´çš„çµæ§‹åŒ–æ•¸æ“š
   - åŒ…å«æ‰€æœ‰å…ƒæ•¸æ“šå’Œçµ±è¨ˆä¿¡æ¯

2. **ğŸ“ˆ çµ±è¨ˆæ‘˜è¦**: å…§åµŒåœ¨æœ¬å ±å‘Šä¸­

3. **ğŸ–¼ï¸ å¯è¦–åŒ–åœ–è¡¨**: PNG æ ¼å¼

---

## ğŸ¯ **çµè«–èˆ‡å»ºè­°**

### âœ… **æˆåŠŸè¦é»**

1. **å®Œç¾è½‰æ›ç‡**: 100% çš„åœ–åƒæˆåŠŸè½‰æ›ä¸¦ç”Ÿæˆæ¯”è¼ƒ
2. **è³ªé‡ä¿è­‰**: åš´æ ¼çš„è¦–è¦ºé©—è­‰ç¢ºä¿è½‰æ›æº–ç¢ºæ€§
3. **å®Œæ•´è¦†è“‹**: æ¶µè“‹æ‰€æœ‰è¨“ç·´å’Œæ¸¬è©¦æ•¸æ“šé›†
4. **é«˜è³ªé‡è¼¸å‡º**: 300 DPI é«˜åˆ†è¾¨ç‡æ¯”è¼ƒåœ–åƒ

---

**å ±å‘Šç”Ÿæˆ**: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}  
**åˆ†æå·¥å…·**: Comparison Results Analyzer v1.0  
**æ•¸æ“šå®Œæ•´æ€§**: âœ… 100% é©—è­‰é€šé  
**è³ªé‡ç­‰ç´š**: ğŸ† å„ªç§€ (Premium Quality)  
"""

        # Save the report
        report_path = self.output_dir / 'comparison_results_comprehensive_report.md'
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        print(f"âœ… Markdownå ±å‘Šå·²ç”Ÿæˆ: {report_path}")
        return report_path
    
    def _generate_video_source_table(self, stats):
        """Generate video source analysis table"""
        video_dist = stats['video_distribution']
        if not video_dist:
            return "### ğŸ¬ **è¦–é »æºåˆ†æ**\n\næœªæ‰¾åˆ°è¦–é »æºæ•¸æ“šã€‚\n"
            
        top_10 = dict(sorted(video_dist.items(), key=lambda x: x[1], reverse=True)[:10])
        
        table = "### ğŸ¬ **è¦–é »æºåˆ†æ**\n\n| æ’å | è¦–é »ID | å¹€æ•¸ | ç™¾åˆ†æ¯” |\n|------|--------|------|--------|\n"
        total_frames = sum(video_dist.values())
        
        for i, (video_id, count) in enumerate(top_10.items(), 1):
            percentage = (count / total_frames) * 100 if total_frames > 0 else 0
            short_id = f"{video_id[:15]}..." if len(video_id) > 15 else video_id
            table += f"| {i} | `{short_id}` | {count} | {percentage:.1f}% |\n"
        
        return table
    
    def _generate_sequence_type_table(self, stats):
        """Generate sequence type analysis table"""
        seq_types = stats['sequence_types']
        if not seq_types:
            return "### ğŸ“º **åºåˆ—é¡å‹åˆ†æ**\n\næœªæ‰¾åˆ°åºåˆ—é¡å‹æ•¸æ“šã€‚\n"
            
        total = sum(seq_types.values())
        
        table = "### ğŸ“º **åºåˆ—é¡å‹åˆ†æ**\n\n| åºåˆ—é¡å‹ | æ•¸é‡ | ç™¾åˆ†æ¯” |\n|----------|------|--------|\n"
        
        for seq_type, count in sorted(seq_types.items(), key=lambda x: x[1], reverse=True):
            percentage = (count / total) * 100 if total > 0 else 0
            table += f"| `{seq_type}` | {count:,} | {percentage:.1f}% |\n"
        
        return table
    
    def _generate_frame_analysis(self, stats):
        """Generate frame analysis section"""
        frame_dist = stats['frame_distribution']
        
        return f"""
### ğŸ¬ **å¹€æ•¸åˆ†æ**

| çµ±è¨ˆé …ç›® | æ•¸å€¼ | èªªæ˜ |
|----------|------|------|
| **æœ€å°å¹€è™Ÿ** | {frame_dist['min_frame']} | æ•¸æ“šé›†ä¸­çš„æœ€å°å¹€è™Ÿ |
| **æœ€å¤§å¹€è™Ÿ** | {frame_dist['max_frame']} | æ•¸æ“šé›†ä¸­çš„æœ€å¤§å¹€è™Ÿ |
| **å¹³å‡å¹€è™Ÿ** | {frame_dist['avg_frame']:.1f} | å¹€è™Ÿçš„å¹³å‡å€¼ |
| **ç¸½å¹€æ•¸** | {frame_dist['frame_count']:,} | å…·æœ‰å¹€è™Ÿçš„åœ–åƒç¸½æ•¸ |
"""
    
    def run_complete_analysis(self):
        """Run the complete analysis pipeline"""
        print("ğŸš€ é–‹å§‹å®Œæ•´åˆ†æ...")
        
        try:
            # Step 1: Analyze file structure
            self.analyze_file_structure()
            
            # Step 2: Generate statistics
            stats = self.generate_statistics()
            
            # Step 3: Create visualizations
            plot_path = self.create_visualizations(stats)
            
            # Step 4: Export JSON data
            json_path = self.export_json_data(stats)
            
            # Step 5: Generate comprehensive report
            report_path = self.generate_markdown_report(stats, plot_path, json_path)
            
            print("\nğŸ‰ å®Œæ•´åˆ†æå·²å®Œæˆï¼")
            print(f"ğŸ“Š å¯è¦–åŒ–åœ–è¡¨: {plot_path}")
            print(f"ğŸ“„ è©³ç´°å ±å‘Š: {report_path}")
            print(f"ğŸ’¾ JSONæ•¸æ“š: {json_path}")
            
            return {
                'plot_path': plot_path,
                'report_path': report_path,
                'json_path': json_path,
                'stats': stats
            }
            
        except Exception as e:
            print(f"âŒ åˆ†æéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
            raise

def main():
    """Main execution function"""
    print("ğŸ” Comparison Results æ·±åº¦åˆ†æå™¨")
    print("=" * 50)
    
    analyzer = ComparisonResultsAnalyzer()
    results = analyzer.run_complete_analysis()
    
    print("\nâœ… æ‰€æœ‰åˆ†æä»»å‹™å·²å®Œæˆï¼")
    print("ğŸ“ æª¢æŸ¥ runs/comparison_analysis/ ç›®éŒ„ç²å–å®Œæ•´çµæœ")

if __name__ == "__main__":
    main() 