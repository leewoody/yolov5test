#!/usr/bin/env python3
"""
é«˜ç²¾åº¦é›™ç¨ç«‹éª¨å¹¹ç¶²è·¯ v2.0
å°ˆç‚ºé†«å­¸åœ–åƒæª¢æ¸¬å’Œåˆ†é¡è¨­è¨ˆçš„é«˜æ€§èƒ½å¤šä»»å‹™å­¸ç¿’æ¶æ§‹

ç›®æ¨™æ€§èƒ½:
- mAP@0.5: 0.6+
- Precision: 0.7+
- Recall: 0.7+
- F1-Score: 0.6+
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision.models as models
from models.yolo import Model
from utils.torch_utils import select_device
from utils.loss import ComputeLoss
from utils.general import colorstr, init_seeds
import numpy as np
import cv2
from pathlib import Path
import math


class SpatialAttentionModule(nn.Module):
    """ç©ºé–“æ³¨æ„åŠ›æ¨¡å¡Š - å¢å¼·ç‰¹å¾µè¡¨ç¤º"""
    def __init__(self, kernel_size=7):
        super(SpatialAttentionModule, self).__init__()
        self.conv = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        avg_out = torch.mean(x, dim=1, keepdim=True)
        max_out, _ = torch.max(x, dim=1, keepdim=True)
        attention = torch.cat([avg_out, max_out], dim=1)
        attention = self.conv(attention)
        return x * self.sigmoid(attention)


class ChannelAttentionModule(nn.Module):
    """é€šé“æ³¨æ„åŠ›æ¨¡å¡Š - SE Block è®Šé«”"""
    def __init__(self, channels, reduction=16):
        super(ChannelAttentionModule, self).__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.max_pool = nn.AdaptiveMaxPool2d(1)
        
        self.fc1 = nn.Conv2d(channels, channels // reduction, 1, bias=False)
        self.relu = nn.ReLU()
        self.fc2 = nn.Conv2d(channels // reduction, channels, 1, bias=False)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        avg_out = self.fc2(self.relu(self.fc1(self.avg_pool(x))))
        max_out = self.fc2(self.relu(self.fc1(self.max_pool(x))))
        attention = self.sigmoid(avg_out + max_out)
        return x * attention


class CBAM(nn.Module):
    """Convolutional Block Attention Module - çµåˆé€šé“å’Œç©ºé–“æ³¨æ„åŠ›"""
    def __init__(self, channels, reduction=16, kernel_size=7):
        super(CBAM, self).__init__()
        self.channel_attention = ChannelAttentionModule(channels, reduction)
        self.spatial_attention = SpatialAttentionModule(kernel_size)

    def forward(self, x):
        x = self.channel_attention(x)
        x = self.spatial_attention(x)
        return x


class EnhancedDetectionBackbone(nn.Module):
    """å¢å¼·æª¢æ¸¬éª¨å¹¹ç¶²è·¯ - åŸºæ–¼YOLOv5l + æ³¨æ„åŠ›æ©Ÿåˆ¶"""
    
    def __init__(self, config_path='models/yolov5l.yaml', nc=4, device='cpu'):
        super(EnhancedDetectionBackbone, self).__init__()
        self.device = select_device(device)
        self.nc = nc
        
        # è¼‰å…¥YOLOv5læ¨¡å‹
        try:
            self.model = Model(config_path, ch=3, nc=nc).to(self.device)
        except:
            # å¦‚æœyolov5l.yamlä¸å­˜åœ¨ï¼Œä½¿ç”¨yolov5sä¸¦æ“´å±•
            print("Warning: Using YOLOv5s as base, expanding to YOLOv5l-like architecture")
            self.model = Model('models/yolov5s.yaml', ch=3, nc=nc).to(self.device)
        
        # è¨­ç½®è¶…åƒæ•¸
        self.model.hyp = {
            'box': 0.05, 'cls': 0.5, 'cls_pw': 1.0, 'obj': 1.0, 'obj_pw': 1.0,
            'iou_t': 0.20, 'anchor_t': 4.0, 'fl_gamma': 0.0,
            # æ–°å¢é«˜ç²¾åº¦ç›¸é—œåƒæ•¸
            'focal_loss_gamma': 2.0,
            'label_smoothing': 0.1,
            'conf_t': 0.25  # ç½®ä¿¡åº¦é–¾å€¼
        }
        
        # æ·»åŠ æ³¨æ„åŠ›æ©Ÿåˆ¶åˆ°æª¢æ¸¬é ­
        self._add_attention_modules()
        
        # ç‰¹å¾µæå–å±¤æ¨™è¨˜ï¼ˆç”¨æ–¼å¾ŒçºŒç‰¹å¾µèåˆï¼‰
        self.feature_layers = []
        self._mark_feature_layers()
        
    def _add_attention_modules(self):
        """åœ¨æª¢æ¸¬æ¨¡å‹ä¸­æ·»åŠ æ³¨æ„åŠ›æ©Ÿåˆ¶"""
        try:
            # ç‚ºæ¨¡å‹çš„é—œéµå±¤æ·»åŠ CBAMæ¨¡å¡Š
            if hasattr(self.model.model, '__iter__'):
                for i, layer in enumerate(self.model.model):
                    if hasattr(layer, 'conv') and hasattr(layer.conv, 'out_channels'):
                        # åœ¨å·ç©å±¤å¾Œæ·»åŠ æ³¨æ„åŠ›
                        channels = layer.conv.out_channels
                        if channels >= 64:  # åªåœ¨è¼ƒæ·±çš„å±¤æ·»åŠ æ³¨æ„åŠ›
                            setattr(layer, 'attention', CBAM(channels))
            print("âœ… æ³¨æ„åŠ›æ©Ÿåˆ¶å·²æ·»åŠ åˆ°æª¢æ¸¬ç¶²è·¯")
        except Exception as e:
            print(f"âš ï¸ æ·»åŠ æ³¨æ„åŠ›æ©Ÿåˆ¶æ™‚å‡ºç¾å•é¡Œ: {e}")
    
    def _mark_feature_layers(self):
        """æ¨™è¨˜ç‰¹å¾µæå–å±¤ï¼Œç”¨æ–¼å¾ŒçºŒèåˆ"""
        self.feature_layers = [4, 6, 9]  # YOLOv5çš„ä¸»è¦ç‰¹å¾µå±¤
        
    def forward(self, x):
        """å‰å‘å‚³æ’­"""
        if self.training:
            return self.model(x)
        else:
            # æ¨ç†æ¨¡å¼ï¼Œæ‡‰ç”¨æ³¨æ„åŠ›æ©Ÿåˆ¶
            return self._forward_with_attention(x)
    
    def _forward_with_attention(self, x):
        """å¸¶æ³¨æ„åŠ›æ©Ÿåˆ¶çš„å‰å‘å‚³æ’­"""
        features = []
        y = x
        
        for i, layer in enumerate(self.model.model):
            y = layer(y)
            
            # æ‡‰ç”¨æ³¨æ„åŠ›æ©Ÿåˆ¶
            if hasattr(layer, 'attention'):
                y = layer.attention(y)
            
            # æ”¶é›†ç‰¹å¾µç”¨æ–¼å¯èƒ½çš„èåˆ
            if i in self.feature_layers:
                features.append(y)
                
        return y

    def extract_features(self, x):
        """æå–ä¸­é–“ç‰¹å¾µï¼Œç”¨æ–¼è·¨ä»»å‹™èåˆ"""
        features = []
        y = x
        
        for i, layer in enumerate(self.model.model):
            y = layer(y)
            if hasattr(layer, 'attention'):
                y = layer.attention(y)
            if i in self.feature_layers:
                features.append(y)
                
        return features


class SpecializedClassificationBackbone(nn.Module):
    """å°ˆæ¥­åŒ–åˆ†é¡éª¨å¹¹ç¶²è·¯ - åŸºæ–¼ResNet-101 + é†«å­¸åœ–åƒå„ªåŒ–"""
    
    def __init__(self, num_classes=3, input_channels=3, pretrained=True):
        super(SpecializedClassificationBackbone, self).__init__()
        self.num_classes = num_classes
        
        # åŸºç¤ResNet-101æ¶æ§‹
        self.backbone = models.resnet101(pretrained=pretrained)
        
        # ç§»é™¤åŸå§‹åˆ†é¡é ­
        self.backbone = nn.Sequential(*list(self.backbone.children())[:-2])
        
        # é†«å­¸åœ–åƒç‰¹å®šçš„é è™•ç†å±¤
        self.medical_preprocessing = self._create_medical_preprocessing()
        
        # å¤šå°ºåº¦ç‰¹å¾µèåˆ
        self.multiscale_fusion = self._create_multiscale_fusion()
        
        # å¢å¼·çš„åˆ†é¡é ­
        self.enhanced_classifier = self._create_enhanced_classifier()
        
        # æ³¨æ„åŠ›æ©Ÿåˆ¶
        self.attention = CBAM(2048)  # ResNet-101çš„æœ€å¾Œç‰¹å¾µé€šé“æ•¸
        
        # Dropout for regularization
        self.dropout = nn.Dropout(0.5)
        
    def _create_medical_preprocessing(self):
        """å‰µå»ºé†«å­¸åœ–åƒç‰¹å®šçš„é è™•ç†å±¤"""
        return nn.Sequential(
            # é‚Šç·£å¢å¼·
            nn.Conv2d(3, 3, kernel_size=3, padding=1, groups=3, bias=False),
            nn.BatchNorm2d(3),
            nn.ReLU(inplace=True),
            
            # å°æ¯”åº¦å¢å¼·
            nn.Conv2d(3, 3, kernel_size=1, bias=False),
            nn.BatchNorm2d(3),
            nn.ReLU(inplace=True)
        )
    
    def _create_multiscale_fusion(self):
        """å‰µå»ºå¤šå°ºåº¦ç‰¹å¾µèåˆæ¨¡å¡Š"""
        return nn.ModuleDict({
            'scale1': nn.AdaptiveAvgPool2d((7, 7)),
            'scale2': nn.AdaptiveAvgPool2d((14, 14)),
            'scale3': nn.AdaptiveAvgPool2d((28, 28)),
            'fusion_conv': nn.Conv2d(2048*3, 2048, kernel_size=1, bias=False),
            'fusion_bn': nn.BatchNorm2d(2048),
            'fusion_relu': nn.ReLU(inplace=True)
        })
    
    def _create_enhanced_classifier(self):
        """å‰µå»ºå¢å¼·çš„åˆ†é¡é ­"""
        return nn.Sequential(
            # å…¨å±€å¹³å‡æ± åŒ– + è‡ªé©æ‡‰æ± åŒ–çµ„åˆ
            nn.AdaptiveAvgPool2d((1, 1)),
            nn.Flatten(),
            
            # ç¬¬ä¸€å€‹FCå±¤
            nn.Linear(2048, 1024),
            nn.BatchNorm1d(1024),
            nn.ReLU(inplace=True),
            nn.Dropout(0.5),
            
            # ç¬¬äºŒå€‹FCå±¤
            nn.Linear(1024, 512),
            nn.BatchNorm1d(512),
            nn.ReLU(inplace=True),
            nn.Dropout(0.3),
            
            # è¼¸å‡ºå±¤
            nn.Linear(512, self.num_classes)
        )
    
    def forward(self, x):
        """å‰å‘å‚³æ’­"""
        # é†«å­¸åœ–åƒé è™•ç†
        x = self.medical_preprocessing(x)
        
        # ä¸»å¹¹ç‰¹å¾µæå–
        features = self.backbone(x)
        
        # å¤šå°ºåº¦ç‰¹å¾µèåˆ
        ms_features = self._apply_multiscale_fusion(features)
        
        # æ‡‰ç”¨æ³¨æ„åŠ›æ©Ÿåˆ¶
        attended_features = self.attention(ms_features)
        
        # åˆ†é¡
        output = self.enhanced_classifier(attended_features)
        
        return output
    
    def _apply_multiscale_fusion(self, features):
        """æ‡‰ç”¨å¤šå°ºåº¦ç‰¹å¾µèåˆ"""
        # ç²å–ä¸åŒå°ºåº¦çš„ç‰¹å¾µ
        scale1 = self.multiscale_fusion['scale1'](features)  # 7x7
        scale2 = self.multiscale_fusion['scale2'](features)  # 14x14  
        scale3 = self.multiscale_fusion['scale3'](features)  # 28x28
        
        # èª¿æ•´åˆ°ç›¸åŒå°ºå¯¸
        scale2_resized = F.interpolate(scale2, size=(7, 7), mode='bilinear', align_corners=False)
        scale3_resized = F.interpolate(scale3, size=(7, 7), mode='bilinear', align_corners=False)
        
        # èåˆ
        fused = torch.cat([scale1, scale2_resized, scale3_resized], dim=1)
        
        # é™ç¶­
        fused = self.multiscale_fusion['fusion_conv'](fused)
        fused = self.multiscale_fusion['fusion_bn'](fused)
        fused = self.multiscale_fusion['fusion_relu'](fused)
        
        return fused

    def extract_features(self, x):
        """æå–ç‰¹å¾µç”¨æ–¼è·¨ä»»å‹™èåˆ"""
        x = self.medical_preprocessing(x)
        features = self.backbone(x)
        return features


class CrossTaskFeatureFusion(nn.Module):
    """è·¨ä»»å‹™ç‰¹å¾µèåˆæ¨¡å¡Š - åœ¨ä¿æŒç¨ç«‹æ€§çš„åŒæ™‚å…è¨±ç‰¹å¾µå”ä½œ"""
    
    def __init__(self, detection_channels=512, classification_channels=2048):
        super(CrossTaskFeatureFusion, self).__init__()
        
        # ç‰¹å¾µå°é½Šå±¤
        self.det_align = nn.Conv2d(detection_channels, 512, kernel_size=1)
        self.cls_align = nn.Conv2d(classification_channels, 512, kernel_size=1)
        
        # è·¨ä»»å‹™æ³¨æ„åŠ›
        self.cross_attention = nn.MultiheadAttention(512, num_heads=8, batch_first=True)
        
        # ç‰¹å¾µå¢å¼·
        self.det_enhance = CBAM(512)
        self.cls_enhance = CBAM(512)
        
        # è¼¸å‡ºæŠ•å½±
        self.det_output = nn.Conv2d(512, detection_channels, kernel_size=1)
        self.cls_output = nn.Conv2d(512, classification_channels, kernel_size=1)
        
    def forward(self, det_features, cls_features):
        """
        Args:
            det_features: æª¢æ¸¬ç¶²è·¯ç‰¹å¾µ [B, C1, H, W]
            cls_features: åˆ†é¡ç¶²è·¯ç‰¹å¾µ [B, C2, H', W']
        """
        # ç‰¹å¾µå°é½Š
        det_aligned = self.det_align(det_features)  # [B, 512, H, W]
        
        # èª¿æ•´åˆ†é¡ç‰¹å¾µå°ºå¯¸ä»¥åŒ¹é…æª¢æ¸¬ç‰¹å¾µ
        cls_resized = F.interpolate(cls_features, size=det_features.shape[2:], 
                                  mode='bilinear', align_corners=False)
        cls_aligned = self.cls_align(cls_resized)   # [B, 512, H, W]
        
        # æº–å‚™è·¨æ³¨æ„åŠ›è¼¸å…¥ (å±•å¹³ç‚ºåºåˆ—)
        B, C, H, W = det_aligned.shape
        det_seq = det_aligned.flatten(2).transpose(1, 2)  # [B, HW, 512]
        cls_seq = cls_aligned.flatten(2).transpose(1, 2)  # [B, HW, 512]
        
        # è·¨ä»»å‹™æ³¨æ„åŠ› (æª¢æ¸¬æŸ¥è©¢åˆ†é¡)
        det_enhanced_seq, _ = self.cross_attention(det_seq, cls_seq, cls_seq)
        cls_enhanced_seq, _ = self.cross_attention(cls_seq, det_seq, det_seq)
        
        # é‡å¡‘å›ç‰¹å¾µåœ–
        det_enhanced = det_enhanced_seq.transpose(1, 2).reshape(B, C, H, W)
        cls_enhanced = cls_enhanced_seq.transpose(1, 2).reshape(B, C, H, W)
        
        # CBAMå¢å¼·
        det_enhanced = self.det_enhance(det_enhanced)
        cls_enhanced = self.cls_enhance(cls_enhanced)
        
        # è¼¸å‡ºæŠ•å½±
        det_output = self.det_output(det_enhanced)
        cls_output = self.cls_output(cls_enhanced)
        
        # æ®˜å·®é€£æ¥
        det_final = det_features + det_output
        cls_final = cls_features + F.interpolate(cls_output, size=cls_features.shape[2:], 
                                               mode='bilinear', align_corners=False)
        
        return det_final, cls_final


class AdvancedDualBackboneModel(nn.Module):
    """é«˜ç´šé›™ç¨ç«‹éª¨å¹¹ç¶²è·¯æ¨¡å‹"""
    
    def __init__(self, nc=4, num_classes=3, device='cpu', enable_fusion=True):
        super(AdvancedDualBackboneModel, self).__init__()
        
        self.device = select_device(device)
        self.nc = nc
        self.num_classes = num_classes
        self.enable_fusion = enable_fusion
        
        # æª¢æ¸¬éª¨å¹¹ç¶²è·¯ (å¢å¼·ç‰ˆ)
        self.detection_backbone = EnhancedDetectionBackbone(
            nc=nc, device=device
        ).to(self.device)
        
        # åˆ†é¡éª¨å¹¹ç¶²è·¯ (å°ˆæ¥­åŒ–)
        self.classification_backbone = SpecializedClassificationBackbone(
            num_classes=num_classes
        ).to(self.device)
        
        # è·¨ä»»å‹™ç‰¹å¾µèåˆ (å¯é¸)
        if enable_fusion:
            self.feature_fusion = CrossTaskFeatureFusion().to(self.device)
        
        print(f"âœ… é«˜ç´šé›™ç¨ç«‹éª¨å¹¹ç¶²è·¯åˆå§‹åŒ–å®Œæˆ")
        print(f"   æª¢æ¸¬é¡åˆ¥æ•¸: {nc}")
        print(f"   åˆ†é¡é¡åˆ¥æ•¸: {num_classes}")
        print(f"   ç‰¹å¾µèåˆ: {'å•Ÿç”¨' if enable_fusion else 'ç¦ç”¨'}")
        print(f"   è¨­å‚™: {device}")
        
    def forward(self, x):
        """å‰å‘å‚³æ’­"""
        # æª¢æ¸¬åˆ†æ”¯
        detection_output = self.detection_backbone(x)
        
        # åˆ†é¡åˆ†æ”¯
        classification_output = self.classification_backbone(x)
        
        # å¯é¸çš„ç‰¹å¾µèåˆ
        if self.enable_fusion and self.training:
            try:
                det_features = self.detection_backbone.extract_features(x)
                cls_features = self.classification_backbone.extract_features(x)
                
                # ä½¿ç”¨æœ€å¾Œä¸€å±¤ç‰¹å¾µé€²è¡Œèåˆ
                if det_features and cls_features:
                    enhanced_det, enhanced_cls = self.feature_fusion(
                        det_features[-1], cls_features
                    )
                    # æ³¨æ„ï¼šå¯¦éš›æ‡‰ç”¨ä¸­éœ€è¦å°‡å¢å¼·ç‰¹å¾µé‡æ–°è¼¸å…¥åˆ°å„è‡ªçš„é ­éƒ¨
                    
            except Exception as e:
                print(f"ç‰¹å¾µèåˆéç¨‹ä¸­å‡ºç¾å•é¡Œ: {e}")
        
        return detection_output, classification_output
    
    def get_model_info(self):
        """ç²å–æ¨¡å‹ä¿¡æ¯"""
        total_params = sum(p.numel() for p in self.parameters())
        trainable_params = sum(p.numel() for p in self.parameters() if p.requires_grad)
        
        det_params = sum(p.numel() for p in self.detection_backbone.parameters())
        cls_params = sum(p.numel() for p in self.classification_backbone.parameters())
        
        info = {
            'total_parameters': total_params,
            'trainable_parameters': trainable_params,
            'detection_parameters': det_params,
            'classification_parameters': cls_params,
            'parameter_ratio': f"Det:{det_params/total_params:.2%}, Cls:{cls_params/total_params:.2%}"
        }
        
        return info


def test_advanced_dual_backbone():
    """æ¸¬è©¦é«˜ç´šé›™ç¨ç«‹éª¨å¹¹ç¶²è·¯"""
    print("ğŸ”§ æ¸¬è©¦é«˜ç´šé›™ç¨ç«‹éª¨å¹¹ç¶²è·¯...")
    
    # åˆå§‹åŒ–æ¨¡å‹
    model = AdvancedDualBackboneModel(
        nc=4, 
        num_classes=3, 
        device='cpu',
        enable_fusion=True
    )
    model.eval()
    
    # æ¸¬è©¦è¼¸å…¥
    test_input = torch.randn(2, 3, 640, 640)
    
    print(f"è¼¸å…¥å½¢ç‹€: {test_input.shape}")
    
    # å‰å‘å‚³æ’­æ¸¬è©¦
    with torch.no_grad():
        detection_out, classification_out = model(test_input)
    
    print(f"æª¢æ¸¬è¼¸å‡ºå½¢ç‹€: {detection_out.shape if hasattr(detection_out, 'shape') else type(detection_out)}")
    print(f"åˆ†é¡è¼¸å‡ºå½¢ç‹€: {classification_out.shape}")
    
    # æ¨¡å‹ä¿¡æ¯
    info = model.get_model_info()
    print(f"\nğŸ“Š æ¨¡å‹ä¿¡æ¯:")
    for key, value in info.items():
        print(f"   {key}: {value}")
    
    print("âœ… é«˜ç´šé›™ç¨ç«‹éª¨å¹¹ç¶²è·¯æ¸¬è©¦å®Œæˆ")
    return model


if __name__ == "__main__":
    # è¨­ç½®éš¨æ©Ÿç¨®å­
    init_seeds(42)
    
    # é‹è¡Œæ¸¬è©¦
    model = test_advanced_dual_backbone() 