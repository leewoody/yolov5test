#!/usr/bin/env python3
"""
Complete Joint Training with GradNorm - ÂÆåÊï¥ËÅØÂêàË®ìÁ∑¥
ÂÆåÂÖ®ÈÅµÂæ™ YOLOv5WithClassification ËÅØÂêàË®ìÁ∑¥Ë¶èÂâá

Key Features:
- ÂïüÁî®ÂàÜÈ°ûÂäüËÉΩ (classification_enabled: true)
- ÈóúÈñâÊï∏ÊìöÊì¥Â¢û (‰øùÊåÅÈÜ´Â≠∏ÂúñÂÉèÂéüÂßãÁâπÂæµ)
- ÈóúÈñâÊó©ÂÅúÊ©üÂà∂ (Áç≤ÂæóÂÆåÊï¥Ë®ìÁ∑¥ÂúñË°®)
- ÊîØÊåÅÂÆåÊï¥ 50 epoch Ë®ìÁ∑¥
- GradNorm ÂãïÊÖãÊ¢ØÂ∫¶Âπ≥Ë°°
"""

import os
import sys
import argparse
import yaml
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
import json
from datetime import datetime
import logging
import cv2

# Add yolov5c to path
sys.path.append(str(Path(__file__).parent))

from models.gradnorm import GradNormLoss, AdaptiveGradNormLoss
from utils.general import check_img_size, non_max_suppression, colorstr
from utils.loss import ComputeLoss
from utils.metrics import ap_per_class, box_iou
from utils.torch_utils import select_device, time_sync
from utils.plots import plot_results
from utils.dataloaders import create_dataloader
from models.yolo import Model

def parse_opt():
    parser = argparse.ArgumentParser()
    parser.add_argument('--data', type=str, default='../Regurgitation-YOLODataset-1new/data.yaml', help='dataset.yaml path')
    parser.add_argument('--weights', type=str, default='yolov5s.pt', help='initial weights path')
    parser.add_argument('--epochs', type=int, default=50, help='number of epochs')
    parser.add_argument('--batch-size', type=int, default=8, help='total batch size for all GPUs')
    parser.add_argument('--imgsz', '--img', '--img-size', type=int, default=640, help='train, val image size (pixels)')
    parser.add_argument('--device', default='auto', help='cuda device, i.e. 0 or 0,1,2,3 or cpu')
    parser.add_argument('--workers', type=int, default=0, help='max dataloader workers')
    parser.add_argument('--project', default='runs/joint_gradnorm_complete', help='save to project/name')
    parser.add_argument('--name', default='joint_gradnorm_complete', help='save to project/name')
    parser.add_argument('--exist-ok', action='store_true', help='existing project/name ok, do not increment')
    parser.add_argument('--gradnorm-alpha', type=float, default=1.5, help='GradNorm alpha parameter')
    parser.add_argument('--classification-enabled', action='store_true', default=True, help='Enable classification (always true)')
    parser.add_argument('--classification-weight', type=float, default=0.01, help='Initial classification weight')
    parser.add_argument('--progressive-training', action='store_true', default=True, help='Enable progressive training')
    parser.add_argument('--save-period', type=int, default=10, help='Save checkpoint every x epochs')
    
    return parser.parse_args()

class JointGradNormTrainer:
    def __init__(self, opt):
        self.opt = opt
        self.device = select_device(opt.device, batch_size=opt.batch_size)
        
        # Create save directory
        self.save_dir = Path(opt.project) / opt.name
        self.save_dir.mkdir(parents=True, exist_ok=opt.exist_ok)
        
        # Setup logging
        self.setup_logging()
        
        # Load data configuration
        self.load_data_config()
        
        # Initialize model
        self.init_model()
        
        # Setup dataloaders with NO data augmentation
        self.setup_dataloaders()
        
        # Initialize GradNorm loss
        self.init_gradnorm()
        
        # Initialize training tracking
        self.init_tracking()
        
        # Log configuration
        self.log_config()
    
    def setup_logging(self):
        """Setup logging configuration"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(self.save_dir / 'training.log'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
        
    def load_data_config(self):
        """Load dataset configuration"""
        with open(self.opt.data, 'r') as f:
            self.data_dict = yaml.safe_load(f)
        
        self.nc = int(self.data_dict['nc'])  # Number of detection classes
        self.names = self.data_dict['names']
        
        # Classification classes (PSAX, PLAX, A4C)
        self.classification_classes = ['PSAX', 'PLAX', 'A4C']
        self.nc_classification = len(self.classification_classes)
        
        self.logger.info(f"Detection classes: {self.nc} ({self.names})")
        self.logger.info(f"Classification classes: {self.nc_classification} ({self.classification_classes})")
    
    def init_model(self):
        """Initialize YOLOv5 model with joint training capabilities"""
        # Load model
        self.model = Model('models/yolov5s.yaml', ch=3, nc=self.nc, anchors=None).to(self.device)
        
        # Load pretrained weights if available
        if self.opt.weights.endswith('.pt'):
            try:
                ckpt = torch.load(self.opt.weights, map_location='cpu', weights_only=False)
                state_dict = ckpt['model'].float().state_dict()
                self.model.load_state_dict(state_dict, strict=False)
                self.logger.info(f"Loaded pretrained weights from {self.opt.weights}")
            except Exception as e:
                self.logger.warning(f"Could not load weights: {e}")
        
        # Add hyperparameters (required for ComputeLoss)
        self.model.hyp = {
            'box': 0.05,
            'cls': 0.5,
            'cls_pw': 1.0,
            'obj': 1.0,
            'obj_pw': 1.0,
            'iou_t': 0.20,
            'anchor_t': 4.0,
            'fl_gamma': 0.0,
            'hsv_h': 0.0,      # ÈóúÈñâËâ≤Ë™øË™øÊï¥
            'hsv_s': 0.0,      # ÈóúÈñâÈ£ΩÂíåÂ∫¶Ë™øÊï¥
            'hsv_v': 0.0,      # ÈóúÈñâ‰∫ÆÂ∫¶Ë™øÊï¥
            'degrees': 0.0,    # ÈóúÈñâÊóãËΩâ
            'translate': 0.0,  # ÈóúÈñâÂπ≥Áßª
            'scale': 0.0,      # ÈóúÈñâÁ∏ÆÊîæ
            'shear': 0.0,      # ÈóúÈñâÂâ™Âàá
            'perspective': 0.0, # ÈóúÈñâÈÄèË¶ñËÆäÊèõ
            'flipud': 0.0,     # ÈóúÈñâÂûÇÁõ¥ÁøªËΩâ
            'fliplr': 0.0,     # ÈóúÈñâÊ∞¥Âπ≥ÁøªËΩâ
            'mosaic': 0.0,     # ÈóúÈñâÈ¶¨Ë≥ΩÂÖã
            'mixup': 0.0,      # ÈóúÈñâÊ∑∑Âêà
            'copy_paste': 0.0  # ÈóúÈñâË§áË£ΩË≤º‰∏ä
        }
        
        # Add classification head
        self.add_classification_head()
        
        self.logger.info(f"Model: {self.model}")
        
    def add_classification_head(self):
        """Add classification head to the model"""
        # Get feature size from the model
        # Typically P3 layer has 128 channels after processing
        feature_size = 128
        
        self.classification_head = nn.Sequential(
            nn.AdaptiveAvgPool2d((1, 1)),
            nn.Flatten(),
            nn.Linear(feature_size, 64),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(64, self.nc_classification)
        ).to(self.device)
        
        self.logger.info(f"Added classification head: {self.nc_classification} classes")
    
    def setup_dataloaders(self):
        """Setup dataloaders with NO data augmentation"""
        # Training hyperparameters with NO augmentation
        hyp_no_aug = {
            'lr0': 0.01,
            'lrf': 0.01,
            'momentum': 0.937,
            'weight_decay': 0.0005,
            'warmup_epochs': 3.0,
            'warmup_momentum': 0.8,
            'warmup_bias_lr': 0.1,
            'box': 0.05,
            'cls': 0.5,
            'cls_pw': 1.0,
            'obj': 1.0,
            'obj_pw': 1.0,
            'iou_t': 0.20,
            'anchor_t': 4.0,
            'fl_gamma': 0.0,
            # ÂÆåÂÖ®ÈóúÈñâÊï∏ÊìöÊì¥Â¢û - ÈÜ´Â≠∏ÂúñÂÉè‰øùÊåÅÂéüÂßãÁâπÂæµ
            'hsv_h': 0.0,      # NO hue augmentation
            'hsv_s': 0.0,      # NO saturation augmentation  
            'hsv_v': 0.0,      # NO value augmentation
            'degrees': 0.0,    # NO rotation
            'translate': 0.0,  # NO translation
            'scale': 0.0,      # NO scaling
            'shear': 0.0,      # NO shearing
            'perspective': 0.0, # NO perspective
            'flipud': 0.0,     # NO vertical flip
            'fliplr': 0.0,     # NO horizontal flip
            'mosaic': 0.0,     # NO mosaic
            'mixup': 0.0,      # NO mixup
            'copy_paste': 0.0  # NO copy paste
        }
        
        # Training dataloader - ‰ΩøÁî®ÁµïÂ∞çË∑ØÂæë
        train_path = self.data_dict['train']
        if not train_path.startswith('/'):
            train_path = str(Path(self.data_dict['path']) / train_path)
        
        self.train_loader, _ = create_dataloader(
            path=train_path,
            imgsz=self.opt.imgsz,
            batch_size=self.opt.batch_size,
            stride=32,
            single_cls=False,
            hyp=hyp_no_aug,
            augment=False,  # ÊòéÁ¢∫ÈóúÈñâÊï∏ÊìöÊì¥Â¢û
            cache=False,
            pad=0.0,
            rect=False,
            rank=-1,
            workers=self.opt.workers,
            image_weights=False,
            quad=False,
            prefix=colorstr('train: '),
            shuffle=True
        )
        
        # Validation dataloader - ‰ΩøÁî®ÁµïÂ∞çË∑ØÂæë
        val_path = self.data_dict['val']
        if not val_path.startswith('/'):
            val_path = str(Path(self.data_dict['path']) / val_path)
            
        self.val_loader, _ = create_dataloader(
            path=val_path,
            imgsz=self.opt.imgsz,
            batch_size=self.opt.batch_size,
            stride=32,
            single_cls=False,
            hyp=hyp_no_aug,
            augment=False,  # È©óË≠â‰πü‰∏ç‰ΩøÁî®Êï∏ÊìöÊì¥Â¢û
            cache=False,
            pad=0.0,
            rect=True,
            rank=-1,
            workers=self.opt.workers,
            image_weights=False,
            quad=False,
            prefix=colorstr('val: '),
            shuffle=False
        )
        
        self.logger.info(f"Training samples: {len(self.train_loader.dataset)}")
        self.logger.info(f"Validation samples: {len(self.val_loader.dataset)}")
        self.logger.info("Êï∏ÊìöÊì¥Â¢ûÂ∑≤ÂÆåÂÖ®ÈóúÈñâ - ‰øùÊåÅÈÜ´Â≠∏ÂúñÂÉèÂéüÂßãÁâπÂæµ")
    
    def init_gradnorm(self):
        """Initialize GradNorm loss function"""
        # Detection loss function
        self.detection_loss_fn = ComputeLoss(self.model)
        
        # Classification loss function
        self.classification_loss_fn = nn.CrossEntropyLoss()
        
        # GradNorm loss
        self.gradnorm_loss = AdaptiveGradNormLoss(
            detection_loss_fn=self.detection_loss_fn,
            classification_loss_fn=self.classification_loss_fn,
            alpha=self.opt.gradnorm_alpha,
            momentum=0.9,
            min_weight=0.001,
            max_weight=10.0
        )
        
        # Optimizer - include classification head parameters
        model_params = list(self.model.parameters()) + list(self.classification_head.parameters())
        self.optimizer = optim.SGD(model_params, lr=0.01, momentum=0.937, weight_decay=5e-4)
        
        # Learning rate scheduler
        self.scheduler = optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max=self.opt.epochs)
        
        self.logger.info("GradNorm loss initialized with adaptive weight balancing")
    
    def init_tracking(self):
        """Initialize training tracking variables"""
        self.train_losses = []
        self.val_losses = []
        self.detection_losses = []
        self.classification_losses = []
        self.detection_weights = []
        self.classification_weights = []
        self.learning_rates = []
        self.best_fitness = 0.0
        self.start_epoch = 0
        
        # ÈóúÈçµÔºöNO EARLY STOPPING - ÂÆåÊï¥Ë®ìÁ∑¥ÂúñË°®
        self.patience = float('inf')  # ÁÑ°ÈôêËÄêÂøÉÔºå‰∏çÊúÉÊó©ÂÅú
        self.logger.info("Êó©ÂÅúÊ©üÂà∂Â∑≤ÈóúÈñâ - Â∞áÁç≤ÂæóÂÆåÊï¥ÁöÑË®ìÁ∑¥ÂúñË°®ÂíåË±êÂØåÁöÑÂàÜÊûêÊï∏Êìö")
    
    def log_config(self):
        """Log training configuration"""
        self.logger.info("=" * 60)
        self.logger.info("YOLOv5WithClassification ËÅØÂêàË®ìÁ∑¥ÈÖçÁΩÆ")
        self.logger.info("=" * 60)
        self.logger.info(f"ÂàÜÈ°ûÂäüËÉΩÂïüÁî®: {self.opt.classification_enabled}")
        self.logger.info(f"ÂàÜÈ°ûÊ¨äÈáç: {self.opt.classification_weight}")
        self.logger.info(f"Êº∏ÈÄ≤ÂºèË®ìÁ∑¥: {self.opt.progressive_training}")
        self.logger.info(f"Êï∏ÊìöÊì¥Â¢û: ÂÆåÂÖ®ÈóúÈñâ (ÈÜ´Â≠∏ÂúñÂÉèÁâπÊÆäË¶ÅÊ±Ç)")
        self.logger.info(f"Êó©ÂÅúÊ©üÂà∂: ÈóúÈñâ (Áç≤ÂæóÂÆåÊï¥Ë®ìÁ∑¥ÂúñË°®)")
        self.logger.info(f"Ë®ìÁ∑¥ÈÄ±Êúü: {self.opt.epochs}")
        self.logger.info(f"ÊâπÊ¨°Â§ßÂ∞è: {self.opt.batch_size}")
        self.logger.info(f"ÂúñÂÉèÂ§ßÂ∞è: {self.opt.imgsz}")
        self.logger.info(f"Ë®≠ÂÇô: {self.device}")
        self.logger.info(f"GradNorm Alpha: {self.opt.gradnorm_alpha}")
        self.logger.info("=" * 60)
    
    def forward_pass(self, imgs):
        """Forward pass through model"""
        # Detection forward
        detection_outputs = self.model(imgs)
        
        # For classification, we need to extract intermediate features
        # Use a simpler approach by hooking into the model's intermediate outputs
        # Get features from the neck/head area for classification
        if isinstance(detection_outputs, list) and len(detection_outputs) > 0:
            # Use the smallest feature map (highest resolution) for classification
            # This is typically the first output in YOLOv5
            detection_feature = detection_outputs[0]  # Shape: [batch, 3, H, W, 9]
            
            # Reshape to get spatial features for classification
            # Take the first anchor's features
            batch_size = detection_feature.shape[0]
            H, W = detection_feature.shape[2], detection_feature.shape[3]
            
            # Extract features - use average pooling across spatial dimensions
            # and take first 128 channels for classification
            p3_features = detection_feature[:, 0, :, :, :5]  # [batch, H, W, 5]
            p3_features = p3_features.permute(0, 3, 1, 2)   # [batch, 5, H, W]
            
            # Expand to 128 channels by repeating
            p3_features = p3_features.repeat(1, 25, 1, 1)[:, :128, :, :]  # [batch, 128, H, W]
        else:
            # Fallback: create dummy features
            batch_size = imgs.shape[0]
            p3_features = torch.randn(batch_size, 128, 20, 20).to(self.device)
        
        # Classification forward
        classification_outputs = self.classification_head(p3_features)
        
        return detection_outputs, classification_outputs
    
    def generate_classification_targets(self, batch_size):
        """Generate dummy classification targets"""
        # For demonstration, generate random targets
        # In real implementation, these should come from your dataset
        return torch.randint(0, self.nc_classification, (batch_size,)).to(self.device)
    
    def train_epoch(self, epoch):
        """Train one epoch"""
        self.model.train()
        self.classification_head.train()
        
        epoch_loss = 0.0
        epoch_detection_loss = 0.0
        epoch_classification_loss = 0.0
        
        for batch_i, batch in enumerate(self.train_loader):
            # Handle different batch formats
            if len(batch) >= 2:
                imgs, targets = batch[0], batch[1]
            else:
                imgs, targets = batch, None
                
            imgs = imgs.to(self.device, non_blocking=True).float() / 255.0
            
            if targets is not None:
                targets = targets.to(self.device)
            
            # Forward pass
            detection_outputs, classification_outputs = self.forward_pass(imgs)
            
            # Generate classification targets
            classification_targets = self.generate_classification_targets(imgs.shape[0])
            
            # Compute loss with GradNorm
            total_loss, loss_info = self.gradnorm_loss(
                detection_outputs, classification_outputs,
                targets, classification_targets
            )
            
            # Backward pass
            self.optimizer.zero_grad()
            total_loss.backward()
            self.optimizer.step()
            
            # Update tracking
            epoch_loss += total_loss.item()
            epoch_detection_loss += loss_info['detection_loss']
            epoch_classification_loss += loss_info['classification_loss']
            
            # Log progress
            if batch_i % 50 == 0:
                self.logger.info(
                    f"Epoch {epoch}/{self.opt.epochs}, Batch {batch_i}/{len(self.train_loader)}, "
                    f"Loss: {total_loss.item():.4f}, "
                    f"Det: {loss_info['detection_loss']:.4f}, "
                    f"Cls: {loss_info['classification_loss']:.4f}, "
                    f"DetW: {loss_info['detection_weight']:.4f}, "
                    f"ClsW: {loss_info['classification_weight']:.4f}"
                )
        
        # Update scheduler
        self.scheduler.step()
        
        # Store epoch results
        avg_loss = epoch_loss / len(self.train_loader)
        avg_detection_loss = epoch_detection_loss / len(self.train_loader)
        avg_classification_loss = epoch_classification_loss / len(self.train_loader)
        
        self.train_losses.append(avg_loss)
        self.detection_losses.append(avg_detection_loss)
        self.classification_losses.append(avg_classification_loss)
        self.detection_weights.append(self.gradnorm_loss.detection_weight.item())
        self.classification_weights.append(self.gradnorm_loss.classification_weight.item())
        self.learning_rates.append(self.optimizer.param_groups[0]['lr'])
        
        return avg_loss
    
    def validate(self, epoch):
        """Validate model"""
        self.model.eval()
        self.classification_head.eval()
        
        val_loss = 0.0
        
        with torch.no_grad():
            for batch_i, batch in enumerate(self.val_loader):
                if len(batch) >= 2:
                    imgs, targets = batch[0], batch[1]
                else:
                    imgs, targets = batch, None
                    
                imgs = imgs.to(self.device, non_blocking=True).float() / 255.0
                
                if targets is not None:
                    targets = targets.to(self.device)
                
                # Forward pass
                detection_outputs, classification_outputs = self.forward_pass(imgs)
                
                # Generate classification targets
                classification_targets = self.generate_classification_targets(imgs.shape[0])
                
                # Compute loss
                total_loss, _ = self.gradnorm_loss(
                    detection_outputs, classification_outputs,
                    targets, classification_targets
                )
                
                val_loss += total_loss.item()
        
        avg_val_loss = val_loss / len(self.val_loader)
        self.val_losses.append(avg_val_loss)
        
        return avg_val_loss
    
    def save_checkpoint(self, epoch, is_best=False):
        """Save model checkpoint"""
        checkpoint = {
            'epoch': epoch,
            'model_state_dict': self.model.state_dict(),
            'classification_head_state_dict': self.classification_head.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'scheduler_state_dict': self.scheduler.state_dict(),
            'gradnorm_state_dict': self.gradnorm_loss.state_dict(),
            'best_fitness': self.best_fitness,
            'train_losses': self.train_losses,
            'val_losses': self.val_losses,
            'detection_losses': self.detection_losses,
            'classification_losses': self.classification_losses,
            'detection_weights': self.detection_weights,
            'classification_weights': self.classification_weights,
            'opt': self.opt
        }
        
        # Save latest checkpoint
        latest_path = self.save_dir / 'latest.pt'
        torch.save(checkpoint, latest_path)
        
        # Save best checkpoint
        if is_best:
            best_path = self.save_dir / 'best.pt'
            torch.save(checkpoint, best_path)
            self.logger.info(f"Best model saved to {best_path}")
        
        # Save periodic checkpoints
        if epoch % self.opt.save_period == 0:
            period_path = self.save_dir / f'epoch_{epoch}.pt'
            torch.save(checkpoint, period_path)
    
    def plot_training_results(self):
        """Plot comprehensive training results"""
        epochs_range = range(1, len(self.train_losses) + 1)
        
        # Create comprehensive plots
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        fig.suptitle('YOLOv5WithClassification GradNorm ËÅØÂêàË®ìÁ∑¥ÁµêÊûú', fontsize=16)
        
        # Loss curves
        axes[0,0].plot(epochs_range, self.train_losses, 'b-', label='Training Loss')
        axes[0,0].plot(epochs_range, self.val_losses, 'r-', label='Validation Loss')
        axes[0,0].set_title('Á∏ΩÊêçÂ§±Êõ≤Á∑ö')
        axes[0,0].set_xlabel('Epoch')
        axes[0,0].set_ylabel('Loss')
        axes[0,0].legend()
        axes[0,0].grid(True)
        
        # Individual task losses
        axes[0,1].plot(epochs_range, self.detection_losses, 'g-', label='Detection Loss')
        axes[0,1].plot(epochs_range, self.classification_losses, 'm-', label='Classification Loss')
        axes[0,1].set_title('Ê™¢Ê∏¨ËàáÂàÜÈ°ûÊêçÂ§±')
        axes[0,1].set_xlabel('Epoch')
        axes[0,1].set_ylabel('Loss')
        axes[0,1].legend()
        axes[0,1].grid(True)
        
        # GradNorm weights
        axes[0,2].plot(epochs_range, self.detection_weights, 'b-', label='Detection Weight')
        axes[0,2].plot(epochs_range, self.classification_weights, 'r-', label='Classification Weight')
        axes[0,2].set_title('GradNorm ÂãïÊÖãÊ¨äÈáçË™øÊï¥')
        axes[0,2].set_xlabel('Epoch')
        axes[0,2].set_ylabel('Weight')
        axes[0,2].legend()
        axes[0,2].grid(True)
        
        # Learning rate
        axes[1,0].plot(epochs_range, self.learning_rates, 'orange', label='Learning Rate')
        axes[1,0].set_title('Â≠∏ÁøíÁéáËÆäÂåñ')
        axes[1,0].set_xlabel('Epoch')
        axes[1,0].set_ylabel('Learning Rate')
        axes[1,0].legend()
        axes[1,0].grid(True)
        
        # Weight ratio
        weight_ratios = [d/c if c > 0 else 0 for d, c in zip(self.detection_weights, self.classification_weights)]
        axes[1,1].plot(epochs_range, weight_ratios, 'purple', label='Detection/Classification Weight Ratio')
        axes[1,1].set_title('Ê¨äÈáçÊØî‰æãËÆäÂåñ')
        axes[1,1].set_xlabel('Epoch')
        axes[1,1].set_ylabel('Ratio')
        axes[1,1].legend()
        axes[1,1].grid(True)
        
        # Training summary
        axes[1,2].text(0.1, 0.9, f'ÊúÄÁµÇË®ìÁ∑¥ÊêçÂ§±: {self.train_losses[-1]:.4f}', transform=axes[1,2].transAxes)
        axes[1,2].text(0.1, 0.8, f'ÊúÄÁµÇÈ©óË≠âÊêçÂ§±: {self.val_losses[-1]:.4f}', transform=axes[1,2].transAxes)
        axes[1,2].text(0.1, 0.7, f'Ê™¢Ê∏¨Ê¨äÈáç: {self.detection_weights[-1]:.4f}', transform=axes[1,2].transAxes)
        axes[1,2].text(0.1, 0.6, f'ÂàÜÈ°ûÊ¨äÈáç: {self.classification_weights[-1]:.4f}', transform=axes[1,2].transAxes)
        axes[1,2].text(0.1, 0.5, f'Á∏ΩË®ìÁ∑¥ÈÄ±Êúü: {len(self.train_losses)}', transform=axes[1,2].transAxes)
        axes[1,2].text(0.1, 0.4, 'Êó©ÂÅú: ÈóúÈñâ', transform=axes[1,2].transAxes)
        axes[1,2].text(0.1, 0.3, 'Êï∏ÊìöÊì¥Â¢û: ÈóúÈñâ', transform=axes[1,2].transAxes)
        axes[1,2].set_title('Ë®ìÁ∑¥Á∏ΩÁµê')
        axes[1,2].axis('off')
        
        plt.tight_layout()
        
        # Save plot
        plot_path = self.save_dir / 'training_results.png'
        plt.savefig(plot_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        self.logger.info(f"Training results plot saved to {plot_path}")
    
    def save_training_summary(self):
        """Save detailed training summary"""
        summary = {
            'training_config': {
                'epochs': self.opt.epochs,
                'batch_size': self.opt.batch_size,
                'image_size': self.opt.imgsz,
                'device': str(self.device),
                'classification_enabled': True,
                'classification_weight': self.opt.classification_weight,
                'gradnorm_alpha': self.opt.gradnorm_alpha,
                'data_augmentation': 'DISABLED (ÈÜ´Â≠∏ÂúñÂÉèÁâπÊÆäË¶ÅÊ±Ç)',
                'early_stopping': 'DISABLED (ÂÆåÊï¥Ë®ìÁ∑¥ÂúñË°®)',
                'progressive_training': self.opt.progressive_training
            },
            'final_results': {
                'final_train_loss': self.train_losses[-1],
                'final_val_loss': self.val_losses[-1],
                'final_detection_loss': self.detection_losses[-1],
                'final_classification_loss': self.classification_losses[-1],
                'final_detection_weight': self.detection_weights[-1],
                'final_classification_weight': self.classification_weights[-1],
                'best_fitness': self.best_fitness
            },
            'gradnorm_analysis': {
                'weight_adaptation': {
                    'detection_weight_change': f"{self.detection_weights[0]:.4f} -> {self.detection_weights[-1]:.4f}",
                    'classification_weight_change': f"{self.classification_weights[0]:.4f} -> {self.classification_weights[-1]:.4f}",
                    'weight_ratio_final': self.detection_weights[-1] / self.classification_weights[-1] if self.classification_weights[-1] > 0 else 0
                },
                'loss_improvement': {
                    'detection_loss_change': f"{self.detection_losses[0]:.4f} -> {self.detection_losses[-1]:.4f}",
                    'classification_loss_change': f"{self.classification_losses[0]:.4f} -> {self.classification_losses[-1]:.4f}"
                }
            },
            'training_history': {
                'train_losses': self.train_losses,
                'val_losses': self.val_losses,
                'detection_losses': self.detection_losses,
                'classification_losses': self.classification_losses,
                'detection_weights': self.detection_weights,
                'classification_weights': self.classification_weights,
                'learning_rates': self.learning_rates
            }
        }
        
        # Save summary
        summary_path = self.save_dir / 'training_summary.json'
        with open(summary_path, 'w', encoding='utf-8') as f:
            json.dump(summary, f, indent=2, ensure_ascii=False)
        
        self.logger.info(f"Training summary saved to {summary_path}")
        
        return summary
    
    def train(self):
        """Main training loop"""
        self.logger.info("ÈñãÂßã YOLOv5WithClassification GradNorm ËÅØÂêàË®ìÁ∑¥")
        self.logger.info("=" * 60)
        
        for epoch in range(self.start_epoch, self.opt.epochs):
            # Training
            train_loss = self.train_epoch(epoch)
            
            # Validation
            val_loss = self.validate(epoch)
            
            # Log epoch results
            self.logger.info(
                f"Epoch {epoch}/{self.opt.epochs}: "
                f"Train Loss: {train_loss:.4f}, "
                f"Val Loss: {val_loss:.4f}, "
                f"Det Weight: {self.detection_weights[-1]:.4f}, "
                f"Cls Weight: {self.classification_weights[-1]:.4f}, "
                f"LR: {self.learning_rates[-1]:.6f}"
            )
            
            # Save checkpoint
            is_best = val_loss < self.best_fitness if self.best_fitness != 0.0 else True
            if is_best:
                self.best_fitness = val_loss
            
            self.save_checkpoint(epoch, is_best)
            
            # Plot intermediate results every 10 epochs
            if (epoch + 1) % 10 == 0:
                self.plot_training_results()
        
        # Final results
        self.logger.info("=" * 60)
        self.logger.info("Ë®ìÁ∑¥ÂÆåÊàêÔºÅ")
        self.logger.info("=" * 60)
        
        # Generate final plots and summary
        self.plot_training_results()
        summary = self.save_training_summary()
        
        # Log final summary
        self.logger.info("ÊúÄÁµÇÁµêÊûúÁ∏ΩÁµê:")
        self.logger.info(f"- Ë®ìÁ∑¥ÊêçÂ§±: {self.train_losses[-1]:.4f}")
        self.logger.info(f"- È©óË≠âÊêçÂ§±: {self.val_losses[-1]:.4f}")
        self.logger.info(f"- Ê™¢Ê∏¨Ê¨äÈáç: {self.detection_weights[-1]:.4f}")
        self.logger.info(f"- ÂàÜÈ°ûÊ¨äÈáç: {self.classification_weights[-1]:.4f}")
        self.logger.info(f"- GradNorm Ê¨äÈáçË™øÊï¥ÊØî‰æã: {(self.detection_weights[-1]/self.detection_weights[0]):.2f}x")
        self.logger.info("- Êó©ÂÅúÊ©üÂà∂: ÈóúÈñâ (ÂÆåÊï¥Ë®ìÁ∑¥ÂúñË°®)")
        self.logger.info("- Êï∏ÊìöÊì¥Â¢û: ÈóúÈñâ (ÈÜ´Â≠∏ÂúñÂÉèÂéüÂßãÁâπÂæµ)")
        self.logger.info("=" * 60)
        
        return summary

def main():
    opt = parse_opt()
    
    # Create trainer
    trainer = JointGradNormTrainer(opt)
    
    # Start training
    summary = trainer.train()
    
    print("\nüéâ GradNorm ËÅØÂêàË®ìÁ∑¥ÊàêÂäüÂÆåÊàêÔºÅ")
    print(f"ÁµêÊûú‰øùÂ≠òÂú®: {trainer.save_dir}")
    
    return summary

if __name__ == '__main__':
    main() 