Get:1 http://archive.ubuntu.com/ubuntu focal InRelease [265 kB]
Get:2 http://security.ubuntu.com/ubuntu focal-security InRelease [128 kB]
Get:3 http://archive.ubuntu.com/ubuntu focal-updates InRelease [128 kB]
Get:4 http://security.ubuntu.com/ubuntu focal-security/multiverse amd64 Packages [33.1 kB]
Get:5 http://archive.ubuntu.com/ubuntu focal-backports InRelease [128 kB]
Get:6 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [1308 kB]
Get:7 http://archive.ubuntu.com/ubuntu focal/universe amd64 Packages [11.3 MB]
Get:8 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [4431 kB]
Get:9 http://security.ubuntu.com/ubuntu focal-security/restricted amd64 Packages [4801 kB]
Get:10 http://archive.ubuntu.com/ubuntu focal/main amd64 Packages [1275 kB]
Get:11 http://archive.ubuntu.com/ubuntu focal/restricted amd64 Packages [33.4 kB]
Get:12 http://archive.ubuntu.com/ubuntu focal/multiverse amd64 Packages [177 kB]
Get:13 http://archive.ubuntu.com/ubuntu focal-updates/multiverse amd64 Packages [36.8 kB]
Get:14 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [4919 kB]
Get:15 http://archive.ubuntu.com/ubuntu focal-updates/restricted amd64 Packages [4998 kB]
Get:16 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1599 kB]
Get:17 http://archive.ubuntu.com/ubuntu focal-backports/main amd64 Packages [55.2 kB]
Get:18 http://archive.ubuntu.com/ubuntu focal-backports/universe amd64 Packages [28.6 kB]
Fetched 35.7 MB in 5s (7108 kB/s)
Reading package lists...
Reading package lists...
Building dependency tree...
Reading state information...
The following additional packages will be installed:
  libdrm-amdgpu1 libdrm-common libdrm-intel1 libdrm-nouveau2 libdrm-radeon1
  libdrm2 libelf1 libgl1-mesa-dri libglapi-mesa libglvnd0 libglx-mesa0 libglx0
  libllvm12 libpciaccess0 libsensors-config libsensors5 libvulkan1
  libwayland-client0 libx11-xcb1 libxcb-dri2-0 libxcb-dri3-0 libxcb-glx0
  libxcb-present0 libxcb-randr0 libxcb-shm0 libxcb-sync1 libxcb-xfixes0
  libxfixes3 libxshmfence1 libxxf86vm1 mesa-vulkan-drivers
Suggested packages:
  pciutils lm-sensors
The following NEW packages will be installed:
  libdrm-amdgpu1 libdrm-common libdrm-intel1 libdrm-nouveau2 libdrm-radeon1
  libdrm2 libelf1 libgl1 libgl1-mesa-dri libglapi-mesa libglvnd0 libglx-mesa0
  libglx0 libllvm12 libpciaccess0 libsensors-config libsensors5 libvulkan1
  libwayland-client0 libx11-xcb1 libxcb-dri2-0 libxcb-dri3-0 libxcb-glx0
  libxcb-present0 libxcb-randr0 libxcb-shm0 libxcb-sync1 libxcb-xfixes0
  libxfixes3 libxshmfence1 libxxf86vm1 mesa-vulkan-drivers
0 upgraded, 32 newly installed, 0 to remove and 199 not upgraded.
Need to get 36.4 MB of archives.
After this operation, 525 MB of additional disk space will be used.
Get:1 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libelf1 amd64 0.176-1.1ubuntu0.1 [44.2 kB]
Get:2 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libdrm-common all 2.4.107-8ubuntu1~20.04.2 [5396 B]
Get:3 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libdrm2 amd64 2.4.107-8ubuntu1~20.04.2 [34.1 kB]
Get:4 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libdrm-amdgpu1 amd64 2.4.107-8ubuntu1~20.04.2 [18.6 kB]
Get:5 http://archive.ubuntu.com/ubuntu focal/main amd64 libpciaccess0 amd64 0.16-0ubuntu1 [17.9 kB]
Get:6 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libdrm-intel1 amd64 2.4.107-8ubuntu1~20.04.2 [60.3 kB]
Get:7 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libdrm-nouveau2 amd64 2.4.107-8ubuntu1~20.04.2 [16.6 kB]
Get:8 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libdrm-radeon1 amd64 2.4.107-8ubuntu1~20.04.2 [19.7 kB]
Get:9 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libglapi-mesa amd64 21.2.6-0ubuntu0.1~20.04.2 [27.4 kB]
Get:10 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libllvm12 amd64 1:12.0.0-3ubuntu1~20.04.5 [18.8 MB]
Get:11 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libsensors-config all 1:3.6.0-2ubuntu1.1 [6052 B]
Get:12 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libsensors5 amd64 1:3.6.0-2ubuntu1.1 [27.2 kB]
Get:13 http://archive.ubuntu.com/ubuntu focal/main amd64 libvulkan1 amd64 1.2.131.2-1 [93.3 kB]
Get:14 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libgl1-mesa-dri amd64 21.2.6-0ubuntu0.1~20.04.2 [11.0 MB]
Get:15 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libx11-xcb1 amd64 2:1.6.9-2ubuntu1.6 [9448 B]
Get:16 http://archive.ubuntu.com/ubuntu focal/main amd64 libxcb-dri2-0 amd64 1.14-2 [6920 B]
Get:17 http://archive.ubuntu.com/ubuntu focal/main amd64 libxcb-dri3-0 amd64 1.14-2 [6552 B]
Get:18 http://archive.ubuntu.com/ubuntu focal/main amd64 libxcb-glx0 amd64 1.14-2 [22.1 kB]
Get:19 http://archive.ubuntu.com/ubuntu focal/main amd64 libxcb-present0 amd64 1.14-2 [5560 B]
Get:20 http://archive.ubuntu.com/ubuntu focal/main amd64 libxcb-shm0 amd64 1.14-2 [5584 B]
Get:21 http://archive.ubuntu.com/ubuntu focal/main amd64 libxcb-sync1 amd64 1.14-2 [8884 B]
Get:22 http://archive.ubuntu.com/ubuntu focal/main amd64 libxcb-xfixes0 amd64 1.14-2 [9296 B]
Get:23 http://archive.ubuntu.com/ubuntu focal/main amd64 libxfixes3 amd64 1:5.0.3-2 [10.9 kB]
Get:24 http://archive.ubuntu.com/ubuntu focal/main amd64 libxshmfence1 amd64 1.3-1 [5028 B]
Get:25 http://archive.ubuntu.com/ubuntu focal/main amd64 libxxf86vm1 amd64 1:1.1.4-1build1 [10.2 kB]
Get:26 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libglx-mesa0 amd64 21.2.6-0ubuntu0.1~20.04.2 [137 kB]
Get:27 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libwayland-client0 amd64 1.18.0-1ubuntu0.1 [23.9 kB]
Get:28 http://archive.ubuntu.com/ubuntu focal/main amd64 libxcb-randr0 amd64 1.14-2 [16.3 kB]
Get:29 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 mesa-vulkan-drivers amd64 21.2.6-0ubuntu0.1~20.04.2 [5788 kB]
Get:30 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libglvnd0 amd64 1.3.2-1~ubuntu0.20.04.2 [48.1 kB]
Get:31 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libglx0 amd64 1.3.2-1~ubuntu0.20.04.2 [32.5 kB]
Get:32 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libgl1 amd64 1.3.2-1~ubuntu0.20.04.2 [85.8 kB]
debconf: unable to initialize frontend: Dialog
debconf: (Dialog frontend will not work on a dumb terminal, an emacs shell buffer, or without a controlling terminal.)
debconf: falling back to frontend: Readline
debconf: unable to initialize frontend: Readline
debconf: (This frontend requires a controlling tty.)
debconf: falling back to frontend: Teletype
dpkg-preconfigure: unable to re-open stdin: 
Fetched 36.4 MB in 4s (8418 kB/s)
Selecting previously unselected package libelf1:amd64.
(Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 40531 files and directories currently installed.)
Preparing to unpack .../00-libelf1_0.176-1.1ubuntu0.1_amd64.deb ...
Unpacking libelf1:amd64 (0.176-1.1ubuntu0.1) ...
Selecting previously unselected package libdrm-common.
Preparing to unpack .../01-libdrm-common_2.4.107-8ubuntu1~20.04.2_all.deb ...
Unpacking libdrm-common (2.4.107-8ubuntu1~20.04.2) ...
Selecting previously unselected package libdrm2:amd64.
Preparing to unpack .../02-libdrm2_2.4.107-8ubuntu1~20.04.2_amd64.deb ...
Unpacking libdrm2:amd64 (2.4.107-8ubuntu1~20.04.2) ...
Selecting previously unselected package libdrm-amdgpu1:amd64.
Preparing to unpack .../03-libdrm-amdgpu1_2.4.107-8ubuntu1~20.04.2_amd64.deb ...
Unpacking libdrm-amdgpu1:amd64 (2.4.107-8ubuntu1~20.04.2) ...
Selecting previously unselected package libpciaccess0:amd64.
Preparing to unpack .../04-libpciaccess0_0.16-0ubuntu1_amd64.deb ...
Unpacking libpciaccess0:amd64 (0.16-0ubuntu1) ...
Selecting previously unselected package libdrm-intel1:amd64.
Preparing to unpack .../05-libdrm-intel1_2.4.107-8ubuntu1~20.04.2_amd64.deb ...
Unpacking libdrm-intel1:amd64 (2.4.107-8ubuntu1~20.04.2) ...
Selecting previously unselected package libdrm-nouveau2:amd64.
Preparing to unpack .../06-libdrm-nouveau2_2.4.107-8ubuntu1~20.04.2_amd64.deb ...
Unpacking libdrm-nouveau2:amd64 (2.4.107-8ubuntu1~20.04.2) ...
Selecting previously unselected package libdrm-radeon1:amd64.
Preparing to unpack .../07-libdrm-radeon1_2.4.107-8ubuntu1~20.04.2_amd64.deb ...
Unpacking libdrm-radeon1:amd64 (2.4.107-8ubuntu1~20.04.2) ...
Selecting previously unselected package libglapi-mesa:amd64.
Preparing to unpack .../08-libglapi-mesa_21.2.6-0ubuntu0.1~20.04.2_amd64.deb ...
Unpacking libglapi-mesa:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...
Selecting previously unselected package libllvm12:amd64.
Preparing to unpack .../09-libllvm12_1%3a12.0.0-3ubuntu1~20.04.5_amd64.deb ...
Unpacking libllvm12:amd64 (1:12.0.0-3ubuntu1~20.04.5) ...
Selecting previously unselected package libsensors-config.
Preparing to unpack .../10-libsensors-config_1%3a3.6.0-2ubuntu1.1_all.deb ...
Unpacking libsensors-config (1:3.6.0-2ubuntu1.1) ...
Selecting previously unselected package libsensors5:amd64.
Preparing to unpack .../11-libsensors5_1%3a3.6.0-2ubuntu1.1_amd64.deb ...
Unpacking libsensors5:amd64 (1:3.6.0-2ubuntu1.1) ...
Selecting previously unselected package libvulkan1:amd64.
Preparing to unpack .../12-libvulkan1_1.2.131.2-1_amd64.deb ...
Unpacking libvulkan1:amd64 (1.2.131.2-1) ...
Selecting previously unselected package libgl1-mesa-dri:amd64.
Preparing to unpack .../13-libgl1-mesa-dri_21.2.6-0ubuntu0.1~20.04.2_amd64.deb ...
Unpacking libgl1-mesa-dri:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...
Selecting previously unselected package libx11-xcb1:amd64.
Preparing to unpack .../14-libx11-xcb1_2%3a1.6.9-2ubuntu1.6_amd64.deb ...
Unpacking libx11-xcb1:amd64 (2:1.6.9-2ubuntu1.6) ...
Selecting previously unselected package libxcb-dri2-0:amd64.
Preparing to unpack .../15-libxcb-dri2-0_1.14-2_amd64.deb ...
Unpacking libxcb-dri2-0:amd64 (1.14-2) ...
Selecting previously unselected package libxcb-dri3-0:amd64.
Preparing to unpack .../16-libxcb-dri3-0_1.14-2_amd64.deb ...
Unpacking libxcb-dri3-0:amd64 (1.14-2) ...
Selecting previously unselected package libxcb-glx0:amd64.
Preparing to unpack .../17-libxcb-glx0_1.14-2_amd64.deb ...
Unpacking libxcb-glx0:amd64 (1.14-2) ...
Selecting previously unselected package libxcb-present0:amd64.
Preparing to unpack .../18-libxcb-present0_1.14-2_amd64.deb ...
Unpacking libxcb-present0:amd64 (1.14-2) ...
Selecting previously unselected package libxcb-shm0:amd64.
Preparing to unpack .../19-libxcb-shm0_1.14-2_amd64.deb ...
Unpacking libxcb-shm0:amd64 (1.14-2) ...
Selecting previously unselected package libxcb-sync1:amd64.
Preparing to unpack .../20-libxcb-sync1_1.14-2_amd64.deb ...
Unpacking libxcb-sync1:amd64 (1.14-2) ...
Selecting previously unselected package libxcb-xfixes0:amd64.
Preparing to unpack .../21-libxcb-xfixes0_1.14-2_amd64.deb ...
Unpacking libxcb-xfixes0:amd64 (1.14-2) ...
Selecting previously unselected package libxfixes3:amd64.
Preparing to unpack .../22-libxfixes3_1%3a5.0.3-2_amd64.deb ...
Unpacking libxfixes3:amd64 (1:5.0.3-2) ...
Selecting previously unselected package libxshmfence1:amd64.
Preparing to unpack .../23-libxshmfence1_1.3-1_amd64.deb ...
Unpacking libxshmfence1:amd64 (1.3-1) ...
Selecting previously unselected package libxxf86vm1:amd64.
Preparing to unpack .../24-libxxf86vm1_1%3a1.1.4-1build1_amd64.deb ...
Unpacking libxxf86vm1:amd64 (1:1.1.4-1build1) ...
Selecting previously unselected package libglx-mesa0:amd64.
Preparing to unpack .../25-libglx-mesa0_21.2.6-0ubuntu0.1~20.04.2_amd64.deb ...
Unpacking libglx-mesa0:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...
Selecting previously unselected package libwayland-client0:amd64.
Preparing to unpack .../26-libwayland-client0_1.18.0-1ubuntu0.1_amd64.deb ...
Unpacking libwayland-client0:amd64 (1.18.0-1ubuntu0.1) ...
Selecting previously unselected package libxcb-randr0:amd64.
Preparing to unpack .../27-libxcb-randr0_1.14-2_amd64.deb ...
Unpacking libxcb-randr0:amd64 (1.14-2) ...
Selecting previously unselected package mesa-vulkan-drivers:amd64.
Preparing to unpack .../28-mesa-vulkan-drivers_21.2.6-0ubuntu0.1~20.04.2_amd64.deb ...
Unpacking mesa-vulkan-drivers:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...
Selecting previously unselected package libglvnd0:amd64.
Preparing to unpack .../29-libglvnd0_1.3.2-1~ubuntu0.20.04.2_amd64.deb ...
Unpacking libglvnd0:amd64 (1.3.2-1~ubuntu0.20.04.2) ...
Selecting previously unselected package libglx0:amd64.
Preparing to unpack .../30-libglx0_1.3.2-1~ubuntu0.20.04.2_amd64.deb ...
Unpacking libglx0:amd64 (1.3.2-1~ubuntu0.20.04.2) ...
Selecting previously unselected package libgl1:amd64.
Preparing to unpack .../31-libgl1_1.3.2-1~ubuntu0.20.04.2_amd64.deb ...
Unpacking libgl1:amd64 (1.3.2-1~ubuntu0.20.04.2) ...
Setting up libxcb-dri3-0:amd64 (1.14-2) ...
Setting up libx11-xcb1:amd64 (2:1.6.9-2ubuntu1.6) ...
Setting up libpciaccess0:amd64 (0.16-0ubuntu1) ...
Setting up libxcb-xfixes0:amd64 (1.14-2) ...
Setting up libglvnd0:amd64 (1.3.2-1~ubuntu0.20.04.2) ...
Setting up libxcb-glx0:amd64 (1.14-2) ...
Setting up libsensors-config (1:3.6.0-2ubuntu1.1) ...
Setting up libxcb-shm0:amd64 (1.14-2) ...
Setting up libxxf86vm1:amd64 (1:1.1.4-1build1) ...
Setting up libxcb-present0:amd64 (1.14-2) ...
Setting up libxfixes3:amd64 (1:5.0.3-2) ...
Setting up libxcb-sync1:amd64 (1.14-2) ...
Setting up libllvm12:amd64 (1:12.0.0-3ubuntu1~20.04.5) ...
Setting up libsensors5:amd64 (1:3.6.0-2ubuntu1.1) ...
Setting up libglapi-mesa:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...
Setting up libvulkan1:amd64 (1.2.131.2-1) ...
Setting up libxcb-dri2-0:amd64 (1.14-2) ...
Setting up libxshmfence1:amd64 (1.3-1) ...
Setting up libxcb-randr0:amd64 (1.14-2) ...
Setting up libdrm-common (2.4.107-8ubuntu1~20.04.2) ...
Setting up libelf1:amd64 (0.176-1.1ubuntu0.1) ...
Setting up libwayland-client0:amd64 (1.18.0-1ubuntu0.1) ...
Setting up libdrm2:amd64 (2.4.107-8ubuntu1~20.04.2) ...
Setting up libdrm-amdgpu1:amd64 (2.4.107-8ubuntu1~20.04.2) ...
Setting up mesa-vulkan-drivers:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...
Setting up libdrm-nouveau2:amd64 (2.4.107-8ubuntu1~20.04.2) ...
Setting up libdrm-radeon1:amd64 (2.4.107-8ubuntu1~20.04.2) ...
Setting up libdrm-intel1:amd64 (2.4.107-8ubuntu1~20.04.2) ...
Setting up libgl1-mesa-dri:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...
Setting up libglx-mesa0:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...
Setting up libglx0:amd64 (1.3.2-1~ubuntu0.20.04.2) ...
Setting up libgl1:amd64 (1.3.2-1~ubuntu0.20.04.2) ...
Processing triggers for libc-bin (2.31-0ubuntu9.2) ...
Collecting pandas
  Downloading pandas-2.0.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)
Collecting tzdata>=2022.1
  Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)
Collecting pytz>=2020.1
  Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)
Collecting numpy>=1.20.3; python_version < "3.10"
  Downloading numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)
Collecting python-dateutil>=2.8.2
  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)
Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.14.0)
Installing collected packages: tzdata, pytz, numpy, python-dateutil, pandas
Successfully installed numpy-1.24.4 pandas-2.0.3 python-dateutil-2.9.0.post0 pytz-2025.2 tzdata-2025.2
Collecting seaborn
  Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)
Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.8/dist-packages (from seaborn) (2.0.3)
Collecting matplotlib!=3.6.1,>=3.4
  Downloading matplotlib-3.7.5-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (9.2 MB)
Requirement already satisfied: numpy!=1.24.0,>=1.20 in /usr/local/lib/python3.8/dist-packages (from seaborn) (1.24.4)
Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.2->seaborn) (2025.2)
Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.2->seaborn) (2025.2)
Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.2->seaborn) (2.9.0.post0)
Collecting kiwisolver>=1.0.1
  Downloading kiwisolver-1.4.7-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)
Collecting pyparsing>=2.3.1
  Downloading pyparsing-3.1.4-py3-none-any.whl (104 kB)
Collecting fonttools>=4.22.0
  Downloading fonttools-4.57.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)
Collecting importlib-resources>=3.2.0; python_version < "3.10"
  Downloading importlib_resources-6.4.5-py3-none-any.whl (36 kB)
Collecting cycler>=0.10
  Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)
Collecting contourpy>=1.0.1
  Downloading contourpy-1.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)
Collecting pillow>=6.2.0
  Downloading pillow-10.4.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)
Collecting packaging>=20.0
  Downloading packaging-25.0-py3-none-any.whl (66 kB)
Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas>=1.2->seaborn) (1.14.0)
Collecting zipp>=3.1.0; python_version < "3.10"
  Downloading zipp-3.20.2-py3-none-any.whl (9.2 kB)
Installing collected packages: kiwisolver, pyparsing, fonttools, zipp, importlib-resources, cycler, contourpy, pillow, packaging, matplotlib, seaborn
Successfully installed contourpy-1.1.1 cycler-0.12.1 fonttools-4.57.0 importlib-resources-6.4.5 kiwisolver-1.4.7 matplotlib-3.7.5 packaging-25.0 pillow-10.4.0 pyparsing-3.1.4 seaborn-0.13.2 zipp-3.20.2
[34m[1mtrain: [0mweights=, cfg=./models/yolov5sc.yaml, data=../Regurgitation-YOLODataset-1new/data.yaml, hyp=data/hyps/hyp.custom.yaml, epochs=300, batch_size=32, imgsz=416, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=yolov5s_test5, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest
YOLOv5 ðŸš€ 2025-6-11 Python-3.8.10 torch-2.1.0+cu121 CUDA:0 (Tesla V100-SXM2-32GB, 32501MiB)

[34m[1mhyperparameters: [0mclassification_weight=0.1, lr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=5.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.0606, cls=0.731, cls_pw=1.22, obj=1.3, obj_pw=0.79, iou_t=0.2, anchor_t=4.27, fl_gamma=1.5, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=5.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.0, mixup=0.0, copy_paste=0.0
[34m[1mComet: [0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 ðŸš€ runs in Comet
[34m[1mTensorBoard: [0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/

                 from  n    params  module                                  arguments                     
  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              
  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                
  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   
  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               
  4                -1  1    115712  models.common.C3                        [128, 128, 2]                 
  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              
  6                -1  1    625152  models.common.C3                        [256, 256, 3]                 
  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              
  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 
  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 
 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              
 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          
 12           [-1, 6]  1         0  models.common.Concat                    [1]                           
 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          
 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              
 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          
 16           [-1, 4]  1         0  models.common.Concat                    [1]                           
 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          
 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              
 19          [-1, 14]  1         0  models.common.Concat                    [1]                           
 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          
 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              
 22          [-1, 10]  1         0  models.common.Concat                    [1]                           
 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          
 24                17  1       387  models.common.YOLOv5WithClassification  [128, 3]                      
 25      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]
--- Debug: model forward outputs: 3 items ---
    Output 0 shape: [1, 3, 32, 32, 9]
    Output 1 shape: [1, 3, 16, 16, 9]
    Output 2 shape: [1, 3, 8, 8, 9]
--- Debug: computed strides = [8.0, 16.0, 32.0] ---
YOLOv5sc summary: 219 layers, 7030804 parameters, 7030804 gradients, 16.0 GFLOPs

[34m[1mgithub: [0mskipping check (not a git repository), for updates see https://github.com/ultralytics/yolov5
Layer 0: f=-1, ch=[3]
Checking f=-1 at layer i=0
Layer 1: f=-1, ch=[32]
Checking f=-1 at layer i=1
Layer 2: f=-1, ch=[32, 64]
Checking f=-1 at layer i=2
Layer 3: f=-1, ch=[32, 64, 64]
Checking f=-1 at layer i=3
Layer 4: f=-1, ch=[32, 64, 64, 128]
Checking f=-1 at layer i=4
Layer 5: f=-1, ch=[32, 64, 64, 128, 128]
Checking f=-1 at layer i=5
Layer 6: f=-1, ch=[32, 64, 64, 128, 128, 256]
Checking f=-1 at layer i=6
Layer 7: f=-1, ch=[32, 64, 64, 128, 128, 256, 256]
Checking f=-1 at layer i=7
Layer 8: f=-1, ch=[32, 64, 64, 128, 128, 256, 256, 512]
Checking f=-1 at layer i=8
Layer 9: f=-1, ch=[32, 64, 64, 128, 128, 256, 256, 512, 512]
Checking f=-1 at layer i=9
Layer 10: f=-1, ch=[32, 64, 64, 128, 128, 256, 256, 512, 512, 512]
Checking f=-1 at layer i=10
Layer 11: f=-1, ch=[32, 64, 64, 128, 128, 256, 256, 512, 512, 512, 256]
Checking f=-1 at layer i=11
Layer 12: f=[-1, 6], ch=[32, 64, 64, 128, 128, 256, 256, 512, 512, 512, 256, 256]
Checking list f=[-1, 6] at layer i=12
Layer 13: f=-1, ch=[32, 64, 64, 128, 128, 256, 256, 512, 512, 512, 256, 256, 512]
Checking f=-1 at layer i=13
Layer 14: f=-1, ch=[32, 64, 64, 128, 128, 256, 256, 512, 512, 512, 256, 256, 512, 256]
Checking f=-1 at layer i=14
Layer 15: f=-1, ch=[32, 64, 64, 128, 128, 256, 256, 512, 512, 512, 256, 256, 512, 256, 128]
Checking f=-1 at layer i=15
Layer 16: f=[-1, 4], ch=[32, 64, 64, 128, 128, 256, 256, 512, 512, 512, 256, 256, 512, 256, 128, 128]
Checking list f=[-1, 4] at layer i=16
Layer 17: f=-1, ch=[32, 64, 64, 128, 128, 256, 256, 512, 512, 512, 256, 256, 512, 256, 128, 128, 256]
Checking f=-1 at layer i=17
Layer 18: f=-1, ch=[32, 64, 64, 128, 128, 256, 256, 512, 512, 512, 256, 256, 512, 256, 128, 128, 256, 128]
Checking f=-1 at layer i=18
Layer 19: f=[-1, 14], ch=[32, 64, 64, 128, 128, 256, 256, 512, 512, 512, 256, 256, 512, 256, 128, 128, 256, 128, 128]
Checking list f=[-1, 14] at layer i=19
Layer 20: f=-1, ch=[32, 64, 64, 128, 128, 256, 256, 512, 512, 512, 256, 256, 512, 256, 128, 128, 256, 128, 128, 256]
Checking f=-1 at layer i=20
Layer 21: f=-1, ch=[32, 64, 64, 128, 128, 256, 256, 512, 512, 512, 256, 256, 512, 256, 128, 128, 256, 128, 128, 256, 256]
Checking f=-1 at layer i=21
Layer 22: f=[-1, 10], ch=[32, 64, 64, 128, 128, 256, 256, 512, 512, 512, 256, 256, 512, 256, 128, 128, 256, 128, 128, 256, 256, 256]
Checking list f=[-1, 10] at layer i=22
Layer 23: f=-1, ch=[32, 64, 64, 128, 128, 256, 256, 512, 512, 512, 256, 256, 512, 256, 128, 128, 256, 128, 128, 256, 256, 256, 512]
Checking f=-1 at layer i=23
Layer 24: f=17, ch=[32, 64, 64, 128, 128, 256, 256, 512, 512, 512, 256, 256, 512, 256, 128, 128, 256, 128, 128, 256, 256, 256, 512, 512]
Checking f=17 at layer i=24
Layer 25: f=[17, 20, 23], ch=[32, 64, 64, 128, 128, 256, 256, 512, 512, 512, 256, 256, 512, 256, 128, 128, 256, 128, 128, 256, 256, 256, 512, 512, 3]
Checking list f=[17, 20, 23] at layer i=25
Concat layer inputs: [torch.Size([1, 256, 16, 16]), torch.Size([1, 256, 16, 16])]
Concat layer inputs: [torch.Size([1, 128, 32, 32]), torch.Size([1, 128, 32, 32])]
Concat layer inputs: [torch.Size([1, 128, 16, 16]), torch.Size([1, 128, 16, 16])]
Concat layer inputs: [torch.Size([1, 256, 8, 8]), torch.Size([1, 256, 8, 8])]
Concat layer inputs: [torch.Size([1, 256, 16, 16]), torch.Size([1, 256, 16, 16])]
Concat layer inputs: [torch.Size([1, 128, 32, 32]), torch.Size([1, 128, 32, 32])]
Concat layer inputs: [torch.Size([1, 128, 16, 16]), torch.Size([1, 128, 16, 16])]
Concat layer inputs: [torch.Size([1, 256, 8, 8]), torch.Size([1, 256, 8, 8])]
Concat layer inputs: [torch.Size([1, 256, 2, 2]), torch.Size([1, 256, 2, 2])]
Concat layer inputs: [torch.Size([1, 128, 4, 4]), torch.Size([1, 128, 4, 4])]
Concat layer inputs: [torch.Size([1, 128, 2, 2]), torch.Size([1, 128, 2, 2])]
Concat layer inputs: [torch.Size([1, 256, 1, 1]), torch.Size([1, 256, 1, 1])]

[_make_grid Debug] i=0, nx=4, ny=4
[_make_grid Debug] stride: tensor([ 8., 16., 32.])
[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],
         [ 2.00000,  3.75000],
         [ 4.12500,  2.87500]],

        [[ 1.87500,  3.81250],
         [ 3.87500,  2.81250],
         [ 3.68750,  7.43750]],

        [[ 3.62500,  2.81250],
         [ 4.87500,  6.18750],
         [11.65625, 10.18750]]])
[_make_grid Debug] anchor index i => anchors[i]: tensor([[1.25000, 1.62500],
        [2.00000, 3.75000],
        [4.12500, 2.87500]])
self.anchors[i]: tensor([[1.25000, 1.62500],
        [2.00000, 3.75000],
        [4.12500, 2.87500]])
self.stride[i]: tensor(8.)

[_make_grid Debug] i=1, nx=2, ny=2
[_make_grid Debug] stride: tensor([ 8., 16., 32.])
[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],
         [ 2.00000,  3.75000],
         [ 4.12500,  2.87500]],

        [[ 1.87500,  3.81250],
         [ 3.87500,  2.81250],
         [ 3.68750,  7.43750]],

        [[ 3.62500,  2.81250],
         [ 4.87500,  6.18750],
         [11.65625, 10.18750]]])
[_make_grid Debug] anchor index i => anchors[i]: tensor([[1.87500, 3.81250],
        [3.87500, 2.81250],
        [3.68750, 7.43750]])
self.anchors[i]: tensor([[1.87500, 3.81250],
        [3.87500, 2.81250],
        [3.68750, 7.43750]])
self.stride[i]: tensor(16.)

[_make_grid Debug] i=2, nx=1, ny=1
[_make_grid Debug] stride: tensor([ 8., 16., 32.])
[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],
         [ 2.00000,  3.75000],
         [ 4.12500,  2.87500]],

        [[ 1.87500,  3.81250],
         [ 3.87500,  2.81250],
         [ 3.68750,  7.43750]],

        [[ 3.62500,  2.81250],
         [ 4.87500,  6.18750],
         [11.65625, 10.18750]]])
[_make_grid Debug] anchor index i => anchors[i]: tensor([[ 3.62500,  2.81250],
        [ 4.87500,  6.18750],
        [11.65625, 10.18750]])
self.anchors[i]: tensor([[ 3.62500,  2.81250],
        [ 4.87500,  6.18750],
        [11.65625, 10.18750]])
self.stride[i]: tensor(32.)
Concat layer inputs: [torch.Size([1, 256, 40, 30]), torch.Size([1, 256, 40, 30])]
Concat layer inputs: [torch.Size([1, 128, 80, 60]), torch.Size([1, 128, 80, 60])]
Concat layer inputs: [torch.Size([1, 128, 40, 30]), torch.Size([1, 128, 40, 30])]
Concat layer inputs: [torch.Size([1, 256, 20, 15]), torch.Size([1, 256, 20, 15])]

[_make_grid Debug] i=0, nx=60, ny=80
[_make_grid Debug] stride: tensor([ 8., 16., 32.], device='cuda:0')
[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],
         [ 2.00000,  3.75000],
         [ 4.12500,  2.87500]],

        [[ 1.87500,  3.81250],
         [ 3.87500,  2.81250],
         [ 3.68750,  7.43750]],

        [[ 3.62500,  2.81250],
         [ 4.87500,  6.18750],
         [11.65625, 10.18750]]], device='cuda:0')
[_make_grid Debug] anchor index i => anchors[i]: tensor([[1.25000, 1.62500],
        [2.00000, 3.75000],
        [4.12500, 2.87500]], device='cuda:0')
self.anchors[i]: tensor([[1.25000, 1.62500],
        [2.00000, 3.75000],
        [4.12500, 2.87500]], device='cuda:0')
self.stride[i]: tensor(8., device='cuda:0')

[_make_grid Debug] i=1, nx=30, ny=40
[_make_grid Debug] stride: tensor([ 8., 16., 32.], device='cuda:0')
[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],
         [ 2.00000,  3.75000],
         [ 4.12500,  2.87500]],

        [[ 1.87500,  3.81250],
         [ 3.87500,  2.81250],
         [ 3.68750,  7.43750]],

        [[ 3.62500,  2.81250],
         [ 4.87500,  6.18750],
         [11.65625, 10.18750]]], device='cuda:0')
[_make_grid Debug] anchor index i => anchors[i]: tensor([[1.87500, 3.81250],
        [3.87500, 2.81250],
        [3.68750, 7.43750]], device='cuda:0')
self.anchors[i]: tensor([[1.87500, 3.81250],
        [3.87500, 2.81250],
        [3.68750, 7.43750]], device='cuda:0')
self.stride[i]: tensor(16., device='cuda:0')

[_make_grid Debug] i=2, nx=15, ny=20
[_make_grid Debug] stride: tensor([ 8., 16., 32.], device='cuda:0')
[34m[1mAMP: [0mchecks passed âœ…
[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],
         [ 2.00000,  3.75000],
         [ 4.12500,  2.87500]],

        [[ 1.87500,  3.81250],
         [ 3.87500,  2.81250],
         [ 3.68750,  7.43750]],

        [[ 3.62500,  2.81250],
         [ 4.87500,  6.18750],
         [11.65625, 10.18750]]], device='cuda:0')
[_make_grid Debug] anchor index i => anchors[i]: tensor([[ 3.62500,  2.81250],
        [ 4.87500,  6.18750],
        [11.65625, 10.18750]], device='cuda:0')
self.anchors[i]: tensor([[ 3.62500,  2.81250],
        [ 4.87500,  6.18750],
        [11.65625, 10.18750]], device='cuda:0')
self.stride[i]: tensor(32., device='cuda:0')
Concat layer inputs: [torch.Size([1, 256, 40, 30]), torch.Size([1, 256, 40, 30])]
Concat layer inputs: [torch.Size([1, 128, 80, 60]), torch.Size([1, 128, 80, 60])]
Concat layer inputs: [torch.Size([1, 128, 40, 30]), torch.Size([1, 128, 40, 30])]
Concat layer inputs: [torch.Size([1, 256, 20, 15]), torch.Size([1, 256, 20, 15])]

Model architecture:

DetectionModel(
  (model): Sequential(
    (0): Conv(
      (conv): Conv2d(3, 32, kernel_size=(6, 6), stride=(2, 2), padding=(2, 2), bias=False)
      (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
      (act): SiLU(inplace=True)
    )
    (1): Conv(
      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
      (act): SiLU(inplace=True)
    )
    (2): C3(
      (cv1): Conv(
        (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
        (act): SiLU(inplace=True)
      )
      (cv2): Conv(
        (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
        (act): SiLU(inplace=True)
      )
      (cv3): Conv(
        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
        (act): SiLU(inplace=True)
      )
      (m): Sequential(
        (0): Bottleneck(
          (cv1): Conv(
            (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
            (act): SiLU(inplace=True)
          )
          (cv2): Conv(
            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
            (act): SiLU(inplace=True)
          )
        )
      )
    )
    (3): Conv(
      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
      (act): SiLU(inplace=True)
    )
    (4): C3(
      (cv1): Conv(
        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
        (act): SiLU(inplace=True)
      )
      (cv2): Conv(
        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
        (act): SiLU(inplace=True)
      )
      (cv3): Conv(
        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
        (act): SiLU(inplace=True)
      )
      (m): Sequential(
        (0): Bottleneck(
          (cv1): Conv(
            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
            (act): SiLU(inplace=True)
          )
          (cv2): Conv(
            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
            (act): SiLU(inplace=True)
          )
        )
        (1): Bottleneck(
          (cv1): Conv(
            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
            (act): SiLU(inplace=True)
          )
          (cv2): Conv(
            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
            (act): SiLU(inplace=True)
          )
        )
      )
    )
    (5): Conv(
      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
      (act): SiLU(inplace=True)
    )
    (6): C3(
      (cv1): Conv(
        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
        (act): SiLU(inplace=True)
      )
      (cv2): Conv(
        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
        (act): SiLU(inplace=True)
      )
      (cv3): Conv(
        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
        (act): SiLU(inplace=True)
      )
      (m): Sequential(
        (0): Bottleneck(
          (cv1): Conv(
            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
            (act): SiLU(inplace=True)
          )
          (cv2): Conv(
            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
            (act): SiLU(inplace=True)
          )
        )
        (1): Bottleneck(
          (cv1): Conv(
            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
            (act): SiLU(inplace=True)
          )
          (cv2): Conv(
            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
            (act): SiLU(inplace=True)
          )
        )
        (2): Bottleneck(
          (cv1): Conv(
            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
            (act): SiLU(inplace=True)
          )
          (cv2): Conv(
            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
            (act): SiLU(inplace=True)
          )
        )
      )
    )
    (7): Conv(
      (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
      (act): SiLU(inplace=True)
    )
    (8): C3(
      (cv1): Conv(
        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
        (act): SiLU(inplace=True)
      )
      (cv2): Conv(
        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
        (act): SiLU(inplace=True)
      )
      (cv3): Conv(
        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
        (act): SiLU(inplace=True)
      )
      (m): Sequential(
        (0): Bottleneck(
          (cv1): Conv(
            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
            (act): SiLU(inplace=True)
          )
          (cv2): Conv(
            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
            (act): SiLU(inplace=True)
          )
        )
      )
    )
[34m[1moptimizer:[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 61 weight(decay=0.0005), 61 bias
    (9): SPPF(
      (cv1): Conv(
        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
        (act): SiLU(inplace=True)
      )
      (cv2): Conv(
        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
        (act): SiLU(inplace=True)
      )
      (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)
    )
    (10): Conv(
      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
      (act): SiLU(inplace=True)
    )
    (11): Upsample(scale_factor=2.0, mode='nearest')
    (12): Concat()
    (13): C3(
      (cv1): Conv(
        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
        (act): SiLU(inplace=True)
      )
      (cv2): Conv(
        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
        (act): SiLU(inplace=True)
      )
      (cv3): Conv(
        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
        (act): SiLU(inplace=True)
      )
      (m): Sequential(
        (0): Bottleneck(
          (cv1): Conv(
            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
            (act): SiLU(inplace=True)
          )
          (cv2): Conv(
            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
            (act): SiLU(inplace=True)
          )
        )
      )
    )
    (14): Conv(
      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
      (act): SiLU(inplace=True)
    )
    (15): Upsample(scale_factor=2.0, mode='nearest')
    (16): Concat()
    (17): C3(
      (cv1): Conv(
        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
        (act): SiLU(inplace=True)
      )
      (cv2): Conv(
        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
        (act): SiLU(inplace=True)
      )
      (cv3): Conv(
        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
        (act): SiLU(inplace=True)
      )
      (m): Sequential(
        (0): Bottleneck(
          (cv1): Conv(
            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
            (act): SiLU(inplace=True)
          )
          (cv2): Conv(
            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
            (act): SiLU(inplace=True)
          )
        )
      )
    )
    (18): Conv(
      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
      (act): SiLU(inplace=True)
    )
    (19): Concat()
    (20): C3(
      (cv1): Conv(
        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
        (act): SiLU(inplace=True)
      )
      (cv2): Conv(
        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
        (act): SiLU(inplace=True)
      )
      (cv3): Conv(
        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
        (act): SiLU(inplace=True)
      )
      (m): Sequential(
        (0): Bottleneck(
          (cv1): Conv(
            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
            (act): SiLU(inplace=True)
          )
          (cv2): Conv(
            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
            (act): SiLU(inplace=True)
          )
        )
      )
    )
    (21): Conv(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
      (act): SiLU(inplace=True)
    )
    (22): Concat()
    (23): C3(
      (cv1): Conv(
        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
        (act): SiLU(inplace=True)
      )
      (cv2): Conv(
        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
        (act): SiLU(inplace=True)
      )
      (cv3): Conv(
        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
        (act): SiLU(inplace=True)
      )
      (m): Sequential(
        (0): Bottleneck(
          (cv1): Conv(
            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
            (act): SiLU(inplace=True)
          )
          (cv2): Conv(
            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
            (act): SiLU(inplace=True)
          )
        )
      )
    )
    (24): YOLOv5WithClassification(
      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (dropout): Dropout(p=0.2, inplace=False)
      (fc): Linear(in_features=128, out_features=3, bias=True)
    )
    (25): Detect(
      (m): ModuleList(
        (0): Conv2d(128, 27, kernel_size=(1, 1), stride=(1, 1))
        (1): Conv2d(256, 27, kernel_size=(1, 1), stride=(1, 1))
        (2): Conv2d(512, 27, kernel_size=(1, 1), stride=(1, 1))
      )
    )
  )
[34m[1malbumentations: [0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))
)

End of model architecture.

[34m[1mtrain: [0mScanning /work/jonchang3909/yolov5test/Regurgitation-YOLODataset-1new/train/labels.cache... 1042 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1042/1042 [00:00<?, ?it/s][34m[1mtrain: [0mScanning /work/jonchang3909/yolov5test/Regurgitation-YOLODataset-1new/train/labels.cache... 1042 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1042/1042 [00:00<?, ?it/s]
  0%|          | 0/1042 [00:00<?, ?it/s][34m[1mtrain: [0mCaching images (0.0GB ram):   2%|â–         | 24/1042 [00:00<00:04, 236.06it/s][34m[1mtrain: [0mCaching images (0.0GB ram):   6%|â–Œ         | 62/1042 [00:00<00:03, 311.71it/s][34m[1mtrain: [0mCaching images (0.0GB ram):  12%|â–ˆâ–        | 126/1042 [00:00<00:02, 432.72it/s][34m[1mtrain: [0mCaching images (0.1GB ram):  19%|â–ˆâ–‰        | 202/1042 [00:00<00:01, 552.27it/s][34m[1mtrain: [0mCaching images (0.1GB ram):  26%|â–ˆâ–ˆâ–Œ       | 273/1042 [00:00<00:01, 590.85it/s][34m[1mtrain: [0mCaching images (0.1GB ram):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 344/1042 [00:00<00:01, 619.92it/s][34m[1mtrain: [0mCaching images (0.1GB ram):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 407/1042 [00:00<00:01, 585.25it/s][34m[1mtrain: [0mCaching images (0.2GB ram):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 466/1042 [00:00<00:01, 527.72it/s][34m[1mtrain: [0mCaching images (0.2GB ram):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 520/1042 [00:01<00:01, 458.51it/s][34m[1mtrain: [0mCaching images (0.2GB ram):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 603/1042 [00:01<00:00, 550.15it/s][34m[1mtrain: [0mCaching images (0.2GB ram):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 662/1042 [00:01<00:00, 554.99it/s][34m[1mtrain: [0mCaching images (0.3GB ram):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 720/1042 [00:01<00:00, 484.76it/s][34m[1mtrain: [0mCaching images (0.3GB ram):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 772/1042 [00:01<00:00, 474.46it/s][34m[1mtrain: [0mCaching images (0.3GB ram):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 837/1042 [00:01<00:00, 509.13it/s][34m[1mtrain: [0mCaching images (0.3GB ram):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 890/1042 [00:01<00:00, 482.74it/s][34m[1mtrain: [0mCaching images (0.3GB ram):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 940/1042 [00:01<00:00, 453.42it/s][34m[1mtrain: [0mCaching images (0.4GB ram):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 987/1042 [00:02<00:00, 435.98it/s][34m[1mtrain: [0mCaching images (0.4GB ram): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1042/1042 [00:02<00:00, 494.46it/s]
[34m[1mval: [0mScanning /work/jonchang3909/yolov5test/Regurgitation-YOLODataset-1new/valid/labels.cache... 183 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 183/183 [00:00<?, ?it/s][34m[1mval: [0mScanning /work/jonchang3909/yolov5test/Regurgitation-YOLODataset-1new/valid/labels.cache... 183 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 183/183 [00:00<?, ?it/s]
  0%|          | 0/183 [00:00<?, ?it/s][34m[1mval: [0mCaching images (0.0GB ram):  10%|â–‰         | 18/183 [00:00<00:01, 142.25it/s][34m[1mval: [0mCaching images (0.0GB ram):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 69/183 [00:00<00:00, 328.26it/s][34m[1mval: [0mCaching images (0.0GB ram):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 122/183 [00:00<00:00, 403.92it/s][34m[1mval: [0mCaching images (0.1GB ram):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 176/183 [00:00<00:00, 430.64it/s][34m[1mval: [0mCaching images (0.1GB ram): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 183/183 [00:00<00:00, 404.25it/s]

[34m[1mAutoAnchor: [0m3.17 anchors/target, 0.500 Best Possible Recall (BPR). Anchors are a poor fit to dataset âš ï¸, attempting to improve...
[34m[1mAutoAnchor: [0mWARNING âš ï¸ Extremely small objects found: 1040 of 2082 labels are <3 pixels in size
[34m[1mAutoAnchor: [0mRunning kmeans for 9 anchors on 1042 points...
  0%|          | 0/1000 [00:00<?, ?it/s]  1%|          | 6/1000 [00:00<00:17, 56.69it/s]  1%|          | 12/1000 [00:00<00:17, 56.19it/s]  2%|â–         | 18/1000 [00:00<00:17, 56.50it/s]  2%|â–         | 24/1000 [00:00<00:17, 56.48it/s]  3%|â–Ž         | 30/1000 [00:00<00:17, 56.59it/s]  4%|â–Ž         | 36/1000 [00:00<00:17, 56.57it/s]  4%|â–         | 42/1000 [00:00<00:16, 56.75it/s][34m[1mAutoAnchor: [0mEvolving anchors with Genetic Algorithm: fitness = 0.8832:  12%|â–ˆâ–        | 118/1000 [00:00<00:03, 272.12it/s][34m[1mAutoAnchor: [0mEvolving anchors with Genetic Algorithm: fitness = 0.8848:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 396/1000 [00:00<00:00, 1035.12it/s][34m[1mAutoAnchor: [0mEvolving anchors with Genetic Algorithm: fitness = 0.8850:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 674/1000 [00:01<00:00, 1563.50it/s][34m[1mAutoAnchor: [0mEvolving anchors with Genetic Algorithm: fitness = 0.8851:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 954/1000 [00:01<00:00, 1934.91it/s][34m[1mAutoAnchor: [0mEvolving anchors with Genetic Algorithm: fitness = 0.8851: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:01<00:00, 862.50it/s]
[34m[1mAutoAnchor: [0mthr=0.23: 0.5005 best possible recall, 4.49 anchors past thr
[34m[1mAutoAnchor: [0mn=9, img_size=416, metric_all=0.335/0.443-mean/best, past_thr=0.672-mean: 43,43, 51,61, 73,47, 65,57, 66,72, 86,59, 84,75, 74,94, 117,65
[34m[1mAutoAnchor: [0mDone âš ï¸ (original anchors better than new anchors, proceeding with original anchors)
Plotting labels to runs/train/yolov5s_test510/labels.jpg... 
Image sizes 416 train, 416 val
Using 8 dataloader workers
Logging results to [1mruns/train/yolov5s_test510[0m
Starting training for 300 epochs...

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 58.53it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:00<00:00, 32.63it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 27/33 [00:00<00:00, 23.98it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 35.00it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 2.8243207931518555
total_loss = 2.8243207931518555, detection_loss = 2.8243207931518555, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:01,  1.86it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.52it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.83it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.64it/s]
                   all        183        366          0          0          0          0

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]

[_make_grid Debug] i=0, nx=56, ny=44
[_make_grid Debug] stride: tensor([ 8., 16., 32.], device='cuda:0', dtype=torch.float16)
[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],
         [ 2.00000,  3.75000],
         [ 4.12500,  2.87500]],

        [[ 1.87500,  3.81250],
         [ 3.87500,  2.81250],
         [ 3.68750,  7.43750]],

        [[ 3.62500,  2.81250],
         [ 4.87500,  6.18750],
         [11.65625, 10.18750]]], device='cuda:0', dtype=torch.float16)
[_make_grid Debug] anchor index i => anchors[i]: tensor([[1.25000, 1.62500],
        [2.00000, 3.75000],
        [4.12500, 2.87500]], device='cuda:0', dtype=torch.float16)
self.anchors[i]: tensor([[1.25000, 1.62500],
        [2.00000, 3.75000],
        [4.12500, 2.87500]], device='cuda:0', dtype=torch.float16)
self.stride[i]: tensor(8., device='cuda:0', dtype=torch.float16)

[_make_grid Debug] i=1, nx=28, ny=22
[_make_grid Debug] stride: tensor([ 8., 16., 32.], device='cuda:0', dtype=torch.float16)
[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],
         [ 2.00000,  3.75000],
         [ 4.12500,  2.87500]],

        [[ 1.87500,  3.81250],
         [ 3.87500,  2.81250],
         [ 3.68750,  7.43750]],

        [[ 3.62500,  2.81250],
         [ 4.87500,  6.18750],
         [11.65625, 10.18750]]], device='cuda:0', dtype=torch.float16)
[_make_grid Debug] anchor index i => anchors[i]: tensor([[1.87500, 3.81250],
        [3.87500, 2.81250],
        [3.68750, 7.43750]], device='cuda:0', dtype=torch.float16)
self.anchors[i]: tensor([[1.87500, 3.81250],
        [3.87500, 2.81250],
        [3.68750, 7.43750]], device='cuda:0', dtype=torch.float16)
self.stride[i]: tensor(16., device='cuda:0', dtype=torch.float16)

[_make_grid Debug] i=2, nx=14, ny=11
[_make_grid Debug] stride: tensor([ 8., 16., 32.], device='cuda:0', dtype=torch.float16)
[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],
         [ 2.00000,  3.75000],
         [ 4.12500,  2.87500]],

        [[ 1.87500,  3.81250],
         [ 3.87500,  2.81250],
         [ 3.68750,  7.43750]],

        [[ 3.62500,  2.81250],
         [ 4.87500,  6.18750],
         [11.65625, 10.18750]]], device='cuda:0', dtype=torch.float16)
[_make_grid Debug] anchor index i => anchors[i]: tensor([[ 3.62500,  2.81250],
        [ 4.87500,  6.18750],
        [11.65625, 10.18750]], device='cuda:0', dtype=torch.float16)
self.anchors[i]: tensor([[ 3.62500,  2.81250],
        [ 4.87500,  6.18750],
        [11.65625, 10.18750]], device='cuda:0', dtype=torch.float16)
self.stride[i]: tensor(32., device='cuda:0', dtype=torch.float16)
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 45.21it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 32.12it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 39.63it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 38.72it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 2.8497486114501953
total_loss = 2.8497486114501953, detection_loss = 2.8497486114501953, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.00it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.26it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.51it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.40it/s]
                   all        183        366          0          0          0          0

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 2.9385762214660645
total_loss = 2.9385762214660645, detection_loss = 2.9385762214660645, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 115.25it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 33.76it/s] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 41.70it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.69it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.54it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.67it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.65it/s]
                   all        183        366          0          0          0          0

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 68.03it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 24/33 [00:00<00:00, 49.29it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 35.95it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 33.68it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 39.28it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 2.7064173221588135
total_loss = 2.7064173221588135, detection_loss = 2.7064173221588135, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.68it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.51it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.62it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.60it/s]
                   all        183        366          0          0          0          0

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 2.8723673820495605
total_loss = 2.8723673820495605, detection_loss = 2.8723673820495605, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 91.21it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 27/33 [00:00<00:00, 33.91it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 44.47it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.63it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.52it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.67it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.64it/s]
                   all        183        366          0          0          0          0

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 53.94it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:00<00:00, 45.62it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 28/33 [00:00<00:00, 34.54it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 42.37it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 2.730940341949463
total_loss = 2.730940341949463, detection_loss = 2.730940341949463, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.38it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.41it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.64it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.57it/s]
                   all        183        366          0          0          0          0

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 118.43it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 26.87it/s] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 35.04it/s]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 2.736557960510254
total_loss = 2.736557960510254, detection_loss = 2.736557960510254, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.63it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.53it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.68it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.65it/s]
                   all        183        366          0          0          0          0

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 2.6982972621917725
total_loss = 2.6982972621917725, detection_loss = 2.6982972621917725, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 43.73it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 33.21it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 41.22it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.69it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.51it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.72it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.68it/s]
                   all        183        366          0          0          0          0

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 2.751814365386963
total_loss = 2.751814365386963, detection_loss = 2.751814365386963, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 39.87it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 33.48it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 36.25it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 36.21it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.72it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.59it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.75it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.72it/s]
                   all        183        366          0          0          0          0

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 114.61it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 36.08it/s] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 40.33it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 2.6431772708892822
total_loss = 2.6431772708892822, detection_loss = 2.6431772708892822, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.70it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.58it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.74it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.71it/s]
                   all        183        366          0          0          0          0

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 2.527413845062256
total_loss = 2.527413845062256, detection_loss = 2.527413845062256, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 46.62it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 22/33 [00:00<00:00, 45.49it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 27/33 [00:00<00:00, 30.11it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 39.03it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.68it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.55it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.72it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.69it/s]
                   all        183        366          0          0          0          0

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 2.574338912963867
total_loss = 2.574338912963867, detection_loss = 2.574338912963867, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 115.41it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 31.69it/s] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 40.53it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.70it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.58it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.73it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.70it/s]
                   all        183        366          0          0          0          0

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 50.48it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:00<00:00, 51.44it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 34.12it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 43.69it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 2.615766763687134
total_loss = 2.615766763687134, detection_loss = 2.615766763687134, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.72it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.61it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.77it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.74it/s]
                   all        183        366          0          0          0          0

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 2.580728530883789
total_loss = 2.580728530883789, detection_loss = 2.580728530883789, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 58.82it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:00<00:00, 52.07it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 28/33 [00:00<00:00, 33.30it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 45.69it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.67it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.55it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.73it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.69it/s]
                   all        183        366          0          0          0          0

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 2.4988441467285156
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 54.66it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:00<00:00, 47.89it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 28/33 [00:00<00:00, 32.22it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 43.95it/s]
total_loss = 2.4988441467285156, detection_loss = 2.4988441467285156, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.79it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.64it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.77it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.75it/s]
                   all        183        366          0          0          0          0

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 2.515446186065674
total_loss = 2.515446186065674, detection_loss = 2.515446186065674, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 51.22it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 44.50it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 30/33 [00:00<00:00, 38.24it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 45.23it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.69it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.58it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.73it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.70it/s]
                   all        183        366          0          0          0          0

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 64.52it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 24/33 [00:00<00:00, 50.19it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 38.52it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 44.84it/s]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 2.5450663566589355
total_loss = 2.5450663566589355, detection_loss = 2.5450663566589355, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.66it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.58it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.74it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.71it/s]
                   all        183        366          0          0          0          0

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 2.2930855751037598
total_loss = 2.2930855751037598, detection_loss = 2.2930855751037598, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 39.63it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 33.58it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 33.54it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 34.36it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.62it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.55it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.73it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.68it/s]
                   all        183        366          0          0          0          0

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 61.04it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 24/33 [00:00<00:00, 52.90it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 30/33 [00:00<00:00, 39.62it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 41.56it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 2.422720432281494
total_loss = 2.422720432281494, detection_loss = 2.422720432281494, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.70it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.58it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.75it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.72it/s]
                   all        183        366          0          0          0          0

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 2.355294704437256
total_loss = 2.355294704437256, detection_loss = 2.355294704437256, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 107.07it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 28/33 [00:00<00:00, 30.52it/s] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 40.21it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.69it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.56it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.72it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.69it/s]
                   all        183        366          0          0          0          0

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 102.27it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 28/33 [00:00<00:00, 35.11it/s] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 41.83it/s]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 2.465284585952759
total_loss = 2.465284585952759, detection_loss = 2.465284585952759, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.75it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.63it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.79it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.76it/s]
                   all        183        366          0          0          0          0

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 57.39it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:00<00:00, 47.97it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 28/33 [00:00<00:00, 40.63it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 32/33 [00:00<00:00, 37.97it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 43.15it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 2.339340925216675
total_loss = 2.339340925216675, detection_loss = 2.339340925216675, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.61it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.59it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.73it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.69it/s]
                   all        183        366    1.8e-05     0.0179   1.46e-05   1.46e-06

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 117.14it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 35.38it/s] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 44.69it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 2.413003921508789
total_loss = 2.413003921508789, detection_loss = 2.413003921508789, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.80it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.61it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.75it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.73it/s]
                   all        183        366   1.95e-05     0.0179   1.12e-05   1.12e-06

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 2.4069037437438965
total_loss = 2.4069037437438965, detection_loss = 2.4069037437438965, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 39.66it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 31.53it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 34.34it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 34.49it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.34it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.45it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.64it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.58it/s]
                   all        183        366   1.77e-05     0.0179   1.01e-05   1.01e-06

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 24%|â–ˆâ–ˆâ–       | 8/33 [00:00<00:00, 77.94it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 65.56it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 24/33 [00:00<00:00, 49.54it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 30/33 [00:00<00:00, 31.91it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 42.94it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 2.296523094177246
total_loss = 2.296523094177246, detection_loss = 2.296523094177246, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.72it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.62it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.76it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.73it/s]
                   all        183        366   1.78e-05     0.0179   9.72e-06   9.72e-07

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 119.01it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 32.42it/s] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 41.96it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 2.2559194564819336
total_loss = 2.2559194564819336, detection_loss = 2.2559194564819336, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.64it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.60it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.74it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.70it/s]
                   all        183        366   2.05e-05     0.0179   1.18e-05   1.18e-06

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 2.302119016647339
total_loss = 2.302119016647339, detection_loss = 2.302119016647339, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 36.26it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 31.92it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 36.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 35.22it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.68it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.56it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.72it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.68it/s]
                   all        183        366   1.97e-05     0.0179   1.09e-05   2.18e-06

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 40.73it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 33.65it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 38.20it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 37.63it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 2.235463857650757
total_loss = 2.235463857650757, detection_loss = 2.235463857650757, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.63it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.55it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.73it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.69it/s]
                   all        183        366   1.92e-05     0.0179   1.07e-05   2.13e-06

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 2.2374398708343506
total_loss = 2.2374398708343506, detection_loss = 2.2374398708343506, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 38.63it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 35.15it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 43.68it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 41.04it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.66it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.57it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.68it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.66it/s]
                   all        183        366   1.92e-05     0.0179   1.11e-05   2.23e-06

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 57.31it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:00<00:00, 46.65it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 28/33 [00:00<00:00, 34.52it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 32/33 [00:00<00:00, 32.20it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 38.27it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 2.2495412826538086
total_loss = 2.2495412826538086, detection_loss = 2.2495412826538086, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.72it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.55it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.68it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.66it/s]
                   all        183        366   1.92e-05     0.0179   1.08e-05   2.16e-06

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 2.173943519592285
total_loss = 2.173943519592285, detection_loss = 2.173943519592285, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 42.61it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 32.60it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 35.88it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 36.10it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.67it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.57it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.69it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.67it/s]
                   all        183        366   5.33e-05     0.0387   5.15e-05   6.87e-06

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 36.93it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 27.98it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 30/33 [00:00<00:00, 30.06it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 33.09it/s]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 2.141392469406128
total_loss = 2.141392469406128, detection_loss = 2.141392469406128, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.64it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.53it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.68it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.65it/s]
                   all        183        366   5.11e-05     0.0387   6.87e-05   8.87e-06

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 44.05it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 31.11it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:01<00:00, 31.35it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:01<00:00, 32.76it/s]
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 2.3335020542144775
total_loss = 2.3335020542144775, detection_loss = 2.3335020542144775, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.61it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.52it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.65it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.62it/s]
                   all        183        366   5.54e-05     0.0387   5.63e-05   7.36e-06

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 56.74it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:00<00:00, 46.94it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 28/33 [00:00<00:00, 26.92it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 38.52it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 2.1689162254333496
total_loss = 2.1689162254333496, detection_loss = 2.1689162254333496, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.43it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.43it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.61it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.56it/s]
                   all        183        366   5.76e-05     0.0387   3.41e-05    5.8e-06

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 78.35it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 42.85it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 30/33 [00:00<00:00, 33.71it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 39.17it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 2.129228353500366
total_loss = 2.129228353500366, detection_loss = 2.129228353500366, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.69it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.56it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.69it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.66it/s]
                   all        183        366   6.99e-05     0.0387   4.01e-05   7.06e-06

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 53.39it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:00<00:00, 40.51it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 27/33 [00:00<00:00, 30.68it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 42.95it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 2.3023219108581543
total_loss = 2.3023219108581543, detection_loss = 2.3023219108581543, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.46it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.36it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.56it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.51it/s]
                   all        183        366   4.43e-05     0.0209   2.45e-05   4.89e-06

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 2.198014736175537
total_loss = 2.198014736175537, detection_loss = 2.198014736175537, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 54.26it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:00<00:00, 52.04it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 31.47it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 41.02it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.60it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.53it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.67it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.64it/s]
                   all        183        366   9.91e-06    0.00301   5.28e-06   1.06e-06

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 2.2489919662475586
total_loss = 2.2489919662475586, detection_loss = 2.2489919662475586, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 115.78it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 29.28it/s] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 36.54it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.68it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.55it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.72it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.69it/s]
                   all        183        366   1.86e-05    0.00602   9.62e-06   1.46e-06

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 2.1265077590942383
total_loss = 2.1265077590942383, detection_loss = 2.1265077590942383, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 43.58it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 33.95it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 41.30it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 40.04it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.61it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.45it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.62it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.59it/s]
                   all        183        366   0.000193     0.0873   0.000132   3.52e-05

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 2.0865895748138428
total_loss = 2.0865895748138428, detection_loss = 2.0865895748138428, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 39.39it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 31.48it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 38.09it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 36.87it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.65it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.50it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.67it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.64it/s]
                   all        183        366   0.000206     0.0895   0.000139   3.65e-05

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 2.124452590942383
total_loss = 2.124452590942383, detection_loss = 2.124452590942383, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 55.76it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:00<00:00, 52.88it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 38.41it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 36.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 41.07it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.70it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.53it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.71it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.67it/s]
                   all        183        366   0.000189     0.0865   0.000131   3.35e-05

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 44.85it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 32.76it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 35.03it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 35.78it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 2.12923264503479
total_loss = 2.12923264503479, detection_loss = 2.12923264503479, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.47it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.43it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.63it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.58it/s]
                   all        183        366   0.000189     0.0865   0.000159   3.93e-05

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 64.12it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 24/33 [00:00<00:00, 51.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 32.66it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 43.68it/s]
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.9970946311950684
total_loss = 1.9970946311950684, detection_loss = 1.9970946311950684, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.67it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.47it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.65it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.62it/s]
                   all        183        366   0.000223     0.0865   0.000169   4.32e-05

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 2.229079246520996
total_loss = 2.229079246520996, detection_loss = 2.229079246520996, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 64.35it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 24/33 [00:00<00:00, 52.56it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 30/33 [00:00<00:00, 36.34it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 44.56it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.66it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.45it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.66it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.62it/s]
                   all        183        366   0.000241     0.0865   0.000182   4.72e-05

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 44.21it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 35.35it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 42.41it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 41.17it/s]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 2.0377001762390137
total_loss = 2.0377001762390137, detection_loss = 2.0377001762390137, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.69it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.55it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.68it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.66it/s]
                   all        183        366   0.000277      0.113   0.000258   6.31e-05

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 66.71it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 24/33 [00:00<00:00, 53.85it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 30/33 [00:00<00:00, 30.66it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 40.76it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.9401006698608398
total_loss = 1.9401006698608398, detection_loss = 1.9401006698608398, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.63it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.47it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.65it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.61it/s]
                   all        183        366   0.000219     0.0865   0.000195    5.2e-05

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 116.65it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 32.59it/s] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 42.39it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.93898606300354
total_loss = 1.93898606300354, detection_loss = 1.93898606300354, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.40it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.36it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.57it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.52it/s]
                   all        183        366   0.000245     0.0956   0.000204   5.21e-05

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 47.97it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 24/33 [00:00<00:00, 52.16it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 30/33 [00:00<00:00, 40.16it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 36.95it/s]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 2.0317351818084717
total_loss = 2.0317351818084717, detection_loss = 2.0317351818084717, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.69it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.48it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.64it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.61it/s]
                   all        183        366   0.000353      0.148   0.000298   6.96e-05

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 2.0426881313323975
total_loss = 2.0426881313323975, detection_loss = 2.0426881313323975, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 40.57it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 36.02it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 39.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 39.29it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.66it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.49it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.68it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.64it/s]
                   all        183        366   0.000217     0.0865   0.000199   5.19e-05

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 63.64it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 24/33 [00:00<00:00, 59.24it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 30/33 [00:00<00:00, 35.87it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 43.56it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.7615749835968018
total_loss = 1.7615749835968018, detection_loss = 1.7615749835968018, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.59it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.46it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.65it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.61it/s]
                   all        183        366    0.00023     0.0917   0.000189   5.05e-05

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.8234167098999023
total_loss = 1.8234167098999023, detection_loss = 1.8234167098999023, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 55.82it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:00<00:00, 44.59it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 28/33 [00:00<00:00, 34.56it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 41.22it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.66it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.47it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.66it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.63it/s]
                   all        183        366   0.000244     0.0978   0.000368   9.84e-05

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 51.63it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 46.11it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 30/33 [00:00<00:00, 39.49it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 43.32it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.923311710357666
total_loss = 1.923311710357666, detection_loss = 1.923311710357666, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.69it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.50it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.66it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.63it/s]
                   all        183        366   0.000278      0.113   0.000318      9e-05

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.9436228275299072
total_loss = 1.9436228275299072, detection_loss = 1.9436228275299072, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 69.41it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 24/33 [00:00<00:00, 53.71it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 30/33 [00:00<00:00, 35.50it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 45.32it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.66it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.47it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.64it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.61it/s]
                   all        183        366   0.000296      0.122   0.000778   0.000233

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 35.58it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 38.09it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 42.47it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 40.41it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.7923983335494995
total_loss = 1.7923983335494995, detection_loss = 1.7923983335494995, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.60it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.47it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.59it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.57it/s]
                   all        183        366   0.000547      0.234   0.000872   0.000208

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 2.070265293121338
total_loss = 2.070265293121338, detection_loss = 2.070265293121338, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 51.61it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:00<00:00, 53.97it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 40.38it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 44.90it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.53it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.42it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.60it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.56it/s]
                   all        183        366   0.000551      0.237    0.00133   0.000361

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 71.00it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 40.48it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 30/33 [00:00<00:00, 31.36it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 40.05it/s]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.9812664985656738
total_loss = 1.9812664985656738, detection_loss = 1.9812664985656738, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.58it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.44it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.58it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.55it/s]
                   all        183        366   0.000607      0.261    0.00154   0.000397

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 58.74it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:00<00:00, 56.23it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 33.91it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 45.20it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.9159564971923828
total_loss = 1.9159564971923828, detection_loss = 1.9159564971923828, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.12it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.24it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.45it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.38it/s]
                   all        183        366   0.000618      0.267    0.00188   0.000443

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.9411892890930176
total_loss = 1.9411892890930176, detection_loss = 1.9411892890930176, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 43.95it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 34.90it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 31.07it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 33.23it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.56it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.37it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.52it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.49it/s]
                   all        183        366   0.000619      0.267    0.00166   0.000439

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.929581880569458
total_loss = 1.929581880569458, detection_loss = 1.929581880569458, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 59.55it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:00<00:00, 52.95it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 31.85it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 42.48it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.48it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.39it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.52it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.49it/s]
                   all        183        366   0.000603      0.261    0.00257   0.000647

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 55.04it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:00<00:00, 42.86it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 28/33 [00:00<00:00, 42.12it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 38.29it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 41.55it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.88443124294281
total_loss = 1.88443124294281, detection_loss = 1.88443124294281, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.57it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.40it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.55it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.52it/s]
                   all        183        366   0.000584      0.253     0.0024   0.000593

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 114.17it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 30.06it/s] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 38.84it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.8543972969055176
total_loss = 1.8543972969055176, detection_loss = 1.8543972969055176, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.55it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.39it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.52it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.50it/s]
                   all        183        366    0.00061      0.264    0.00264   0.000582

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.8455387353897095
total_loss = 1.8455387353897095, detection_loss = 1.8455387353897095, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 55.48it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:00<00:00, 45.92it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 28/33 [00:00<00:00, 29.92it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 41.46it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.20it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.25it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.45it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.39it/s]
                   all        183        366   0.000617      0.267    0.00262    0.00062

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.9482618570327759
total_loss = 1.9482618570327759, detection_loss = 1.9482618570327759, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 36.56it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 31.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 39.81it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.26it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.29it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.47it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.42it/s]
                   all        183        366   0.000615      0.267    0.00271   0.000633

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 52.69it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:00<00:00, 45.87it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 28/33 [00:00<00:00, 25.92it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 36.34it/s]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.8667552471160889
total_loss = 1.8667552471160889, detection_loss = 1.8667552471160889, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.55it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.34it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.52it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.49it/s]
                   all        183        366   0.000635      0.267    0.00331   0.000759

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.808914065361023
total_loss = 1.808914065361023, detection_loss = 1.808914065361023, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 115.56it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 33.84it/s] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 40.90it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.45it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.38it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.57it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.52it/s]
                   all        183        366   0.000634      0.267    0.00317    0.00075

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.8982540369033813
total_loss = 1.8982540369033813, detection_loss = 1.8982540369033813, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 51.65it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 35.41it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 44.15it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.45it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.31it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.45it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.42it/s]
                   all        183        366   0.000641      0.267    0.00325   0.000776

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 40.95it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 33.86it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 41.01it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 39.48it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.8283956050872803
total_loss = 1.8283956050872803, detection_loss = 1.8283956050872803, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.44it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.30it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.45it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.42it/s]
                   all        183        366    0.00064       0.27    0.00386   0.000859

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.9766937494277954
total_loss = 1.9766937494277954, detection_loss = 1.9766937494277954, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 55.28it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:00<00:00, 50.91it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 28/33 [00:00<00:00, 40.89it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 35.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 40.55it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.49it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.34it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.50it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.47it/s]
                   all        183        366   0.000661      0.275     0.0042   0.000969

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 64.82it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 24/33 [00:00<00:00, 53.08it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 30/33 [00:00<00:00, 35.53it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 42.38it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 2.0511434078216553
total_loss = 2.0511434078216553, detection_loss = 2.0511434078216553, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.10it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.19it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.38it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.32it/s]
                   all        183        366   0.000653      0.275    0.00446    0.00104

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 62.43it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 24/33 [00:00<00:00, 50.40it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 32.67it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 43.80it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.8178319931030273
total_loss = 1.8178319931030273, detection_loss = 1.8178319931030273, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.45it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.31it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.49it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.45it/s]
                   all        183        366   0.000652      0.278    0.00432    0.00104

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 119.42it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 37.31it/s] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 41.29it/s]
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.9810893535614014
total_loss = 1.9810893535614014, detection_loss = 1.9810893535614014, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.42it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.31it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.47it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.43it/s]
                   all        183        366   0.000653      0.281    0.00464    0.00107

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 42.45it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 40.58it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 45.97it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 44.32it/s]
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.8460164070129395
total_loss = 1.8460164070129395, detection_loss = 1.8460164070129395, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.35it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.28it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.44it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.40it/s]
                   all        183        366   0.000652      0.281    0.00477    0.00117

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.9114739894866943
total_loss = 1.9114739894866943, detection_loss = 1.9114739894866943, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 94.45it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 27/33 [00:00<00:00, 24.16it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 33.76it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.41it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.31it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.44it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.41it/s]
                   all        183        366   0.000679      0.295    0.00511    0.00119

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 42.83it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 33.29it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 31/33 [00:00<00:00, 37.57it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 37.43it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.829261302947998
total_loss = 1.829261302947998, detection_loss = 1.829261302947998, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.45it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.35it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.50it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.47it/s]
                   all        183        366   0.000679      0.295    0.00515    0.00132

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 43.04it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 35.61it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 41.54it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 40.53it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.7387257814407349
total_loss = 1.7387257814407349, detection_loss = 1.7387257814407349, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.49it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.36it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.49it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.47it/s]
                   all        183        366   0.000678      0.295    0.00549    0.00141

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.7524415254592896
total_loss = 1.7524415254592896, detection_loss = 1.7524415254592896, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 104.46it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 28/33 [00:00<00:00, 34.11it/s] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 41.76it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.42it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.29it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.45it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.42it/s]
                   all        183        366   0.000678      0.295    0.00542     0.0013

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.8984763622283936
total_loss = 1.8984763622283936, detection_loss = 1.8984763622283936, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 63.94it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 24/33 [00:00<00:00, 49.36it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 40.23it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 44.64it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.42it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.31it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.44it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.41it/s]
                   all        183        366    0.00189      0.296    0.00738    0.00181

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.6862975358963013
total_loss = 1.6862975358963013, detection_loss = 1.6862975358963013, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 116.83it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 34.53it/s] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 39.87it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.36it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.23it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.38it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.35it/s]
                   all        183        366    0.00217      0.294    0.00662     0.0016

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 62.65it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 24/33 [00:00<00:00, 53.73it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 30/33 [00:00<00:00, 34.70it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 43.21it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.9349322319030762
total_loss = 1.9349322319030762, detection_loss = 1.9349322319030762, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.35it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.23it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.39it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.35it/s]
                   all        183        366    0.00295      0.304    0.00765    0.00187

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.8392982482910156
total_loss = 1.8392982482910156, detection_loss = 1.8392982482910156, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 58.86it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:00<00:00, 51.07it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 28/33 [00:00<00:00, 39.03it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 41.18it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 44.23it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.46it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.26it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.37it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.36it/s]
                   all        183        366    0.00352      0.315    0.00753    0.00196

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.7782247066497803
total_loss = 1.7782247066497803, detection_loss = 1.7782247066497803, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 44.52it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 31.65it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 33.52it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 34.46it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.37it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.23it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.35it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.33it/s]
                   all        183        366    0.00301      0.317    0.00832    0.00221

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 103.53it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 28/33 [00:00<00:00, 37.94it/s] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 45.95it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.8440210819244385
total_loss = 1.8440210819244385, detection_loss = 1.8440210819244385, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.20it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.17it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.30it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.27it/s]
                   all        183        366    0.00267      0.322    0.00853    0.00242

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 60.93it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 24/33 [00:00<00:00, 52.91it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 30/33 [00:00<00:00, 35.28it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 42.74it/s]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.8004158735275269
total_loss = 1.8004158735275269, detection_loss = 1.8004158735275269, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.31it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.18it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.30it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.28it/s]
                   all        183        366    0.00233      0.328    0.00903    0.00262

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.9113086462020874
total_loss = 1.9113086462020874, detection_loss = 1.9113086462020874, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 70.38it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 37.02it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 30/33 [00:00<00:00, 38.36it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 44.96it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.31it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.15it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.23it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.23it/s]
                   all        183        366    0.00204      0.333    0.00988    0.00299

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.907031774520874
total_loss = 1.907031774520874, detection_loss = 1.907031774520874, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 116.50it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 33.92it/s] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 44.01it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.05it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.93it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.11it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.07it/s]
                   all        183        366    0.00196      0.334    0.00681    0.00176

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.875284194946289
total_loss = 1.875284194946289, detection_loss = 1.875284194946289, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 57.23it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:00<00:00, 46.41it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 28/33 [00:00<00:00, 40.53it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 45.14it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.70it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.83it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  3.01it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.94it/s]
                   all        183        366    0.00194      0.335    0.00614    0.00154

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 100.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 28/33 [00:00<00:00, 32.37it/s] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 43.45it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.948676347732544
total_loss = 1.948676347732544, detection_loss = 1.948676347732544, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.12it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.98it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.09it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.08it/s]
                   all        183        366    0.00182      0.339    0.00587    0.00142

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 59.55it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:00<00:00, 37.42it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 27/33 [00:00<00:00, 29.90it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 38.10it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.8754510879516602
total_loss = 1.8754510879516602, detection_loss = 1.8754510879516602, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.14it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.02it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.11it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.09it/s]
                   all        183        366    0.00165      0.345     0.0058    0.00139

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 89.54it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 26/33 [00:00<00:00, 30.28it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 39.97it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.6921309232711792
total_loss = 1.6921309232711792, detection_loss = 1.6921309232711792, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.08it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.95it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.05it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.03it/s]
                   all        183        366    0.00168      0.347    0.00728    0.00203

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.7246694564819336
total_loss = 1.7246694564819336, detection_loss = 1.7246694564819336, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 97.94it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 27/33 [00:00<00:00, 30.20it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 41.73it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.03it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.91it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  3.01it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  3.00it/s]
                   all        183        366    0.00165      0.346    0.00965    0.00332

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 72.23it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 43.04it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 30/33 [00:00<00:00, 36.07it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 44.89it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.7970666885375977
total_loss = 1.7970666885375977, detection_loss = 1.7970666885375977, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.03it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.92it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.02it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.00it/s]
                   all        183        366    0.00164      0.344    0.00966    0.00329

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 94.64it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 27/33 [00:00<00:00, 31.48it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 39.36it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.8751839399337769
total_loss = 1.8751839399337769, detection_loss = 1.8751839399337769, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.06it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.94it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.07it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.05it/s]
                   all        183        366    0.00163       0.35     0.0102    0.00334

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 63.64it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 24/33 [00:00<00:00, 46.53it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 32.43it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 40.27it/s]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.9255661964416504
total_loss = 1.9255661964416504, detection_loss = 1.9255661964416504, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.83it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.85it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.99it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.95it/s]
                   all        183        366     0.0016      0.343    0.00743    0.00197

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.8672401905059814
total_loss = 1.8672401905059814, detection_loss = 1.8672401905059814, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 37.50it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 33.96it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 38.74it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 37.58it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.00it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.89it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.97it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.96it/s]
                   all        183        366     0.0016      0.347    0.00749    0.00211

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 43.24it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 35.09it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 41.51it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 40.41it/s]
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.8718886375427246
total_loss = 1.8718886375427246, detection_loss = 1.8718886375427246, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.01it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.89it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  3.00it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.98it/s]
                   all        183        366    0.00164      0.357    0.00829    0.00231

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.8157634735107422
total_loss = 1.8157634735107422, detection_loss = 1.8157634735107422, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 54.90it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:00<00:00, 54.68it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 32.42it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 43.21it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.00it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.90it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  3.00it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.98it/s]
                   all        183        366    0.00166      0.362    0.00774    0.00213

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 60.69it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 24/33 [00:00<00:00, 51.02it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 41.52it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 45.14it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.7963804006576538
total_loss = 1.7963804006576538, detection_loss = 1.7963804006576538, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.97it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.85it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.98it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.95it/s]
                   all        183        366    0.00164      0.356    0.00681    0.00169

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 59.00it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:00<00:00, 51.18it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 28/33 [00:00<00:00, 32.89it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 42.62it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.8451457023620605
total_loss = 1.8451457023620605, detection_loss = 1.8451457023620605, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.90it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.74it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.93it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.89it/s]
                   all        183        366    0.00162      0.349    0.00499    0.00126

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.8199725151062012
total_loss = 1.8199725151062012, detection_loss = 1.8199725151062012, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 55.13it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:00<00:00, 47.98it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 28/33 [00:00<00:00, 39.42it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 32/33 [00:00<00:00, 39.30it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 43.55it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.01it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.89it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  3.02it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.99it/s]
                   all        183        366    0.00165      0.354    0.00507    0.00126

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.8002737760543823
total_loss = 1.8002737760543823, detection_loss = 1.8002737760543823, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 49.52it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 36.18it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 43.88it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.00it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.91it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.03it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.00it/s]
                   all        183        366    0.00169      0.361    0.00504    0.00125

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.8616092205047607
total_loss = 1.8616092205047607, detection_loss = 1.8616092205047607, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 40.29it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 35.05it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 37.35it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 37.32it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.97it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.88it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  3.02it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.99it/s]
                   all        183        366    0.00169      0.359     0.0046    0.00121

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 43.76it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 36.76it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 38.73it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 39.04it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.7908682823181152
total_loss = 1.7908682823181152, detection_loss = 1.7908682823181152, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.03it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.89it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  3.00it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.99it/s]
                   all        183        366    0.00166      0.347    0.00436    0.00119

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 113.93it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 35.87it/s] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 41.91it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.7637383937835693
total_loss = 1.7637383937835693, detection_loss = 1.7637383937835693, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.93it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.86it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  3.00it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.97it/s]
                   all        183        366    0.00215      0.384    0.00467    0.00128

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 56.82it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:00<00:00, 54.68it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 34.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 43.91it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.8167693614959717
total_loss = 1.8167693614959717, detection_loss = 1.8167693614959717, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.00it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.85it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.98it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.96it/s]
                   all        183        366    0.00233      0.406    0.00489    0.00131

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 38.69it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 38.67it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 32/33 [00:00<00:00, 44.77it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 41.76it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.7534235715866089
total_loss = 1.7534235715866089, detection_loss = 1.7534235715866089, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.67it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.72it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.89it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.84it/s]
                   all        183        366    0.00228      0.402    0.00542    0.00145

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.8980801105499268
total_loss = 1.8980801105499268, detection_loss = 1.8980801105499268, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 60.43it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 24/33 [00:00<00:00, 55.74it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 30/33 [00:00<00:00, 39.67it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 45.80it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.97it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.86it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.98it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.96it/s]
                   all        183        366    0.00221      0.398    0.00556    0.00151

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 45.56it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 48.06it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 30/33 [00:00<00:00, 32.33it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 39.39it/s]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.8150882720947266
total_loss = 1.8150882720947266, detection_loss = 1.8150882720947266, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.98it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.88it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.99it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.97it/s]
                   all        183        366    0.00206      0.392    0.00481    0.00135

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 44.71it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 32.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 34.09it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 35.02it/s]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.7510716915130615
total_loss = 1.7510716915130615, detection_loss = 1.7510716915130615, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.04it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.89it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.98it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.97it/s]
                   all        183        366    0.00217      0.396    0.00467    0.00125

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.793848991394043
total_loss = 1.793848991394043, detection_loss = 1.793848991394043, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 81.83it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 26/33 [00:00<00:00, 44.51it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 32/33 [00:00<00:00, 29.64it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 36.67it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.94it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.82it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.94it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.92it/s]
                   all        183        366    0.00241      0.431    0.00737    0.00155

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.8339756727218628
total_loss = 1.8339756727218628, detection_loss = 1.8339756727218628, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 119.24it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 30.13it/s] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 39.44it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.01it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.88it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.97it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.96it/s]
                   all        183        366    0.00226      0.417    0.00729    0.00155

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.7587405443191528
total_loss = 1.7587405443191528, detection_loss = 1.7587405443191528, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 44.30it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 40.35it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 32.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 39.92it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.00it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.88it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.98it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.96it/s]
                   all        183        366    0.00255      0.449     0.0078    0.00162

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 60.67it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 24/33 [00:00<00:00, 47.29it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 32.49it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 42.59it/s]
detection_loss = 2.0096592903137207
total_loss = 2.0096592903137207, detection_loss = 2.0096592903137207, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.00it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.87it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.97it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.96it/s]
                   all        183        366    0.00267      0.462    0.00937    0.00189

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 106.00it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 28/33 [00:00<00:00, 31.66it/s] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 42.21it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.6920262575149536
total_loss = 1.6920262575149536, detection_loss = 1.6920262575149536, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.99it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.86it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.95it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.94it/s]
                   all        183        366    0.00277      0.486    0.00951    0.00189

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 34.05it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 38.77it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 30/33 [00:00<00:00, 38.54it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 41.09it/s]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.7165333032608032
total_loss = 1.7165333032608032, detection_loss = 1.7165333032608032, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.96it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.84it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.94it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.92it/s]
                   all        183        366    0.00274      0.491     0.0114     0.0021

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 48.94it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 22/33 [00:00<00:00, 43.57it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 27/33 [00:00<00:00, 36.71it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 44.15it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.793297529220581
total_loss = 1.793297529220581, detection_loss = 1.793297529220581, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.24it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.52it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.75it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.64it/s]
                   all        183        366    0.00276      0.505     0.0108    0.00205

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.66286301612854
total_loss = 1.66286301612854, detection_loss = 1.66286301612854, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 64.65it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 24/33 [00:00<00:00, 51.98it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 33.69it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 33.62it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 38.87it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.98it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.82it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.93it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.92it/s]
                   all        183        366    0.00268       0.51     0.0116    0.00217

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 61.68it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 24/33 [00:00<00:00, 52.15it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 35.85it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 36.19it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 40.88it/s]
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.8369526863098145
total_loss = 1.8369526863098145, detection_loss = 1.8369526863098145, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.99it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.87it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  3.00it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.98it/s]
                   all        183        366    0.00254       0.49     0.0126    0.00226

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 40.33it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 36.46it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 30/33 [00:00<00:00, 39.17it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 41.92it/s]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.783423900604248
total_loss = 1.783423900604248, detection_loss = 1.783423900604248, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.00it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.87it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.96it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.95it/s]
                   all        183        366    0.00249       0.49     0.0104    0.00192

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 48.05it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 38.08it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 25.54it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:01<00:00, 32.65it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.7874205112457275
total_loss = 1.7874205112457275, detection_loss = 1.7874205112457275, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.98it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.84it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.95it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.93it/s]
                   all        183        366    0.00237      0.478    0.00579    0.00125

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 50.91it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:00<00:00, 49.03it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 28/33 [00:00<00:00, 33.20it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 39.50it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.7387940883636475
total_loss = 1.7387940883636475, detection_loss = 1.7387940883636475, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.01it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.85it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.94it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.93it/s]
                   all        183        366    0.00253      0.515    0.00579    0.00126

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.7579904794692993
total_loss = 1.7579904794692993, detection_loss = 1.7579904794692993, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 64.57it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 24/33 [00:00<00:00, 49.18it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 28.62it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 39.22it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.01it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.87it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.98it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.96it/s]
                   all        183        366    0.00252      0.523    0.00606    0.00131

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.7067850828170776
total_loss = 1.7067850828170776, detection_loss = 1.7067850828170776, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 40.52it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 38.48it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 43.41it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 41.96it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.06it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.87it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.98it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.97it/s]
                   all        183        366    0.00248      0.518    0.00591    0.00137

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 63.72it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 24/33 [00:00<00:00, 51.30it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 29.28it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 39.96it/s]
detection_loss = 1.8081440925598145
total_loss = 1.8081440925598145, detection_loss = 1.8081440925598145, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.00it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.86it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.98it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.96it/s]
                   all        183        366    0.00253      0.533    0.00657    0.00143

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 60.94it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 24/33 [00:00<00:00, 49.41it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 36.82it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 42.74it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.7359185218811035
total_loss = 1.7359185218811035, detection_loss = 1.7359185218811035, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.00it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.86it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.97it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.95it/s]
                   all        183        366    0.00255      0.532     0.0064    0.00154

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 63.28it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 24/33 [00:00<00:00, 47.20it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 32.31it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 42.76it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.892256736755371
total_loss = 1.892256736755371, detection_loss = 1.892256736755371, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.04it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.87it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.95it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.94it/s]
                   all        183        366    0.00255      0.531     0.0068    0.00158

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 2.03825306892395
total_loss = 2.03825306892395, detection_loss = 2.03825306892395, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 50.89it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:00<00:00, 52.31it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 36.85it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 42.15it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.97it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.86it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.88it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.88it/s]
                   all        183        366    0.00259      0.542    0.00662    0.00152

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.9482132196426392
total_loss = 1.9482132196426392, detection_loss = 1.9482132196426392, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 39.45it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 36.28it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 43.12it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 41.11it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.95it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.83it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.93it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.91it/s]
                   all        183        366    0.00264      0.526    0.00617    0.00152

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 58.48it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 24/33 [00:00<00:00, 53.25it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 30/33 [00:00<00:00, 34.29it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 43.36it/s]
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 2.00583815574646
total_loss = 2.00583815574646, detection_loss = 2.00583815574646, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.98it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.82it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.85it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.85it/s]
                   all        183        366    0.00251      0.485    0.00605    0.00159

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.7855873107910156
total_loss = 1.7855873107910156, detection_loss = 1.7855873107910156, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 64.30it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 24/33 [00:00<00:00, 54.53it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 30/33 [00:00<00:00, 37.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 37.54it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.95it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.79it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.88it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.87it/s]
                   all        183        366    0.00251       0.46    0.00623    0.00156

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 110.53it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 36.92it/s] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 42.55it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.723252534866333
total_loss = 1.723252534866333, detection_loss = 1.723252534866333, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.82it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.76it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.86it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.84it/s]
                   all        183        366    0.00224       0.41    0.00844    0.00237

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 62.83it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 24/33 [00:00<00:00, 53.29it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 30/33 [00:00<00:00, 33.92it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 40.41it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.8200429677963257
total_loss = 1.8200429677963257, detection_loss = 1.8200429677963257, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.90it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.78it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.87it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.85it/s]
                   all        183        366    0.00231      0.418     0.0079    0.00207

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 39.30it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 35.46it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 40.26it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 39.15it/s]
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.759610891342163
total_loss = 1.759610891342163, detection_loss = 1.759610891342163, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.70it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.68it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.83it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.79it/s]
                   all        183        366    0.00227       0.41     0.0074    0.00181

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 120.01it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 30/33 [00:00<00:00, 33.53it/s] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 41.43it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.7568391561508179
total_loss = 1.7568391561508179, detection_loss = 1.7568391561508179, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.94it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.78it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.88it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.87it/s]
                   all        183        366    0.00242      0.425    0.00788    0.00195

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 65.69it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 24/33 [00:00<00:00, 48.84it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 34.70it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 40.60it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.813705325126648
total_loss = 1.813705325126648, detection_loss = 1.813705325126648, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.96it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.80it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.90it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.89it/s]
                   all        183        366    0.00241      0.426     0.0082    0.00213

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.8674861192703247
total_loss = 1.8674861192703247, detection_loss = 1.8674861192703247, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 72.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 40.12it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 30/33 [00:00<00:00, 35.90it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 44.13it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.92it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.78it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.89it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.87it/s]
                   all        183        366    0.00247      0.441    0.00782     0.0022

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 54.30it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:00<00:00, 49.75it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 28/33 [00:00<00:00, 35.47it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 45.51it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.7589055299758911
total_loss = 1.7589055299758911, detection_loss = 1.7589055299758911, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.92it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.78it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.89it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.87it/s]
                   all        183        366    0.00265       0.47    0.00813    0.00221

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.6890673637390137
total_loss = 1.6890673637390137, detection_loss = 1.6890673637390137, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 55.46it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:00<00:00, 54.71it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 36.53it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 46.30it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.85it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.76it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.88it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.85it/s]
                   all        183        366    0.00289      0.518    0.00795    0.00214

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.7562977075576782
total_loss = 1.7562977075576782, detection_loss = 1.7562977075576782, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 38.69it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 42.54it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 30/33 [00:00<00:00, 36.08it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 39.25it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.97it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.83it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.93it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.92it/s]
                   all        183        366     0.0028      0.518    0.00775    0.00194

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.9756126403808594
total_loss = 1.9756126403808594, detection_loss = 1.9756126403808594, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 54.71it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 38.40it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 30/33 [00:00<00:00, 39.98it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 45.24it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.00it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.83it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.94it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.92it/s]
                   all        183        366     0.0026      0.499    0.00738    0.00179

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 50.38it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 24/33 [00:00<00:00, 55.03it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 30/33 [00:00<00:00, 36.47it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 43.42it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.6849486827850342
total_loss = 1.6849486827850342, detection_loss = 1.6849486827850342, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.75it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.75it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.87it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.84it/s]
                   all        183        366    0.00262      0.524    0.00876    0.00224

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.6758569478988647
total_loss = 1.6758569478988647, detection_loss = 1.6758569478988647, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 53.99it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:00<00:00, 52.31it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 40.20it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 43.38it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.87it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.78it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.88it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.86it/s]
                   all        183        366    0.00261      0.525    0.00975    0.00238

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.878333330154419
total_loss = 1.878333330154419, detection_loss = 1.878333330154419, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 43.37it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 35.63it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 34.05it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 35.50it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.93it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.79it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.91it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.89it/s]
                   all        183        366    0.00242      0.504     0.0103    0.00238

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.7821398973464966
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 114.09it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 37.20it/s] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 45.51it/s]
total_loss = 1.7821398973464966, detection_loss = 1.7821398973464966, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.93it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.77it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.84it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.84it/s]
                   all        183        366    0.00239      0.507    0.00935     0.0023

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.8158411979675293
total_loss = 1.8158411979675293, detection_loss = 1.8158411979675293, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 35.45it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 31.97it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 38.16it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 36.44it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.94it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.79it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.87it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.86it/s]
                   all        183        366    0.00247      0.529    0.00983    0.00232

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.7669402360916138
total_loss = 1.7669402360916138, detection_loss = 1.7669402360916138, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 64.61it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 24/33 [00:00<00:00, 52.08it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 31.87it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 43.38it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.87it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.75it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.86it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.84it/s]
                   all        183        366    0.00247      0.529     0.0111    0.00269

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.5379902124404907
total_loss = 1.5379902124404907, detection_loss = 1.5379902124404907, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 38.93it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 35.44it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 41.66it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.97it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.79it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.87it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.86it/s]
                   all        183        366    0.00255      0.545    0.00934    0.00229

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.9769350290298462
total_loss = 1.9769350290298462, detection_loss = 1.9769350290298462, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 42.52it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 35.89it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 30/33 [00:00<00:00, 38.13it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 40.04it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.94it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.77it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.83it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.83it/s]
                   all        183        366    0.00262      0.558    0.00923    0.00207

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.6462111473083496
total_loss = 1.6462111473083496, detection_loss = 1.6462111473083496, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 106.79it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 28/33 [00:00<00:00, 30.06it/s] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 40.69it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.91it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.75it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.80it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.80it/s]
                   all        183        366    0.00265       0.58     0.0082    0.00193

Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.9033029079437256
total_loss = 1.9033029079437256, detection_loss = 1.9033029079437256, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 38.37it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 30.78it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:01<00:00, 32.11it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:01<00:00, 32.67it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.91it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.68it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.80it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.79it/s]
                   all        183        366    0.00278      0.626    0.00914    0.00195

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 61.09it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 24/33 [00:00<00:00, 45.00it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 28.03it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 36.89it/s]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.7159713506698608
total_loss = 1.7159713506698608, detection_loss = 1.7159713506698608, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.99it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.79it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.84it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.85it/s]
                   all        183        366    0.00265       0.59    0.00894    0.00193

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.678715705871582
total_loss = 1.678715705871582, detection_loss = 1.678715705871582, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 40.98it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 34.36it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 39.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 38.97it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.96it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.79it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.87it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.86it/s]
                   all        183        366    0.00259      0.577    0.00768    0.00184

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.8868563175201416
total_loss = 1.8868563175201416, detection_loss = 1.8868563175201416, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 61.55it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 24/33 [00:00<00:00, 51.29it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 35.73it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 41.84it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.98it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.81it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.87it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.87it/s]
                   all        183        366    0.00242      0.536    0.00756     0.0018

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 66.20it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 24/33 [00:00<00:00, 53.16it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 30/33 [00:00<00:00, 30.40it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 40.37it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.7851481437683105
total_loss = 1.7851481437683105, detection_loss = 1.7851481437683105, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.99it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.82it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.89it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.89it/s]
                   all        183        366    0.00233      0.521    0.00749    0.00167

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.8479623794555664
total_loss = 1.8479623794555664, detection_loss = 1.8479623794555664, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 46.37it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 36.26it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 31/33 [00:00<00:00, 39.25it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 39.23it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.92it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.68it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.80it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.79it/s]
                   all        183        366    0.00252      0.557    0.00804     0.0018

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 109.02it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 28/33 [00:00<00:00, 31.62it/s] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 42.73it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.7270958423614502
total_loss = 1.7270958423614502, detection_loss = 1.7270958423614502, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.89it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.76it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.85it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.84it/s]
                   all        183        366    0.00256      0.562    0.00769    0.00178

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.6808372735977173
total_loss = 1.6808372735977173, detection_loss = 1.6808372735977173, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 56.09it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:00<00:00, 52.54it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 39.09it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 45.52it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.89it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.75it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.85it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.84it/s]
                   all        183        366    0.00261      0.571    0.00778    0.00184

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.713879942893982
total_loss = 1.713879942893982, detection_loss = 1.713879942893982, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 37.87it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 32.25it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 35.56it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 35.23it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.89it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.76it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.85it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.84it/s]
                   all        183        366    0.00252      0.546    0.00765    0.00189

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 49.99it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 22/33 [00:00<00:00, 46.02it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 27/33 [00:00<00:00, 39.33it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 31/33 [00:00<00:00, 33.28it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 40.03it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.7982808351516724
total_loss = 1.7982808351516724, detection_loss = 1.7982808351516724, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.88it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.75it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.84it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.83it/s]
                   all        183        366     0.0026      0.553    0.00766    0.00183

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 116.50it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 33.74it/s] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 43.82it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.6436430215835571
total_loss = 1.6436430215835571, detection_loss = 1.6436430215835571, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.63it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.64it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.72it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.70it/s]
                   all        183        366    0.00259      0.531    0.00839    0.00208

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 69.23it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 24/33 [00:00<00:00, 47.44it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 31.77it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 42.95it/s]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.7392784357070923
total_loss = 1.7392784357070923, detection_loss = 1.7392784357070923, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.86it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.72it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.83it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.82it/s]
                   all        183        366    0.00267      0.537    0.00889    0.00221

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 60.01it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 24/33 [00:00<00:00, 57.61it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 30/33 [00:00<00:00, 35.62it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 45.57it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.6652145385742188
total_loss = 1.6652145385742188, detection_loss = 1.6652145385742188, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.84it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.72it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.82it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.80it/s]
                   all        183        366    0.00267      0.523    0.00907    0.00237

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.6962889432907104
total_loss = 1.6962889432907104, detection_loss = 1.6962889432907104, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 66.16it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 24/33 [00:00<00:00, 51.18it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 32.55it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 31.81it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 37.37it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.90it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.74it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.82it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.81it/s]
                   all        183        366    0.00269      0.516     0.0102    0.00251

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.7022188901901245
total_loss = 1.7022188901901245, detection_loss = 1.7022188901901245, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 89.08it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 26/33 [00:00<00:00, 41.66it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 32/33 [00:00<00:00, 38.20it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 44.10it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.93it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.70it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.83it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.82it/s]
                   all        183        366    0.00286      0.538     0.0104     0.0025

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.7338371276855469
total_loss = 1.7338371276855469, detection_loss = 1.7338371276855469, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 53.17it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:00<00:00, 52.93it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 32.79it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 41.45it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.93it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.78it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.89it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.88it/s]
                   all        183        366    0.00262      0.482     0.0129    0.00304

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.708001971244812
total_loss = 1.708001971244812, detection_loss = 1.708001971244812, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 118.15it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 36.22it/s] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 46.86it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.89it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.76it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.88it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.86it/s]
                   all        183        366    0.00286      0.544     0.0127    0.00318

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.7185194492340088
total_loss = 1.7185194492340088, detection_loss = 1.7185194492340088, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 44.69it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 34.78it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 43.80it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 41.95it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.93it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.79it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.91it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.89it/s]
                   all        183        366    0.00261      0.509     0.0125    0.00303

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 42.80it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 34.10it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 41.63it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 40.18it/s]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.6932166814804077
total_loss = 1.6932166814804077, detection_loss = 1.6932166814804077, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.88it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.77it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.88it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.86it/s]
                   all        183        366    0.00266      0.525     0.0127    0.00327

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 65.04it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 24/33 [00:00<00:00, 52.13it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 32.97it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 44.52it/s]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.6444106101989746
total_loss = 1.6444106101989746, detection_loss = 1.6444106101989746, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.96it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.81it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.93it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.91it/s]
                   all        183        366    0.00269      0.541     0.0133     0.0035

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 55.68it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:00<00:00, 53.25it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 31.63it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 42.01it/s]
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.789698839187622
total_loss = 1.789698839187622, detection_loss = 1.789698839187622, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.78it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.73it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.86it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.82it/s]
                   all        183        366    0.00269      0.541     0.0135    0.00367

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.7953581809997559
total_loss = 1.7953581809997559, detection_loss = 1.7953581809997559, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 63.94it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 24/33 [00:00<00:00, 51.60it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 35.30it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 42.92it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.89it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.72it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.84it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.82it/s]
                   all        183        366    0.00267      0.545     0.0124    0.00357

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 42.38it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 42.75it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 31/33 [00:00<00:00, 45.78it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 44.36it/s]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.635209321975708
total_loss = 1.635209321975708, detection_loss = 1.635209321975708, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.52it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.58it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.75it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.70it/s]
                   all        183        366    0.00286      0.581      0.013    0.00358

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 65.16it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 24/33 [00:00<00:00, 50.06it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 30.19it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 41.42it/s]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.7450984716415405
total_loss = 1.7450984716415405, detection_loss = 1.7450984716415405, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.80it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.69it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.83it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.80it/s]
                   all        183        366    0.00285      0.581     0.0144    0.00364

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.620471715927124
total_loss = 1.620471715927124, detection_loss = 1.620471715927124, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 37.54it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 35.53it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 41.19it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 39.45it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.77it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.66it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.79it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.76it/s]
                   all        183        366    0.00286       0.56     0.0143    0.00368

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.6698986291885376
total_loss = 1.6698986291885376, detection_loss = 1.6698986291885376, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 39.45it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 36.31it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 43.25it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 41.21it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.76it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.64it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.78it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.75it/s]
                   all        183        366     0.0029      0.557     0.0139    0.00354

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.7285751104354858
total_loss = 1.7285751104354858, detection_loss = 1.7285751104354858, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 111.79it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 37.59it/s] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 42.84it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.45it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.51it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.67it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.62it/s]
                   all        183        366    0.00282      0.526     0.0125    0.00322

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.6789599657058716
total_loss = 1.6789599657058716, detection_loss = 1.6789599657058716, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 52.59it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:00<00:00, 51.51it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 36.06it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 32.74it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 37.76it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.44it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.47it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.65it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.60it/s]
                   all        183        366    0.00274      0.517     0.0117    0.00291

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 37.09it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 32.85it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 34.13it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 34.31it/s]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.7122129201889038
total_loss = 1.7122129201889038, detection_loss = 1.7122129201889038, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.72it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.59it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.72it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.69it/s]
                   all        183        366    0.00272       0.52     0.0102    0.00268

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 40.84it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 36.80it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 35.71it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 36.16it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 36.84it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.8375170230865479
total_loss = 1.8375170230865479, detection_loss = 1.8375170230865479, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.68it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.52it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.68it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.65it/s]
                   all        183        366    0.00272      0.517    0.00893    0.00235

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 40.59it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 32.69it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 31/33 [00:00<00:00, 35.83it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 34.81it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.6741273403167725
total_loss = 1.6741273403167725, detection_loss = 1.6741273403167725, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.68it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.57it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.69it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.67it/s]
                   all        183        366    0.00262       0.52     0.0085    0.00215

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 38.66it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 36.53it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 40.36it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 39.33it/s]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.7334957122802734
total_loss = 1.7334957122802734, detection_loss = 1.7334957122802734, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.67it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.58it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.71it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.69it/s]
                   all        183        366    0.00254      0.517    0.00752    0.00171

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 63.10it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 24/33 [00:00<00:00, 54.15it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 30/33 [00:00<00:00, 32.72it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 41.87it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.652380347251892
total_loss = 1.652380347251892, detection_loss = 1.652380347251892, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.62it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.53it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.67it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.64it/s]
                   all        183        366     0.0025      0.512    0.00692    0.00154

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 58.30it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 24/33 [00:00<00:00, 60.81it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 31/33 [00:00<00:00, 36.43it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 39.97it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.8598549365997314
total_loss = 1.8598549365997314, detection_loss = 1.8598549365997314, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.64it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.53it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.66it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.64it/s]
                   all        183        366    0.00261      0.521    0.00686    0.00161

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 93.34it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 27/33 [00:00<00:00, 31.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 43.70it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.6956292390823364
total_loss = 1.6956292390823364, detection_loss = 1.6956292390823364, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.66it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.54it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.65it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.63it/s]
                   all        183        366    0.00279      0.541    0.00845    0.00197

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 62.16it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 24/33 [00:00<00:00, 46.79it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 38.00it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 44.09it/s]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.5959093570709229
total_loss = 1.5959093570709229, detection_loss = 1.5959093570709229, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.65it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.54it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.64it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.62it/s]
                   all        183        366    0.00281      0.574     0.0105     0.0024

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.7190924882888794
total_loss = 1.7190924882888794, detection_loss = 1.7190924882888794, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 113.41it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 34.18it/s] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 44.28it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.57it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.44it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.55it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.53it/s]
                   all        183        366    0.00269      0.573     0.0124    0.00294

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 120.60it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 30/33 [00:00<00:00, 34.99it/s] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 43.72it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.851022720336914
total_loss = 1.851022720336914, detection_loss = 1.851022720336914, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.51it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.40it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.50it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.49it/s]
                   all        183        366    0.00264      0.574     0.0112    0.00272

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 38.05it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 30.23it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 37.57it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 36.05it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.6945960521697998
total_loss = 1.6945960521697998, detection_loss = 1.6945960521697998, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.54it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.39it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.50it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.48it/s]
                   all        183        366    0.00256      0.561    0.00984    0.00229

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 36.98it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 37.38it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 45.96it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 42.58it/s]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.6918529272079468
total_loss = 1.6918529272079468, detection_loss = 1.6918529272079468, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.54it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.39it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.51it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.49it/s]
                   all        183        366    0.00244      0.533     0.0093    0.00198

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 59.53it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:00<00:00, 46.13it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 28/33 [00:00<00:00, 22.82it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 33.69it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.7189592123031616
total_loss = 1.7189592123031616, detection_loss = 1.7189592123031616, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.49it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.37it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.49it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.47it/s]
                   all        183        366    0.00244      0.505    0.00847    0.00191

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 48.62it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 22/33 [00:00<00:00, 48.31it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 27/33 [00:00<00:00, 31.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 41.47it/s]
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.771255373954773
total_loss = 1.771255373954773, detection_loss = 1.771255373954773, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.58it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.42it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.51it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.50it/s]
                   all        183        366     0.0157      0.177     0.0083    0.00176

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.584725022315979
total_loss = 1.584725022315979, detection_loss = 1.584725022315979, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 63.18it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 24/33 [00:00<00:00, 53.62it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 30/33 [00:00<00:00, 34.02it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 43.04it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.55it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.40it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.50it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.48it/s]
                   all        183        366      0.258     0.0649    0.00853    0.00181

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.7296555042266846
total_loss = 1.7296555042266846, detection_loss = 1.7296555042266846, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 63.82it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 24/33 [00:00<00:00, 52.44it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 29.91it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 41.31it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.58it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.39it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.51it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.49it/s]
                   all        183        366      0.257     0.0436     0.0103    0.00209

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.6649776697158813
total_loss = 1.6649776697158813, detection_loss = 1.6649776697158813, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 53.38it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:00<00:00, 52.33it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 38.62it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 45.29it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.43it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.37it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.49it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.46it/s]
                   all        183        366      0.259     0.0626     0.0103    0.00215

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.5446698665618896
total_loss = 1.5446698665618896, detection_loss = 1.5446698665618896, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 62.57it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 24/33 [00:00<00:00, 50.04it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 36.18it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 36.60it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 41.04it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.61it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.47it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.56it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.55it/s]
                   all        183        366       0.26      0.101     0.0126    0.00261

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.818859338760376
total_loss = 1.818859338760376, detection_loss = 1.818859338760376, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 62.28it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 24/33 [00:00<00:00, 50.52it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 29.94it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 40.48it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.61it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.47it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.57it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.55it/s]
                   all        183        366    0.00882      0.128     0.0128    0.00273

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.8036303520202637
total_loss = 1.8036303520202637, detection_loss = 1.8036303520202637, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 63.80it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 24/33 [00:00<00:00, 54.70it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 30/33 [00:00<00:00, 37.88it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 44.54it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.57it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.46it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.56it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.54it/s]
                   all        183        366     0.0402      0.158     0.0138    0.00302

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.678231120109558
total_loss = 1.678231120109558, detection_loss = 1.678231120109558, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 104.95it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 28/33 [00:00<00:00, 33.92it/s] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 42.46it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.62it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.49it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.58it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.57it/s]
                   all        183        366    0.00438      0.493     0.0149    0.00332

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.8213179111480713
total_loss = 1.8213179111480713, detection_loss = 1.8213179111480713, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 41.91it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 30.62it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 37.81it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 36.80it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.63it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.48it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.58it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.56it/s]
                   all        183        366    0.00241      0.535     0.0154    0.00367

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.8271392583847046
total_loss = 1.8271392583847046, detection_loss = 1.8271392583847046, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 113.96it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 37.63it/s] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 42.46it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.46it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.41it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.51it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.48it/s]
                   all        183        366    0.00251      0.554     0.0152    0.00368

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 41.55it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 22/33 [00:00<00:00, 42.89it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 27/33 [00:00<00:00, 37.01it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 31/33 [00:00<00:00, 34.59it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 33.22it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.8589435815811157
total_loss = 1.8589435815811157, detection_loss = 1.8589435815811157, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.63it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.51it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.61it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.59it/s]
                   all        183        366    0.00251      0.561     0.0167    0.00417

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 35.91it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 33.26it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 38.85it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 37.24it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.7184020280838013
total_loss = 1.7184020280838013, detection_loss = 1.7184020280838013, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.65it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.51it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.60it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.59it/s]
                   all        183        366    0.00251      0.561     0.0157    0.00412

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 39.39it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 30.95it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 39.66it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 37.69it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.791272759437561
total_loss = 1.791272759437561, detection_loss = 1.791272759437561, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.68it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.53it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.61it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.60it/s]
                   all        183        366    0.00245      0.545     0.0158    0.00414

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.8466979265213013
total_loss = 1.8466979265213013, detection_loss = 1.8466979265213013, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 44.64it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 39.92it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 39.06it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 43.28it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.70it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.54it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.65it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.64it/s]
                   all        183        366    0.00257      0.577      0.017     0.0046

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 44.64it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:00<00:00, 46.85it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 28/33 [00:00<00:00, 33.50it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 36.14it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 38.19it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.6984199285507202
total_loss = 1.6984199285507202, detection_loss = 1.6984199285507202, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.71it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.56it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.67it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.65it/s]
                   all        183        366     0.0025      0.556     0.0172    0.00488

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 116.98it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 32.61it/s] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 39.39it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.6998443603515625
total_loss = 1.6998443603515625, detection_loss = 1.6998443603515625, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.71it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.59it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.68it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.66it/s]
                   all        183        366    0.00244      0.538     0.0164    0.00463

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 51.11it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:00<00:00, 50.65it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 45.22it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 37.26it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.7802212238311768
total_loss = 1.7802212238311768, detection_loss = 1.7802212238311768, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.81it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.65it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.75it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.74it/s]
                   all        183        366    0.00253      0.566     0.0161    0.00471

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.6548376083374023
total_loss = 1.6548376083374023, detection_loss = 1.6548376083374023, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 53.24it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 24/33 [00:00<00:00, 53.17it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 30/33 [00:00<00:00, 36.18it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 44.57it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.85it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.67it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.77it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.76it/s]
                   all        183        366    0.00249      0.556     0.0151    0.00437

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.7890831232070923
total_loss = 1.7890831232070923, detection_loss = 1.7890831232070923, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 120.07it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 30/33 [00:00<00:00, 37.76it/s] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 39.38it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.92it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.70it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.83it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.81it/s]
                   all        183        366    0.00247      0.554     0.0142    0.00443

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 114.84it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 32.97it/s] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 41.73it/s]
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.6569066047668457
total_loss = 1.6569066047668457, detection_loss = 1.6569066047668457, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.84it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.69it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.81it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.79it/s]
                   all        183        366    0.00262      0.599     0.0147    0.00429

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.7466812133789062
total_loss = 1.7466812133789062, detection_loss = 1.7466812133789062, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 64.29it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 24/33 [00:00<00:00, 48.89it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 33.37it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 42.23it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.64it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.62it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.78it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.74it/s]
                   all        183        366    0.00255       0.58     0.0161    0.00438

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.7522026300430298
total_loss = 1.7522026300430298, detection_loss = 1.7522026300430298, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 55.93it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:00<00:00, 54.63it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 37.24it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 44.27it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.88it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.72it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.80it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.79it/s]
                   all        183        366    0.00259      0.592     0.0184    0.00538

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.7107341289520264
total_loss = 1.7107341289520264, detection_loss = 1.7107341289520264, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 39.67it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 30.19it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 37.84it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.95it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.76it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.87it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.86it/s]
                   all        183        366     0.0026      0.595     0.0183    0.00536

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 98.72it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 27/33 [00:00<00:00, 34.31it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 44.61it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.8186736106872559
total_loss = 1.8186736106872559, detection_loss = 1.8186736106872559, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.87it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.74it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.85it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.83it/s]
                   all        183        366    0.00263      0.597     0.0173    0.00511

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.7637227773666382
total_loss = 1.7637227773666382, detection_loss = 1.7637227773666382, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 51.99it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:00<00:00, 47.19it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 28/33 [00:00<00:00, 38.03it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 32/33 [00:00<00:00, 36.18it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 40.04it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.89it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.75it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.84it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.83it/s]
                   all        183        366    0.00267      0.617      0.017    0.00499

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.7436929941177368
total_loss = 1.7436929941177368, detection_loss = 1.7436929941177368, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 59.80it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:00<00:00, 56.63it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 35.48it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 42.39it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.90it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.76it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.87it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.85it/s]
                   all        183        366    0.00263      0.609     0.0153     0.0051

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 61.45it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 24/33 [00:00<00:00, 52.90it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 30/33 [00:00<00:00, 35.05it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 40.09it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.7254873514175415
total_loss = 1.7254873514175415, detection_loss = 1.7254873514175415, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.90it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.75it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.86it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.85it/s]
                   all        183        366    0.00265      0.614     0.0157    0.00475

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.646608591079712
total_loss = 1.646608591079712, detection_loss = 1.646608591079712, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 49.33it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 22/33 [00:00<00:00, 47.04it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 27/33 [00:00<00:00, 35.86it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 44.72it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.94it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.76it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.84it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.83it/s]
                   all        183        366    0.00268      0.618     0.0143    0.00382

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 43.76it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 32.28it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 33.70it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 34.65it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.6761103868484497
total_loss = 1.6761103868484497, detection_loss = 1.6761103868484497, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.69it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.68it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.82it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.78it/s]
                   all        183        366    0.00257      0.586     0.0145    0.00365

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.809556007385254
total_loss = 1.809556007385254, detection_loss = 1.809556007385254, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 44.15it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 31.91it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 38.03it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 37.52it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.93it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.78it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.89it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.87it/s]
                   all        183        366    0.00254      0.576     0.0131    0.00315

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 55.57it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:00<00:00, 56.07it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 39.20it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 42.49it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.638247013092041
total_loss = 1.638247013092041, detection_loss = 1.638247013092041, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.95it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.78it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.87it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.86it/s]
                   all        183        366    0.00256      0.593     0.0124     0.0029

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.7152246236801147
total_loss = 1.7152246236801147, detection_loss = 1.7152246236801147, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 49.71it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 42.70it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 30/33 [00:00<00:00, 39.41it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 45.60it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.91it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.72it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.82it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.81it/s]
                   all        183        366    0.00262      0.608     0.0121    0.00272

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 54.99it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:00<00:00, 53.19it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 34.90it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 42.82it/s]
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.6982789039611816
total_loss = 1.6982789039611816, detection_loss = 1.6982789039611816, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.91it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.74it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.84it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.83it/s]
                   all        183        366    0.00261      0.607      0.012    0.00265

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.7734451293945312
total_loss = 1.7734451293945312, detection_loss = 1.7734451293945312, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 76.00it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 44.36it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 30/33 [00:00<00:00, 34.71it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 42.48it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.93it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.73it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.82it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.81it/s]
                   all        183        366     0.0026      0.605     0.0122    0.00269

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 41.03it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 35.86it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 42.49it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 40.89it/s]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.5498801469802856
total_loss = 1.5498801469802856, detection_loss = 1.5498801469802856, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.72it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.64it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.75it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.72it/s]
                   all        183        366    0.00264      0.612     0.0127    0.00281

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.668601155281067
total_loss = 1.668601155281067, detection_loss = 1.668601155281067, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 50.67it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:00<00:00, 49.43it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 28/33 [00:00<00:00, 36.27it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 46.32it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.56it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.58it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.72it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.68it/s]
                   all        183        366    0.00259      0.605      0.014    0.00304

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.5681135654449463
total_loss = 1.5681135654449463, detection_loss = 1.5681135654449463, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 47.95it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 22/33 [00:00<00:00, 37.07it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 26/33 [00:00<00:00, 35.03it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 30/33 [00:00<00:00, 35.50it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 37.72it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.85it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.64it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.75it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.74it/s]
                   all        183        366    0.00264      0.636     0.0147    0.00335

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 40.86it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 31.54it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 38.38it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 37.26it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.7390738725662231
total_loss = 1.7390738725662231, detection_loss = 1.7390738725662231, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.84it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.66it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.77it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.75it/s]
                   all        183        366    0.00256       0.61     0.0145     0.0036

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 51.71it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:00<00:00, 45.47it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 28/33 [00:00<00:00, 29.21it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 39.75it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.5490508079528809
total_loss = 1.5490508079528809, detection_loss = 1.5490508079528809, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.86it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.69it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.79it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.78it/s]
                   all        183        366    0.00252      0.606     0.0149    0.00363

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 106.65it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 28/33 [00:00<00:00, 38.76it/s] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 39.41it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.7829673290252686
total_loss = 1.7829673290252686, detection_loss = 1.7829673290252686, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.79it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.66it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.74it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.73it/s]
                   all        183        366    0.00253      0.613     0.0148    0.00367

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.8334354162216187
total_loss = 1.8334354162216187, detection_loss = 1.8334354162216187, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 42.48it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 32.90it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 39.96it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 38.79it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.82it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.67it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.77it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.75it/s]
                   all        183        366    0.00255      0.618     0.0142    0.00353

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 64.81it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 24/33 [00:00<00:00, 47.64it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 33.23it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 43.81it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.7078158855438232
total_loss = 1.7078158855438232, detection_loss = 1.7078158855438232, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.83it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.68it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.78it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.76it/s]
                   all        183        366    0.00256      0.617     0.0139    0.00344

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.699507474899292
total_loss = 1.699507474899292, detection_loss = 1.699507474899292, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 39.58it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 28.13it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 36.12it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 34.79it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.80it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.65it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.73it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.72it/s]
                   all        183        366    0.00253      0.611      0.014     0.0035

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.7827681303024292
total_loss = 1.7827681303024292, detection_loss = 1.7827681303024292, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 59.79it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:00<00:00, 44.46it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 28/33 [00:00<00:00, 39.80it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 32/33 [00:00<00:00, 39.73it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 44.11it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.66it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.59it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.73it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.69it/s]
                   all        183        366    0.00255      0.601     0.0142    0.00351

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.8440005779266357
total_loss = 1.8440005779266357, detection_loss = 1.8440005779266357, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 51.04it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:00<00:00, 50.92it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 36.65it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 37.37it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 40.67it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.84it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.66it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.77it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.76it/s]
                   all        183        366    0.00258      0.602     0.0153    0.00387

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.6321451663970947
total_loss = 1.6321451663970947, detection_loss = 1.6321451663970947, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 64.18it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 24/33 [00:00<00:00, 55.18it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 30/33 [00:00<00:00, 34.07it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 43.40it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.71it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.63it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.75it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.72it/s]
                   all        183        366    0.00258      0.602     0.0158    0.00412

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.6312469244003296
total_loss = 1.6312469244003296, detection_loss = 1.6312469244003296, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 103.82it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 28/33 [00:00<00:00, 35.14it/s] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 45.97it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.57it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.55it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.69it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.65it/s]
                   all        183        366     0.0025      0.575     0.0162    0.00418

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 115.75it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 32.04it/s] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 40.53it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.693518877029419
total_loss = 1.693518877029419, detection_loss = 1.693518877029419, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.74it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.59it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.73it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.71it/s]
                   all        183        366    0.00258      0.604     0.0169    0.00435

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.596198320388794
total_loss = 1.596198320388794, detection_loss = 1.596198320388794, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 57.51it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:00<00:00, 52.52it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 32.42it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 42.72it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.73it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.60it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.72it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.70it/s]
                   all        183        366    0.00261      0.602     0.0179     0.0045

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 50.22it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:00<00:00, 53.05it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 32.65it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 42.78it/s]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.6892915964126587
total_loss = 1.6892915964126587, detection_loss = 1.6892915964126587, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.66it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.59it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.72it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.69it/s]
                   all        183        366    0.00258      0.595     0.0172    0.00442

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 121.64it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 30/33 [00:00<00:00, 35.09it/s] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 42.02it/s]
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.566673755645752
total_loss = 1.566673755645752, detection_loss = 1.566673755645752, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.62it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.55it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.68it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.65it/s]
                   all        183        366    0.00262      0.602     0.0186    0.00446

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 109.00it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 28/33 [00:00<00:00, 29.67it/s] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 40.24it/s]
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.8192698955535889
total_loss = 1.8192698955535889, detection_loss = 1.8192698955535889, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.56it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.49it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.62it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.59it/s]
                   all        183        366    0.00269      0.608     0.0178    0.00452

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 63.94it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 24/33 [00:00<00:00, 49.27it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 33.51it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 44.55it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.6458861827850342
total_loss = 1.6458861827850342, detection_loss = 1.6458861827850342, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.48it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.44it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.55it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.52it/s]
                   all        183        366     0.0027      0.609      0.018     0.0046

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 55.15it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:00<00:00, 55.57it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 31.06it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 41.93it/s]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.590572476387024
total_loss = 1.590572476387024, detection_loss = 1.590572476387024, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.39it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.37it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.51it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.47it/s]
                   all        183        366     0.0027      0.605     0.0168    0.00435

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 71.78it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 41.98it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 30/33 [00:00<00:00, 36.17it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 44.38it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.7410262823104858
total_loss = 1.7410262823104858, detection_loss = 1.7410262823104858, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.47it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.38it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.51it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.48it/s]
                   all        183        366    0.00272      0.607     0.0167    0.00404

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.7613595724105835
total_loss = 1.7613595724105835, detection_loss = 1.7613595724105835, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 44.45it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 37.32it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 40.68it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 40.54it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.42it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.35it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.46it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.43it/s]
                   all        183        366    0.00271      0.597     0.0141    0.00359

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 57.62it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:00<00:00, 56.72it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 36.05it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 36.81it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 41.32it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.6672358512878418
total_loss = 1.6672358512878418, detection_loss = 1.6672358512878418, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.35it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.31it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.44it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.41it/s]
                   all        183        366    0.00269      0.587     0.0133    0.00314

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 108.33it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 28/33 [00:00<00:00, 32.60it/s] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 43.95it/s]
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.6663413047790527
total_loss = 1.6663413047790527, detection_loss = 1.6663413047790527, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.36it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.28it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.39it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.37it/s]
                   all        183        366    0.00271      0.587     0.0131    0.00311

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.8091607093811035
total_loss = 1.8091607093811035, detection_loss = 1.8091607093811035, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 53.67it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:00<00:00, 49.62it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 28/33 [00:00<00:00, 38.11it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 32/33 [00:00<00:00, 35.04it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 40.92it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.28it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.25it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.37it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.34it/s]
                   all        183        366    0.00274      0.587     0.0129      0.003

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.7488325834274292
total_loss = 1.7488325834274292, detection_loss = 1.7488325834274292, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 55.63it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:00<00:00, 45.40it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 28/33 [00:00<00:00, 31.41it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 42.87it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.29it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.24it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.33it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.31it/s]
                   all        183        366     0.0027      0.568     0.0125    0.00277

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 61.11it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 24/33 [00:00<00:00, 49.89it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 38.29it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 33.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 39.23it/s]
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.7524402141571045
total_loss = 1.7524402141571045, detection_loss = 1.7524402141571045, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.23it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.14it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.27it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.24it/s]
                   all        183        366    0.00286      0.602     0.0148    0.00302

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 41.92it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 38.61it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 31/33 [00:00<00:00, 40.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 38.14it/s]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.7213398218154907
total_loss = 1.7213398218154907, detection_loss = 1.7213398218154907, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.23it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.18it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.29it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.26it/s]
                   all        183        366    0.00291      0.609     0.0167    0.00335

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 58.79it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:00<00:00, 47.50it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 28/33 [00:00<00:00, 31.28it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 43.33it/s]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.6129881143569946
total_loss = 1.6129881143569946, detection_loss = 1.6129881143569946, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.21it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.17it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.28it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.26it/s]
                   all        183        366    0.00289        0.6     0.0173    0.00396

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 51.67it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:00<00:00, 52.61it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 33.58it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 39.87it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.5787698030471802
total_loss = 1.5787698030471802, detection_loss = 1.5787698030471802, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.20it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.15it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.27it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.24it/s]
                   all        183        366    0.00297      0.611     0.0212    0.00446

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 46.48it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 32.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 40.18it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.610778570175171
total_loss = 1.610778570175171, detection_loss = 1.610778570175171, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.20it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.15it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.26it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.23it/s]
                   all        183        366    0.00294      0.606     0.0204    0.00433

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.592167615890503
total_loss = 1.592167615890503, detection_loss = 1.592167615890503, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 45.18it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:00<00:00, 42.42it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 28/33 [00:00<00:00, 32.10it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 38.86it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.18it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.13it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.22it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.20it/s]
                   all        183        366    0.00288      0.597     0.0201     0.0042

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 38.59it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 39.07it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 37.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 38.94it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.6385931968688965
total_loss = 1.6385931968688965, detection_loss = 1.6385931968688965, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.15it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.13it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.25it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.21it/s]
                   all        183        366    0.00281      0.594     0.0194    0.00427

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 59.30it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:00<00:00, 41.88it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 27/33 [00:00<00:00, 27.95it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 39.56it/s]
detection_loss = 1.657639741897583
total_loss = 1.657639741897583, detection_loss = 1.657639741897583, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.14it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.12it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.22it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.20it/s]
                   all        183        366    0.00265      0.565     0.0182    0.00393

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.698810338973999
total_loss = 1.698810338973999, detection_loss = 1.698810338973999, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 117.07it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 33.00it/s] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 42.93it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.04it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.08it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.18it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.14it/s]
                   all        183        366    0.00263      0.566     0.0167    0.00367

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.6878787279129028
total_loss = 1.6878787279129028, detection_loss = 1.6878787279129028, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 33.53it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 33.56it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 34.75it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 34.33it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.07it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.09it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.23it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.19it/s]
                   all        183        366    0.00259      0.562     0.0158    0.00347

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.8220791816711426
total_loss = 1.8220791816711426, detection_loss = 1.8220791816711426, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 58.41it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:00<00:00, 42.42it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 28/33 [00:00<00:00, 34.22it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 44.99it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.12it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.14it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.26it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.22it/s]
                   all        183        366    0.00256      0.562     0.0146    0.00328

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 41.39it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 37.13it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 43.36it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 41.77it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.852934718132019
total_loss = 1.852934718132019, detection_loss = 1.852934718132019, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.18it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.14it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.28it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.24it/s]
                   all        183        366    0.00255      0.558     0.0149    0.00319

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 61.42it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 24/33 [00:00<00:00, 51.82it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 37.20it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 43.42it/s]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.6402630805969238
total_loss = 1.6402630805969238, detection_loss = 1.6402630805969238, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.21it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.16it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.27it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.24it/s]
                   all        183        366    0.00257      0.573     0.0139    0.00324

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.6912028789520264
total_loss = 1.6912028789520264, detection_loss = 1.6912028789520264, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 56.38it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:00<00:00, 52.29it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 36.94it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 45.22it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.21it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.17it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.29it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.26it/s]
                   all        183        366    0.00255      0.568     0.0129    0.00311

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.6967211961746216
total_loss = 1.6967211961746216, detection_loss = 1.6967211961746216, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 64.13it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 24/33 [00:00<00:00, 55.18it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 30/33 [00:00<00:00, 24.68it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 34.29it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.23it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.20it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.29it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.27it/s]
                   all        183        366    0.00258      0.576     0.0128    0.00311

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 54.81it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:00<00:00, 44.77it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 28/33 [00:00<00:00, 38.72it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 44.22it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.612765908241272
total_loss = 1.612765908241272, detection_loss = 1.612765908241272, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.20it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.17it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.29it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.26it/s]
                   all        183        366    0.00255      0.571     0.0121    0.00288

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.5644025802612305
total_loss = 1.5644025802612305, detection_loss = 1.5644025802612305, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 45.17it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 32.19it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 33.60it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 34.69it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.21it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.16it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.28it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.25it/s]
                   all        183        366    0.00255      0.571     0.0123    0.00295

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 55.30it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:00<00:00, 55.62it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 35.06it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 41.39it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.6697691679000854
total_loss = 1.6697691679000854, detection_loss = 1.6697691679000854, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.28it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.22it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.32it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.30it/s]
                   all        183        366    0.00253      0.562     0.0132    0.00315

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 62.68it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 24/33 [00:00<00:00, 50.17it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 34.88it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 43.88it/s]
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.6426693201065063
total_loss = 1.6426693201065063, detection_loss = 1.6426693201065063, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.22it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.20it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.32it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.29it/s]
                   all        183        366    0.00254      0.569     0.0122    0.00324

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 38.30it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 36.58it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 40.97it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 39.67it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.7383533716201782
total_loss = 1.7383533716201782, detection_loss = 1.7383533716201782, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.21it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.20it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.32it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.29it/s]
                   all        183        366    0.00253      0.567     0.0124    0.00326

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 41.36it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 37.51it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 42.43it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 41.28it/s]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.5559245347976685
total_loss = 1.5559245347976685, detection_loss = 1.5559245347976685, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.28it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.23it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.34it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.31it/s]
                   all        183        366    0.00261        0.6     0.0113    0.00299

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.5842581987380981
total_loss = 1.5842581987380981, detection_loss = 1.5842581987380981, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 116.47it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 36.84it/s] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 44.83it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.32it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.25it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.36it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.34it/s]
                   all        183        366     0.0026      0.595     0.0112    0.00298

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.5903023481369019
total_loss = 1.5903023481369019, detection_loss = 1.5903023481369019, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 51.26it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 24/33 [00:00<00:00, 56.73it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 31/33 [00:00<00:00, 39.91it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 45.35it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.20it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.21it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.34it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.30it/s]
                   all        183        366    0.00257       0.59     0.0115    0.00312

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.6607019901275635
total_loss = 1.6607019901275635, detection_loss = 1.6607019901275635, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 40.87it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 36.64it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 42.58it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 41.10it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.38it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.26it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.37it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.35it/s]
                   all        183        366    0.00256      0.589     0.0117    0.00303

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.8467984199523926
total_loss = 1.8467984199523926, detection_loss = 1.8467984199523926, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 39.60it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 39.15it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 45.84it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.32it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.25it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.37it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.34it/s]
                   all        183        366    0.00256      0.585     0.0119    0.00308

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 102.95it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 28/33 [00:00<00:00, 35.17it/s] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 42.12it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.7648036479949951
total_loss = 1.7648036479949951, detection_loss = 1.7648036479949951, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.23it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.21it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.33it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.30it/s]
                   all        183        366    0.00253      0.572     0.0124    0.00324

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.751967430114746
total_loss = 1.751967430114746, detection_loss = 1.751967430114746, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 115.19it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 36.76it/s] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 44.19it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.34it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.25it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.36it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.34it/s]
                   all        183        366    0.00256      0.585     0.0134     0.0032

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.59519624710083
total_loss = 1.59519624710083, detection_loss = 1.59519624710083, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 103.04it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 28/33 [00:00<00:00, 31.74it/s] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 42.72it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.39it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.27it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.36it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.34it/s]
                   all        183        366    0.00254      0.579     0.0121    0.00307

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 52.78it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:00<00:00, 53.78it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 32.47it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 42.20it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.5920828580856323
total_loss = 1.5920828580856323, detection_loss = 1.5920828580856323, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.41it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.29it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.39it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.37it/s]
                   all        183        366    0.00252      0.574     0.0122    0.00313

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.527005672454834
total_loss = 1.527005672454834, detection_loss = 1.527005672454834, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 61.66it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 24/33 [00:00<00:00, 47.80it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 35.65it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 36.03it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 40.24it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.32it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.25it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.36it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.34it/s]
                   all        183        366    0.00253      0.579     0.0126    0.00317

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 58.27it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:00<00:00, 48.60it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 28/33 [00:00<00:00, 32.72it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 42.71it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.669334888458252
total_loss = 1.669334888458252, detection_loss = 1.669334888458252, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.42it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.28it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.38it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.37it/s]
                   all        183        366    0.00256      0.592     0.0127     0.0032

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.6859122514724731
total_loss = 1.6859122514724731, detection_loss = 1.6859122514724731, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 61.56it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 24/33 [00:00<00:00, 54.59it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 30/33 [00:00<00:00, 34.85it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 41.07it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.36it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.26it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.38it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.36it/s]
                   all        183        366    0.00253      0.575     0.0123    0.00308

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 63.61it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 24/33 [00:00<00:00, 52.48it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 35.17it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 35.84it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 40.66it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.501370906829834
total_loss = 1.501370906829834, detection_loss = 1.501370906829834, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.38it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.27it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.09it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.14it/s]
                   all        183        366    0.00252      0.574     0.0124    0.00311

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 35.99it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 35.99it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 41.98it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.5116887092590332
total_loss = 1.5116887092590332, detection_loss = 1.5116887092590332, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.33it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.24it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.37it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.34it/s]
                   all        183        366    0.00248      0.566     0.0123    0.00291

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.562375783920288
total_loss = 1.562375783920288, detection_loss = 1.562375783920288, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 116.26it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 35.05it/s] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 41.73it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.37it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.24it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.37it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.35it/s]
                   all        183        366    0.00249      0.571     0.0119    0.00294

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 39.33it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 35.64it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 41.93it/s]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.6710777282714844
total_loss = 1.6710777282714844, detection_loss = 1.6710777282714844, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.38it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.25it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.39it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.36it/s]
                   all        183        366    0.00248       0.57     0.0115    0.00286

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 113.84it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 36.21it/s] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 45.10it/s]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.5556576251983643
total_loss = 1.5556576251983643, detection_loss = 1.5556576251983643, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.38it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.28it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.41it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.38it/s]
                   all        183        366    0.00242      0.551     0.0114    0.00274

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 64.88it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 24/33 [00:00<00:00, 53.37it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 30/33 [00:00<00:00, 38.45it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 42.12it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.6326572895050049
total_loss = 1.6326572895050049, detection_loss = 1.6326572895050049, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.37it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.30it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.42it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.39it/s]
                   all        183        366    0.00244      0.552      0.011    0.00272

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 113.20it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 35.13it/s] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 41.65it/s]
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.539830207824707
total_loss = 1.539830207824707, detection_loss = 1.539830207824707, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.32it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.26it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.39it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.36it/s]
                   all        183        366    0.00242      0.551     0.0112    0.00277

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.6130527257919312
total_loss = 1.6130527257919312, detection_loss = 1.6130527257919312, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 53.49it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:00<00:00, 49.11it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 28/33 [00:00<00:00, 36.40it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 44.30it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.34it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.27it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.38it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.36it/s]
                   all        183        366    0.00249      0.567     0.0124    0.00296

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 54.80it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 37.37it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 43.80it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 43.78it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.6392199993133545
total_loss = 1.6392199993133545, detection_loss = 1.6392199993133545, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.37it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.29it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.40it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.38it/s]
                   all        183        366    0.00251      0.582     0.0124    0.00268

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.7891052961349487
total_loss = 1.7891052961349487, detection_loss = 1.7891052961349487, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 64.64it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 24/33 [00:00<00:00, 50.62it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 30.89it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 40.39it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.35it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.27it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.40it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.37it/s]
                   all        183        366    0.00251      0.582     0.0125    0.00268

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 56.97it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:00<00:00, 46.73it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 28/33 [00:00<00:00, 32.86it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 42.85it/s]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.5440407991409302
total_loss = 1.5440407991409302, detection_loss = 1.5440407991409302, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.32it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.27it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.39it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.36it/s]
                   all        183        366    0.00252      0.582     0.0123    0.00261

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.59609055519104
total_loss = 1.59609055519104, detection_loss = 1.59609055519104, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 38.41it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 35.52it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 42.50it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 40.39it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.25it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.23it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.36it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.32it/s]
                   all        183        366    0.00249      0.572     0.0119    0.00252

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.627824306488037
total_loss = 1.627824306488037, detection_loss = 1.627824306488037, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 43.16it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 36.22it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 31/33 [00:00<00:00, 41.03it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 38.61it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.33it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.25it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.35it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.33it/s]
                   all        183        366    0.00249      0.576     0.0116     0.0026

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.7641730308532715
total_loss = 1.7641730308532715, detection_loss = 1.7641730308532715, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 55.01it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:00<00:00, 48.49it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 28/33 [00:00<00:00, 35.82it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 43.41it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.27it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.21it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.34it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.31it/s]
                   all        183        366     0.0025       0.58     0.0117    0.00265

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 117.12it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 40.49it/s] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 44.05it/s]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.5800915956497192
total_loss = 1.5800915956497192, detection_loss = 1.5800915956497192, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.29it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.23it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.34it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.32it/s]
                   all        183        366    0.00251      0.581     0.0119    0.00266

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.6302639245986938
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 53.59it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:00<00:00, 51.56it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 33.89it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 43.89it/s]
total_loss = 1.6302639245986938, detection_loss = 1.6302639245986938, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.32it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.24it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.36it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.34it/s]
                   all        183        366    0.00251      0.577     0.0118     0.0027

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.4745312929153442
total_loss = 1.4745312929153442, detection_loss = 1.4745312929153442, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 39.55it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 25/33 [00:00<00:00, 36.16it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 33.14it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 37.68it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.28it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.23it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.36it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.33it/s]
                   all        183        366    0.00254      0.585      0.012    0.00291

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.5788116455078125
total_loss = 1.5788116455078125, detection_loss = 1.5788116455078125, classification_loss = 0.0
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 48.14it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 23/33 [00:00<00:00, 51.25it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 37.83it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 42.60it/s]
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.32it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.27it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.39it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.36it/s]
                   all        183        366    0.00254      0.587     0.0118    0.00289

      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([18, 256, 26, 26]), torch.Size([18, 256, 26, 26])]
Concat layer inputs: [torch.Size([18, 128, 52, 52]), torch.Size([18, 128, 52, 52])]
  0%|          | 0/33 [00:00<?, ?it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 17/33 [00:00<00:00, 118.20it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [00:00<00:00, 34.33it/s] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 44.57it/s]
Concat layer inputs: [torch.Size([18, 128, 26, 26]), torch.Size([18, 128, 26, 26])]
Concat layer inputs: [torch.Size([18, 256, 13, 13]), torch.Size([18, 256, 13, 13])]
detections[0].shape = torch.Size([18, 3, 52, 52, 9])
detections[1].shape = torch.Size([18, 3, 26, 26, 9])
detections[2].shape = torch.Size([18, 3, 13, 13, 9])
detection_loss = 1.659722089767456
total_loss = 1.659722089767456, detection_loss = 1.659722089767456, classification_loss = 0.0
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.25it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  2.19it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.32it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.29it/s]
                   all        183        366    0.00256       0.59     0.0117     0.0029

300 epochs completed in 0.228 hours.
Optimizer stripped from runs/train/yolov5s_test510/weights/last.pt, 14.3MB
Optimizer stripped from runs/train/yolov5s_test510/weights/best.pt, 14.3MB

Validating runs/train/yolov5s_test510/weights/best.pt...
Fusing layers... 
YOLOv5sc summary: 162 layers, 7021300 parameters, 0 gradients, 15.8 GFLOPs
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
Concat layer inputs: [torch.Size([1, 256, 2, 2]), torch.Size([1, 256, 2, 2])]
Concat layer inputs: [torch.Size([1, 128, 4, 4]), torch.Size([1, 128, 4, 4])]
Concat layer inputs: [torch.Size([1, 128, 2, 2]), torch.Size([1, 128, 2, 2])]
Concat layer inputs: [torch.Size([1, 256, 1, 1]), torch.Size([1, 256, 1, 1])]

[_make_grid Debug] i=0, nx=4, ny=4
[_make_grid Debug] stride: tensor([ 8., 16., 32.], device='cuda:0')
[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],
         [ 2.00000,  3.75000],
         [ 4.12500,  2.87500]],

        [[ 1.87500,  3.81250],
         [ 3.87500,  2.81250],
         [ 3.68750,  7.43750]],

        [[ 3.62500,  2.81250],
         [ 4.87500,  6.18750],
         [11.65625, 10.18750]]], device='cuda:0')
[_make_grid Debug] anchor index i => anchors[i]: tensor([[1.25000, 1.62500],
        [2.00000, 3.75000],
        [4.12500, 2.87500]], device='cuda:0')
self.anchors[i]: tensor([[1.25000, 1.62500],
        [2.00000, 3.75000],
        [4.12500, 2.87500]], device='cuda:0')
self.stride[i]: tensor(8., device='cuda:0')

[_make_grid Debug] i=1, nx=2, ny=2
[_make_grid Debug] stride: tensor([ 8., 16., 32.], device='cuda:0')
[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],
         [ 2.00000,  3.75000],
         [ 4.12500,  2.87500]],

        [[ 1.87500,  3.81250],
         [ 3.87500,  2.81250],
         [ 3.68750,  7.43750]],

        [[ 3.62500,  2.81250],
         [ 4.87500,  6.18750],
         [11.65625, 10.18750]]], device='cuda:0')
[_make_grid Debug] anchor index i => anchors[i]: tensor([[1.87500, 3.81250],
        [3.87500, 2.81250],
        [3.68750, 7.43750]], device='cuda:0')
self.anchors[i]: tensor([[1.87500, 3.81250],
        [3.87500, 2.81250],
        [3.68750, 7.43750]], device='cuda:0')
self.stride[i]: tensor(16., device='cuda:0')

[_make_grid Debug] i=2, nx=1, ny=1
[_make_grid Debug] stride: tensor([ 8., 16., 32.], device='cuda:0')
[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],
         [ 2.00000,  3.75000],
         [ 4.12500,  2.87500]],

        [[ 1.87500,  3.81250],
         [ 3.87500,  2.81250],
         [ 3.68750,  7.43750]],

        [[ 3.62500,  2.81250],
         [ 4.87500,  6.18750],
         [11.65625, 10.18750]]], device='cuda:0')
[_make_grid Debug] anchor index i => anchors[i]: tensor([[ 3.62500,  2.81250],
        [ 4.87500,  6.18750],
        [11.65625, 10.18750]], device='cuda:0')
self.anchors[i]: tensor([[ 3.62500,  2.81250],
        [ 4.87500,  6.18750],
        [11.65625, 10.18750]], device='cuda:0')
self.stride[i]: tensor(32., device='cuda:0')
                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/3 [00:00<?, ?it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  2.63it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:01<00:00,  1.88it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.86it/s]                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.92it/s]
                   all        183        366    0.00259      0.592     0.0184    0.00538
                     0        183        221    0.00296       0.24    0.00667     0.0018
                     1        183         83     0.0025       0.53     0.0333      0.013
                     2        183         14    0.00219      0.786      0.019    0.00314
                     3        183         48    0.00271      0.812     0.0147     0.0036
Confusion matrix saved to runs/train/yolov5s_test510/detection_confusion_matrix.png
No classification data available for confusion matrix. Use 'process_classification_batch' to collect data.
Results saved to [1mruns/train/yolov5s_test510[0m
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([64, 256, 22, 28]), torch.Size([64, 256, 22, 28])]
Concat layer inputs: [torch.Size([64, 128, 44, 56]), torch.Size([64, 128, 44, 56])]
Concat layer inputs: [torch.Size([64, 128, 22, 28]), torch.Size([64, 128, 22, 28])]
Concat layer inputs: [torch.Size([64, 256, 11, 14]), torch.Size([64, 256, 11, 14])]
Concat layer inputs: [torch.Size([55, 256, 22, 28]), torch.Size([55, 256, 22, 28])]
Concat layer inputs: [torch.Size([55, 128, 44, 56]), torch.Size([55, 128, 44, 56])]
Concat layer inputs: [torch.Size([55, 128, 22, 28]), torch.Size([55, 128, 22, 28])]
Concat layer inputs: [torch.Size([55, 256, 11, 14]), torch.Size([55, 256, 11, 14])]
