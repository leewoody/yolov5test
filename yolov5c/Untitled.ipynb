{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1031c79a-3eea-4515-855d-6ed07ea3de81",
   "metadata": {},
   "source": [
    "#Yolov5c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45228c7a-71ca-4850-b6d9-83a21eb92065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\darks\\Desktop\\yolov5test\\yolov5c\n"
     ]
    }
   ],
   "source": [
    "%cd C:\\Users\\darks\\Desktop\\yolov5test\\yolov5c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b502570f-a63d-44b6-82db-f9dd83a57fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Blank or comment\n",
      "*** Blank or comment\n",
      "*** Blank or comment\n",
      "NOTE: Enter 'c' at the ipdb>  prompt to continue execution.\n",
      "> \u001b[1;32mc:\\users\\darks\\desktop\\yolov5test\\yolov5c\\train.py\u001b[0m(2)\u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m      1 \u001b[1;33m\u001b[1;31m# YOLOv5 ðŸš€ by Ultralytics, AGPL-3.0 license\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m----> 2 \u001b[1;33m\"\"\"\n",
      "\u001b[0m\u001b[1;32m      3 \u001b[1;33m\u001b[0mTrain\u001b[0m \u001b[0ma\u001b[0m \u001b[0mYOLOv5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0mcustom\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      4 \u001b[1;33m\u001b[0mModels\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0mdownload\u001b[0m \u001b[0mautomatically\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlatest\u001b[0m \u001b[0mYOLOv5\u001b[0m \u001b[0mrelease\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      5 \u001b[1;33m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "--KeyboardInterrupt--\n",
      "\n",
      "KeyboardInterrupt: Interrupted by user\n"
     ]
    }
   ],
   "source": [
    "%run -d train.py --img 416 --batch 8 --epochs 10 --data ../Regurgitation-YOLODataset-1new/data.yaml --cfg ./models/yolov5s.yaml --name yolov5s_test --cache\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ce038e-184d-4e1a-8909-39c482900274",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "!python train.py --img 416 --batch 8 --epochs 10 --data ../demo/data.yaml --cfg ./models/yolov5s.yaml  --name yolov5s_test --cache \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75f811a3-5442-48cc-9ba5-47c4ae51d1fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Blank or comment\n",
      "*** Blank or comment\n",
      "*** Blank or comment\n",
      "NOTE: Enter 'c' at the ipdb>  prompt to continue execution.\n",
      "> \u001b[1;32mc:\\users\\darks\\desktop\\yolov5test\\yolov5c\\train.py\u001b[0m(2)\u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m      1 \u001b[1;33m\u001b[1;31m# YOLOv5 ðŸš€ by Ultralytics, AGPL-3.0 license\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m----> 2 \u001b[1;33m\"\"\"\n",
      "\u001b[0m\u001b[1;32m      3 \u001b[1;33m\u001b[0mTrain\u001b[0m \u001b[0ma\u001b[0m \u001b[0mYOLOv5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0mcustom\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      4 \u001b[1;33m\u001b[0mModels\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0mdownload\u001b[0m \u001b[0mautomatically\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlatest\u001b[0m \u001b[0mYOLOv5\u001b[0m \u001b[0mrelease\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      5 \u001b[1;33m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=./models/yolov5sc.yaml, data=../demo/data.yaml, hyp=data\\hyps\\hyp.scratch-low.yaml, epochs=100, batch_size=8, imgsz=416, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs\\train, name=yolov5s_test, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "YOLOv5  2024-3-7 Python-3.8.19 torch-2.3.0+cpu CPU\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=5.0, translate=0.1, scale=0.0, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.0, mosaic=0.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5  runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\train', view at http://localhost:6006/\n",
      "Overriding model.yaml nc=4 with nc=2\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  5                -1  1    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  6                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  7                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mgithub: \u001b[0mskipping check (not a git repository), for updates see https://github.com/ultralytics/yolov5\n",
      "Layer 0: f=-1, ch=[3]\n",
      "Checking f=-1 at layer i=0\n",
      "Layer 1: f=-1, ch=[32]\n",
      "Checking f=-1 at layer i=1\n",
      "Layer 2: f=-1, ch=[32, 64]\n",
      "Checking f=-1 at layer i=2\n",
      "Layer 3: f=-1, ch=[32, 64, 64]\n",
      "Checking f=-1 at layer i=3\n",
      "Layer 4: f=-1, ch=[32, 64, 64, 128]\n",
      "Checking f=-1 at layer i=4\n",
      "Layer 5: f=-1, ch=[32, 64, 64, 128, 256]\n",
      "Checking f=-1 at layer i=5\n",
      "Layer 6: f=-1, ch=[32, 64, 64, 128, 256, 256]\n",
      "Checking f=-1 at layer i=6\n",
      "Layer 7: f=-1, ch=[32, 64, 64, 128, 256, 256, 512]\n",
      "Checking f=-1 at layer i=7\n",
      "Layer 8: f=-1, ch=[32, 64, 64, 128, 256, 256, 512, 512]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      "  9                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 10                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 11           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 12                -1  1    427520  models.common.C3                        [768, 256, 1, False]          \n",
      " 13                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 14                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 15           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 16                -1  1    107264  models.common.C3                        [384, 128, 1, False]          \n",
      " 17                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 18          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 19                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 20                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 21          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 22                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 23                17  1       387  models.common.YOLOv5WithClassification  [128, 3]                      \n",
      " 24      [17, 20, 23]  1      8190  models.yolo.Detect                      [2, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 3]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking f=-1 at layer i=8\n",
      "Layer 9: f=-1, ch=[32, 64, 64, 128, 256, 256, 512, 512, 512]\n",
      "Checking f=-1 at layer i=9\n",
      "Layer 10: f=-1, ch=[32, 64, 64, 128, 256, 256, 512, 512, 512, 256]\n",
      "Checking f=-1 at layer i=10\n",
      "Layer 11: f=[-1, 6], ch=[32, 64, 64, 128, 256, 256, 512, 512, 512, 256, 256]\n",
      "Checking list f=[-1, 6] at layer i=11\n",
      "Layer 12: f=-1, ch=[32, 64, 64, 128, 256, 256, 512, 512, 512, 256, 256, 768]\n",
      "Checking f=-1 at layer i=12\n",
      "Layer 13: f=-1, ch=[32, 64, 64, 128, 256, 256, 512, 512, 512, 256, 256, 768, 256]\n",
      "Checking f=-1 at layer i=13\n",
      "Layer 14: f=-1, ch=[32, 64, 64, 128, 256, 256, 512, 512, 512, 256, 256, 768, 256, 128]\n",
      "Checking f=-1 at layer i=14\n",
      "Layer 15: f=[-1, 4], ch=[32, 64, 64, 128, 256, 256, 512, 512, 512, 256, 256, 768, 256, 128, 128]\n",
      "Checking list f=[-1, 4] at layer i=15\n",
      "Layer 16: f=-1, ch=[32, 64, 64, 128, 256, 256, 512, 512, 512, 256, 256, 768, 256, 128, 128, 384]\n",
      "Checking f=-1 at layer i=16\n",
      "Layer 17: f=-1, ch=[32, 64, 64, 128, 256, 256, 512, 512, 512, 256, 256, 768, 256, 128, 128, 384, 128]\n",
      "Checking f=-1 at layer i=17\n",
      "Layer 18: f=[-1, 14], ch=[32, 64, 64, 128, 256, 256, 512, 512, 512, 256, 256, 768, 256, 128, 128, 384, 128, 128]\n",
      "Checking list f=[-1, 14] at layer i=18\n",
      "Layer 19: f=-1, ch=[32, 64, 64, 128, 256, 256, 512, 512, 512, 256, 256, 768, 256, 128, 128, 384, 128, 128, 256]\n",
      "Checking f=-1 at layer i=19\n",
      "Layer 20: f=-1, ch=[32, 64, 64, 128, 256, 256, 512, 512, 512, 256, 256, 768, 256, 128, 128, 384, 128, 128, 256, 256]\n",
      "Checking f=-1 at layer i=20\n",
      "Layer 21: f=[-1, 10], ch=[32, 64, 64, 128, 256, 256, 512, 512, 512, 256, 256, 768, 256, 128, 128, 384, 128, 128, 256, 256, 256]\n",
      "Checking list f=[-1, 10] at layer i=21\n",
      "Layer 22: f=-1, ch=[32, 64, 64, 128, 256, 256, 512, 512, 512, 256, 256, 768, 256, 128, 128, 384, 128, 128, 256, 256, 256, 512]\n",
      "Checking f=-1 at layer i=22\n",
      "Layer 23: f=17, ch=[32, 64, 64, 128, 256, 256, 512, 512, 512, 256, 256, 768, 256, 128, 128, 384, 128, 128, 256, 256, 256, 512, 512]\n",
      "Checking f=17 at layer i=23\n",
      "Layer 24: f=[17, 20, 23], ch=[32, 64, 64, 128, 256, 256, 512, 512, 512, 256, 256, 768, 256, 128, 128, 384, 128, 128, 256, 256, 256, 512, 512, 3]\n",
      "Checking list f=[17, 20, 23] at layer i=24\n",
      "Model Layers and Connections:\n",
      "Layer 0: m.f=-1, m.type=models.common.Conv, m=Conv(\n",
      "  (conv): Conv2d(3, 32, kernel_size=(6, 6), stride=(2, 2), padding=(2, 2), bias=False)\n",
      "  (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act): SiLU()\n",
      ")\n",
      "Layer 1: m.f=-1, m.type=models.common.Conv, m=Conv(\n",
      "  (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act): SiLU()\n",
      ")\n",
      "Layer 2: m.f=-1, m.type=models.common.C3, m=C3(\n",
      "  (cv1): Conv(\n",
      "    (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): SiLU()\n",
      "  )\n",
      "  (cv2): Conv(\n",
      "    (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): SiLU()\n",
      "  )\n",
      "  (cv3): Conv(\n",
      "    (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): SiLU()\n",
      "  )\n",
      "  (m): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Layer 3: m.f=-1, m.type=models.common.Conv, m=Conv(\n",
      "  (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act): SiLU()\n",
      ")\n",
      "Layer 4: m.f=-1, m.type=models.common.Conv, m=Conv(\n",
      "  (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act): SiLU()\n",
      ")\n",
      "Layer 5: m.f=-1, m.type=models.common.C3, m=C3(\n",
      "  (cv1): Conv(\n",
      "    (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): SiLU()\n",
      "  )\n",
      "  (cv2): Conv(\n",
      "    (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): SiLU()\n",
      "  )\n",
      "  (cv3): Conv(\n",
      "    (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): SiLU()\n",
      "  )\n",
      "  (m): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Layer 6: m.f=-1, m.type=models.common.Conv, m=Conv(\n",
      "  (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act): SiLU()\n",
      ")\n",
      "Layer 7: m.f=-1, m.type=models.common.C3, m=C3(\n",
      "  (cv1): Conv(\n",
      "    (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): SiLU()\n",
      "  )\n",
      "  (cv2): Conv(\n",
      "    (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): SiLU()\n",
      "  )\n",
      "  (cv3): Conv(\n",
      "    (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): SiLU()\n",
      "  )\n",
      "  (m): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Layer 8: m.f=-1, m.type=models.common.SPPF, m=SPPF(\n",
      "  (cv1): Conv(\n",
      "    (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): SiLU()\n",
      "  )\n",
      "  (cv2): Conv(\n",
      "    (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): SiLU()\n",
      "  )\n",
      "  (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
      ")\n",
      "Layer 9: m.f=-1, m.type=models.common.Conv, m=Conv(\n",
      "  (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act): SiLU()\n",
      ")\n",
      "Layer 10: m.f=-1, m.type=torch.nn.modules.upsampling.Upsample, m=Upsample(scale_factor=2.0, mode='nearest')\n",
      "Layer 11: m.f=[-1, 6], m.type=models.common.Concat, m=Concat()\n",
      "Layer 12: m.f=-1, m.type=models.common.C3, m=C3(\n",
      "  (cv1): Conv(\n",
      "    (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): SiLU()\n",
      "  )\n",
      "  (cv2): Conv(\n",
      "    (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): SiLU()\n",
      "  )\n",
      "  (cv3): Conv(\n",
      "    (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): SiLU()\n",
      "  )\n",
      "  (m): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Layer 13: m.f=-1, m.type=models.common.Conv, m=Conv(\n",
      "  (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act): SiLU()\n",
      ")\n",
      "Layer 14: m.f=-1, m.type=torch.nn.modules.upsampling.Upsample, m=Upsample(scale_factor=2.0, mode='nearest')\n",
      "Layer 15: m.f=[-1, 4], m.type=models.common.Concat, m=Concat()\n",
      "Layer 16: m.f=-1, m.type=models.common.C3, m=C3(\n",
      "  (cv1): Conv(\n",
      "    (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): SiLU()\n",
      "  )\n",
      "  (cv2): Conv(\n",
      "    (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): SiLU()\n",
      "  )\n",
      "  (cv3): Conv(\n",
      "    (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): SiLU()\n",
      "  )\n",
      "  (m): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Layer 17: m.f=-1, m.type=models.common.Conv, m=Conv(\n",
      "  (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act): SiLU()\n",
      ")\n",
      "Layer 18: m.f=[-1, 14], m.type=models.common.Concat, m=Concat()\n",
      "Layer 19: m.f=-1, m.type=models.common.C3, m=C3(\n",
      "  (cv1): Conv(\n",
      "    (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): SiLU()\n",
      "  )\n",
      "  (cv2): Conv(\n",
      "    (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): SiLU()\n",
      "  )\n",
      "  (cv3): Conv(\n",
      "    (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): SiLU()\n",
      "  )\n",
      "  (m): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Layer 20: m.f=-1, m.type=models.common.Conv, m=Conv(\n",
      "  (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act): SiLU()\n",
      ")\n",
      "Layer 21: m.f=[-1, 10], m.type=models.common.Concat, m=Concat()\n",
      "Layer 22: m.f=-1, m.type=models.common.C3, m=C3(\n",
      "  (cv1): Conv(\n",
      "    (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): SiLU()\n",
      "  )\n",
      "  (cv2): Conv(\n",
      "    (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): SiLU()\n",
      "  )\n",
      "  (cv3): Conv(\n",
      "    (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): SiLU()\n",
      "  )\n",
      "  (m): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Layer 23: m.f=17, m.type=models.common.YOLOv5WithClassification, m=YOLOv5WithClassification(\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc): Linear(in_features=128, out_features=3, bias=True)\n",
      ")\n",
      "Layer 24: m.f=[17, 20, 23], m.type=models.yolo.Detect, m=Detect(\n",
      "  (m): ModuleList(\n",
      "    (0): Conv2d(128, 21, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): Conv2d(256, 21, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (2): Conv2d(3, 21, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "Processing Layer 0: m.f=-1, len(y)=0\n",
      "Processing Layer 1: m.f=-1, len(y)=1\n",
      "Processing Layer 2: m.f=-1, len(y)=2\n",
      "Processing Layer 3: m.f=-1, len(y)=3\n",
      "Processing Layer 4: m.f=-1, len(y)=4\n",
      "Processing Layer 5: m.f=-1, len(y)=5\n",
      "Processing Layer 6: m.f=-1, len(y)=6\n",
      "Processing Layer 7: m.f=-1, len(y)=7\n",
      "Processing Layer 8: m.f=-1, len(y)=8\n",
      "Processing Layer 9: m.f=-1, len(y)=9\n",
      "Processing Layer 10: m.f=-1, len(y)=10\n",
      "Processing Layer 11: m.f=[-1, 6], len(y)=11\n",
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\yolo\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2866\u001b[0m, in \u001b[0;36mInteractiveShell.safe_execfile\u001b[1;34m(self, fname, exit_ignore, raise_exceptions, shell_futures, *where)\u001b[0m\n",
      "\u001b[0;32m   2864\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m   2865\u001b[0m     glob, loc \u001b[38;5;241m=\u001b[39m (where \u001b[38;5;241m+\u001b[39m (\u001b[38;5;28;01mNone\u001b[39;00m, ))[:\u001b[38;5;241m2\u001b[39m]\n",
      "\u001b[1;32m-> 2866\u001b[0m     \u001b[43mpy3compat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecfile\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[0;32m   2867\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloc\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   2868\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mshell_futures\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m   2869\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mSystemExit\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m status:\n",
      "\u001b[0;32m   2870\u001b[0m     \u001b[38;5;66;03m# If the call was made with 0 or None exit status (sys.exit(0)\u001b[39;00m\n",
      "\u001b[0;32m   2871\u001b[0m     \u001b[38;5;66;03m# or sys.exit() ), don't bother showing a traceback, as both of\u001b[39;00m\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m   2877\u001b[0m     \u001b[38;5;66;03m# For other exit status, we show the exception unless\u001b[39;00m\n",
      "\u001b[0;32m   2878\u001b[0m     \u001b[38;5;66;03m# explicitly silenced, but only in short form.\u001b[39;00m\n",
      "\u001b[0;32m   2879\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status\u001b[38;5;241m.\u001b[39mcode:\n",
      "\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\yolo\\lib\\site-packages\\IPython\\utils\\py3compat.py:55\u001b[0m, in \u001b[0;36mexecfile\u001b[1;34m(fname, glob, loc, compiler)\u001b[0m\n",
      "\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(fname, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[0;32m     54\u001b[0m     compiler \u001b[38;5;241m=\u001b[39m compiler \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mcompile\u001b[39m\n",
      "\u001b[1;32m---> 55\u001b[0m     \u001b[43mexec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompiler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexec\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloc\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[1;32m~\\Desktop\\yolov5test\\yolov5c\\train.py:2\u001b[0m\n",
      "\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# YOLOv5 ðŸš€ by Ultralytics, AGPL-3.0 license\u001b[39;00m\n",
      "\u001b[1;32m----> 2\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
      "\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mTrain a YOLOv5 model on a custom dataset.\u001b[39;00m\n",
      "\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03mModels and datasets download automatically from the latest YOLOv5 release.\u001b[39;00m\n",
      "\u001b[0;32m      5\u001b[0m \n",
      "\u001b[0;32m      6\u001b[0m \u001b[38;5;124;03mUsage - Single-GPU training:\u001b[39;00m\n",
      "\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03m    $ python train.py --data coco128.yaml --weights yolov5s.pt --img 640  # from pretrained (recommended)\u001b[39;00m\n",
      "\u001b[0;32m      8\u001b[0m \u001b[38;5;124;03m    $ python train.py --data coco128.yaml --weights '' --cfg yolov5s.yaml --img 640  # from scratch\u001b[39;00m\n",
      "\u001b[0;32m      9\u001b[0m \n",
      "\u001b[0;32m     10\u001b[0m \u001b[38;5;124;03mUsage - Multi-GPU DDP training:\u001b[39;00m\n",
      "\u001b[0;32m     11\u001b[0m \u001b[38;5;124;03m    $ python -m torch.distributed.run --nproc_per_node 4 --master_port 1 train.py --data coco128.yaml --weights yolov5s.pt --img 640 --device 0,1,2,3\u001b[39;00m\n",
      "\u001b[0;32m     12\u001b[0m \n",
      "\u001b[0;32m     13\u001b[0m \u001b[38;5;124;03mModels:     https://github.com/ultralytics/yolov5/tree/master/models\u001b[39;00m\n",
      "\u001b[0;32m     14\u001b[0m \u001b[38;5;124;03mDatasets:   https://github.com/ultralytics/yolov5/tree/master/data\u001b[39;00m\n",
      "\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03mTutorial:   https://docs.ultralytics.com/yolov5/tutorials/train_custom_data\u001b[39;00m\n",
      "\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
      "\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01margparse\u001b[39;00m\n",
      "\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n",
      "\n",
      "File \u001b[1;32m~\\Desktop\\yolov5test\\yolov5c\\train.py:603\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(opt, callbacks)\u001b[0m\n",
      "\u001b[0;32m    601\u001b[0m \u001b[38;5;66;03m# Train\u001b[39;00m\n",
      "\u001b[0;32m    602\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt\u001b[38;5;241m.\u001b[39mevolve:\n",
      "\u001b[1;32m--> 603\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m    605\u001b[0m \u001b[38;5;66;03m# Evolve hyperparameters (optional)\u001b[39;00m\n",
      "\u001b[0;32m    606\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m    607\u001b[0m     \u001b[38;5;66;03m# Hyperparameter evolution metadata (mutation scale 0-1, lower_limit, upper_limit)\u001b[39;00m\n",
      "\u001b[0;32m    608\u001b[0m     meta \u001b[38;5;241m=\u001b[39m {\n",
      "\u001b[0;32m    609\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr0\u001b[39m\u001b[38;5;124m'\u001b[39m: (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1e-5\u001b[39m, \u001b[38;5;241m1e-1\u001b[39m),  \u001b[38;5;66;03m# initial learning rate (SGD=1E-2, Adam=1E-3)\u001b[39;00m\n",
      "\u001b[0;32m    610\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlrf\u001b[39m\u001b[38;5;124m'\u001b[39m: (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m1.0\u001b[39m),  \u001b[38;5;66;03m# final OneCycleLR learning rate (lr0 * lrf)\u001b[39;00m\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m    636\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmixup\u001b[39m\u001b[38;5;124m'\u001b[39m: (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m1.0\u001b[39m),  \u001b[38;5;66;03m# image mixup (probability)\u001b[39;00m\n",
      "\u001b[0;32m    637\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcopy_paste\u001b[39m\u001b[38;5;124m'\u001b[39m: (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m1.0\u001b[39m)}  \u001b[38;5;66;03m# segment copy-paste (probability)\u001b[39;00m\n",
      "\n",
      "File \u001b[1;32m~\\Desktop\\yolov5test\\yolov5c\\train.py:131\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(hyp, opt, device, callbacks)\u001b[0m\n",
      "\u001b[0;32m    129\u001b[0m     weights \u001b[38;5;241m=\u001b[39m attempt_download(weights)  \u001b[38;5;66;03m# download if not found locally\u001b[39;00m\n",
      "\u001b[0;32m    130\u001b[0m ckpt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(weights, map_location\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# load checkpoint to CPU to avoid CUDA memory leak\u001b[39;00m\n",
      "\u001b[1;32m--> 131\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mckpt\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43myaml\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manchors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhyp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43manchors\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# create\u001b[39;00m\n",
      "\u001b[0;32m    132\u001b[0m model\u001b[38;5;241m.\u001b[39mhyp \u001b[38;5;241m=\u001b[39m hyp\n",
      "\u001b[0;32m    133\u001b[0m exclude \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manchor\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m (cfg \u001b[38;5;129;01mor\u001b[39;00m hyp\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manchors\u001b[39m\u001b[38;5;124m'\u001b[39m)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m resume \u001b[38;5;28;01melse\u001b[39;00m []  \u001b[38;5;66;03m# exclude keys\u001b[39;00m\n",
      "\n",
      "File \u001b[1;32m~\\Desktop\\yolov5test\\yolov5c\\models\\yolo.py:224\u001b[0m, in \u001b[0;36mDetectionModel.__init__\u001b[1;34m(self, cfg, ch, nc, anchors)\u001b[0m\n",
      "\u001b[0;32m    222\u001b[0m \u001b[38;5;66;03m# ### DEBUG: Show the final outputs from the dummy forward\u001b[39;00m\n",
      "\u001b[0;32m    223\u001b[0m dummy_input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m1\u001b[39m, ch, s, s)\n",
      "\u001b[1;32m--> 224\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mforward_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdummy_input\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n",
      "\u001b[0;32m    226\u001b[0m     LOGGER\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--- Debug: model forward outputs: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(out)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m items ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\n",
      "File \u001b[1;32m~\\Desktop\\yolov5test\\yolov5c\\models\\yolo.py:264\u001b[0m, in \u001b[0;36mDetectionModel.forward\u001b[1;34m(self, x, augment, profile, visualize)\u001b[0m\n",
      "\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m augment:\n",
      "\u001b[0;32m    263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_augment(x)\n",
      "\u001b[1;32m--> 264\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[1;32m~\\Desktop\\yolov5test\\yolov5c\\models\\yolo.py:140\u001b[0m, in \u001b[0;36mBaseModel._forward_once\u001b[1;34m(self, x, profile, visualize)\u001b[0m\n",
      "\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile:\n",
      "\u001b[0;32m    139\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_one_layer(m, x, dt)  \u001b[38;5;66;03m# profile layer timing\u001b[39;00m\n",
      "\u001b[1;32m--> 140\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# run the module\u001b[39;00m\n",
      "\u001b[0;32m    141\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(x \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output if required\u001b[39;00m\n",
      "\u001b[0;32m    142\u001b[0m \u001b[38;5;66;03m# Optional: visualize intermediate features\u001b[39;00m\n",
      "\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\yolo\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
      "\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\yolo\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n",
      "\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n",
      "\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n",
      "\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n",
      "\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n",
      "\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\n",
      "File \u001b[1;32m~\\Desktop\\yolov5test\\yolov5c\\models\\common.py:332\u001b[0m, in \u001b[0;36mConcat.forward\u001b[1;34m(self, x)\u001b[0m\n",
      "\u001b[0;32m    331\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n",
      "\u001b[1;32m--> 332\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 16 but got size 8 for tensor number 1 in the list.\n"
     ]
    }
   ],
   "source": [
    "%run -d train.py --img 416 --batch 8 --epochs 100 --data ../demo/data.yaml --cfg ./models/yolov5sc.yaml --name yolov5s_test --cache\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38353da-be77-4ddb-adb5-556500b16ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -d train.py --img 416 --batch 8\n",
    "IndexError: index 1 is out of boun --epochs 10 --data ../demo/data.yaml --cfg ./models/yolov5sc2.yaml --name yolov5s_test --cache\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc0ba433-8963-4511-9aee-adbdb29ec6e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\darks\\Desktop\\yolov5test\\yolov5\n"
     ]
    }
   ],
   "source": [
    "%cd C:\\Users\\darks\\Desktop\\yolov5test\\yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de223c3-0135-47cd-a1a4-830fe3580ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Blank or comment\n",
      "*** Blank or comment\n",
      "*** Blank or comment\n",
      "NOTE: Enter 'c' at the ipdb>  prompt to continue execution.\n",
      "> \u001b[1;32mc:\\users\\darks\\desktop\\yolov5test\\yolov5c\\train.py\u001b[0m(2)\u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m      1 \u001b[1;33m\u001b[1;31m# YOLOv5 ðŸš€ by Ultralytics, AGPL-3.0 license\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m----> 2 \u001b[1;33m\"\"\"\n",
      "\u001b[0m\u001b[1;32m      3 \u001b[1;33m\u001b[0mTrain\u001b[0m \u001b[0ma\u001b[0m \u001b[0mYOLOv5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0mcustom\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      4 \u001b[1;33m\u001b[0mModels\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0mdownload\u001b[0m \u001b[0mautomatically\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlatest\u001b[0m \u001b[0mYOLOv5\u001b[0m \u001b[0mrelease\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      5 \u001b[1;33m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    }
   ],
   "source": [
    "%run -d train.py --img 416 --batch 8 --epochs 100 --data ../Regurgitation-YOLODataset-1new/data.yaml --cfg ./models/yolov5sc.yaml --name yolov5s_test --cache\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ac6e533-2c05-47db-b190-2270603aa4d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Blank or comment\n",
      "*** Blank or comment\n",
      "*** Blank or comment\n",
      "NOTE: Enter 'c' at the ipdb>  prompt to continue execution.\n",
      "> \u001b[1;32mc:\\users\\darks\\desktop\\yolov5test\\yolov5c\\train.py\u001b[0m(2)\u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m      1 \u001b[1;33m\u001b[1;31m# YOLOv5 ðŸš€ by Ultralytics, AGPL-3.0 license\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m----> 2 \u001b[1;33m\"\"\"\n",
      "\u001b[0m\u001b[1;32m      3 \u001b[1;33m\u001b[0mTrain\u001b[0m \u001b[0ma\u001b[0m \u001b[0mYOLOv5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0mcustom\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      4 \u001b[1;33m\u001b[0mModels\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0mdownload\u001b[0m \u001b[0mautomatically\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlatest\u001b[0m \u001b[0mYOLOv5\u001b[0m \u001b[0mrelease\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      5 \u001b[1;33m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=./models/yolov5sc.yaml, data=../Regurgitation-YOLODataset-1new/data.yaml, hyp=data/hyps/hyp.custom.yaml, epochs=10, batch_size=8, imgsz=416, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs\\train, name=yolov5s_test, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "YOLOv5  2024-3-7 Python-3.8.19 torch-2.3.0+cpu CPU\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.0157, lrf=0.0112, momentum=0.98, weight_decay=0.00052, warmup_epochs=2.36, warmup_momentum=0.734, warmup_bias_lr=0.162, box=0.0606, cls=0.731, cls_pw=1.22, obj=1.3, obj_pw=0.79, iou_t=0.2, anchor_t=4.27, fl_gamma=1.5, hsv_h=0.0143, hsv_s=0.7, hsv_v=0.515, degrees=4.78, translate=0.12, scale=0.0, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.0, mosaic=0.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5  runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\train', view at http://localhost:6006/\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mgithub: \u001b[0mskipping check (not a git repository), for updates see https://github.com/ultralytics/yolov5\n",
      "Layer 0: f=-1, ch=[3]\n",
      "Checking f=-1 at layer i=0\n",
      "Layer 1: f=-1, ch=[32]\n",
      "Checking f=-1 at layer i=1\n",
      "Layer 2: f=-1, ch=[32, 64]\n",
      "Checking f=-1 at layer i=2\n",
      "Layer 3: f=-1, ch=[32, 64, 64]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24                17  1       387  models.common.YOLOv5WithClassification  [128, 3]                      \n",
      " 25      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "--- Debug: model forward outputs: 3 items ---\n",
      "    Output 0 shape: [1, 3, 32, 32, 9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking f=-1 at layer i=3\n",
      "Layer 4: f=-1, ch=[32, 64, 64, 128]\n",
      "Checking f=-1 at layer i=4\n",
      "Layer 5: f=-1, ch=[32, 64, 64, 128, 128]\n",
      "Checking f=-1 at layer i=5\n",
      "Layer 6: f=-1, ch=[32, 64, 64, 128, 128, 256]\n",
      "Checking f=-1 at layer i=6\n",
      "Layer 7: f=-1, ch=[32, 64, 64, 128, 128, 256, 256]\n",
      "Checking f=-1 at layer i=7\n",
      "Layer 8: f=-1, ch=[32, 64, 64, 128, 128, 256, 256, 512]\n",
      "Checking f=-1 at layer i=8\n",
      "Layer 9: f=-1, ch=[32, 64, 64, 128, 128, 256, 256, 512, 512]\n",
      "Checking f=-1 at layer i=9\n",
      "Layer 10: f=-1, ch=[32, 64, 64, 128, 128, 256, 256, 512, 512, 512]\n",
      "Checking f=-1 at layer i=10\n",
      "Layer 11: f=-1, ch=[32, 64, 64, 128, 128, 256, 256, 512, 512, 512, 256]\n",
      "Checking f=-1 at layer i=11\n",
      "Layer 12: f=[-1, 6], ch=[32, 64, 64, 128, 128, 256, 256, 512, 512, 512, 256, 256]\n",
      "Checking list f=[-1, 6] at layer i=12\n",
      "Layer 13: f=-1, ch=[32, 64, 64, 128, 128, 256, 256, 512, 512, 512, 256, 256, 512]\n",
      "Checking f=-1 at layer i=13\n",
      "Layer 14: f=-1, ch=[32, 64, 64, 128, 128, 256, 256, 512, 512, 512, 256, 256, 512, 256]\n",
      "Checking f=-1 at layer i=14\n",
      "Layer 15: f=-1, ch=[32, 64, 64, 128, 128, 256, 256, 512, 512, 512, 256, 256, 512, 256, 128]\n",
      "Checking f=-1 at layer i=15\n",
      "Layer 16: f=[-1, 4], ch=[32, 64, 64, 128, 128, 256, 256, 512, 512, 512, 256, 256, 512, 256, 128, 128]\n",
      "Checking list f=[-1, 4] at layer i=16\n",
      "Layer 17: f=-1, ch=[32, 64, 64, 128, 128, 256, 256, 512, 512, 512, 256, 256, 512, 256, 128, 128, 256]\n",
      "Checking f=-1 at layer i=17\n",
      "Layer 18: f=-1, ch=[32, 64, 64, 128, 128, 256, 256, 512, 512, 512, 256, 256, 512, 256, 128, 128, 256, 128]\n",
      "Checking f=-1 at layer i=18\n",
      "Layer 19: f=[-1, 14], ch=[32, 64, 64, 128, 128, 256, 256, 512, 512, 512, 256, 256, 512, 256, 128, 128, 256, 128, 128]\n",
      "Checking list f=[-1, 14] at layer i=19\n",
      "Layer 20: f=-1, ch=[32, 64, 64, 128, 128, 256, 256, 512, 512, 512, 256, 256, 512, 256, 128, 128, 256, 128, 128, 256]\n",
      "Checking f=-1 at layer i=20\n",
      "Layer 21: f=-1, ch=[32, 64, 64, 128, 128, 256, 256, 512, 512, 512, 256, 256, 512, 256, 128, 128, 256, 128, 128, 256, 256]\n",
      "Checking f=-1 at layer i=21\n",
      "Layer 22: f=[-1, 10], ch=[32, 64, 64, 128, 128, 256, 256, 512, 512, 512, 256, 256, 512, 256, 128, 128, 256, 128, 128, 256, 256, 256]\n",
      "Checking list f=[-1, 10] at layer i=22\n",
      "Layer 23: f=-1, ch=[32, 64, 64, 128, 128, 256, 256, 512, 512, 512, 256, 256, 512, 256, 128, 128, 256, 128, 128, 256, 256, 256, 512]\n",
      "Checking f=-1 at layer i=23\n",
      "Layer 24: f=17, ch=[32, 64, 64, 128, 128, 256, 256, 512, 512, 512, 256, 256, 512, 256, 128, 128, 256, 128, 128, 256, 256, 256, 512, 512]\n",
      "Checking f=17 at layer i=24\n",
      "Layer 25: f=[17, 20, 23], ch=[32, 64, 64, 128, 128, 256, 256, 512, 512, 512, 256, 256, 512, 256, 128, 128, 256, 128, 128, 256, 256, 256, 512, 512, 3]\n",
      "Checking list f=[17, 20, 23] at layer i=25\n",
      "Concat layer inputs: [torch.Size([1, 256, 16, 16]), torch.Size([1, 256, 16, 16])]\n",
      "Concat layer inputs: [torch.Size([1, 128, 32, 32]), torch.Size([1, 128, 32, 32])]\n",
      "Concat layer inputs: [torch.Size([1, 128, 16, 16]), torch.Size([1, 128, 16, 16])]\n",
      "Concat layer inputs: [torch.Size([1, 256, 8, 8]), torch.Size([1, 256, 8, 8])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Output 1 shape: [1, 3, 16, 16, 9]\n",
      "    Output 2 shape: [1, 3, 8, 8, 9]\n",
      "--- Debug: computed strides = [8.0, 16.0, 32.0] ---\n",
      "YOLOv5sc summary: 218 layers, 7030804 parameters, 7030804 gradients, 16.0 GFLOPs\n",
      "\n",
      "Transferred 342/351 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.0157) with parameter groups 57 weight(decay=0.0), 61 weight(decay=0.00052), 61 bias\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([1, 256, 16, 16]), torch.Size([1, 256, 16, 16])]\n",
      "Concat layer inputs: [torch.Size([1, 128, 32, 32]), torch.Size([1, 128, 32, 32])]\n",
      "Concat layer inputs: [torch.Size([1, 128, 16, 16]), torch.Size([1, 128, 16, 16])]\n",
      "Concat layer inputs: [torch.Size([1, 256, 8, 8]), torch.Size([1, 256, 8, 8])]\n",
      "Concat layer inputs: [torch.Size([1, 256, 2, 2]), torch.Size([1, 256, 2, 2])]\n",
      "Concat layer inputs: [torch.Size([1, 128, 4, 4]), torch.Size([1, 128, 4, 4])]\n",
      "Concat layer inputs: [torch.Size([1, 128, 2, 2]), torch.Size([1, 128, 2, 2])]\n",
      "Concat layer inputs: [torch.Size([1, 256, 1, 1]), torch.Size([1, 256, 1, 1])]\n",
      "\n",
      "[_make_grid Debug] i=0, nx=4, ny=4\n",
      "[_make_grid Debug] stride: tensor([ 8., 16., 32.])\n",
      "[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],\n",
      "         [ 2.00000,  3.75000],\n",
      "         [ 4.12500,  2.87500]],\n",
      "\n",
      "        [[ 1.87500,  3.81250],\n",
      "         [ 3.87500,  2.81250],\n",
      "         [ 3.68750,  7.43750]],\n",
      "\n",
      "        [[ 3.62500,  2.81250],\n",
      "         [ 4.87500,  6.18750],\n",
      "         [11.65625, 10.18750]]])\n",
      "[_make_grid Debug] anchor index i => anchors[i]: tensor([[1.25000, 1.62500],\n",
      "        [2.00000, 3.75000],\n",
      "        [4.12500, 2.87500]])\n",
      "self.anchors[i]: tensor([[1.25000, 1.62500],\n",
      "        [2.00000, 3.75000],\n",
      "        [4.12500, 2.87500]])\n",
      "self.stride[i]: tensor(8.)\n",
      "\n",
      "[_make_grid Debug] i=1, nx=2, ny=2\n",
      "[_make_grid Debug] stride: tensor([ 8., 16., 32.])\n",
      "[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],\n",
      "         [ 2.00000,  3.75000],\n",
      "         [ 4.12500,  2.87500]],\n",
      "\n",
      "        [[ 1.87500,  3.81250],\n",
      "         [ 3.87500,  2.81250],\n",
      "         [ 3.68750,  7.43750]],\n",
      "\n",
      "        [[ 3.62500,  2.81250],\n",
      "         [ 4.87500,  6.18750],\n",
      "         [11.65625, 10.18750]]])\n",
      "[_make_grid Debug] anchor index i => anchors[i]: tensor([[1.87500, 3.81250],\n",
      "        [3.87500, 2.81250],\n",
      "        [3.68750, 7.43750]])\n",
      "self.anchors[i]: tensor([[1.87500, 3.81250],\n",
      "        [3.87500, 2.81250],\n",
      "        [3.68750, 7.43750]])\n",
      "self.stride[i]: tensor(16.)\n",
      "\n",
      "[_make_grid Debug] i=2, nx=1, ny=1\n",
      "[_make_grid Debug] stride: tensor([ 8., 16., 32.])\n",
      "[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],\n",
      "         [ 2.00000,  3.75000],\n",
      "         [ 4.12500,  2.87500]],\n",
      "\n",
      "        [[ 1.87500,  3.81250],\n",
      "         [ 3.87500,  2.81250],\n",
      "         [ 3.68750,  7.43750]],\n",
      "\n",
      "        [[ 3.62500,  2.81250],\n",
      "         [ 4.87500,  6.18750],\n",
      "         [11.65625, 10.18750]]])\n",
      "[_make_grid Debug] anchor index i => anchors[i]: tensor([[ 3.62500,  2.81250],\n",
      "        [ 4.87500,  6.18750],\n",
      "        [11.65625, 10.18750]])\n",
      "self.anchors[i]: tensor([[ 3.62500,  2.81250],\n",
      "        [ 4.87500,  6.18750],\n",
      "        [11.65625, 10.18750]])\n",
      "self.stride[i]: tensor(32.)\n",
      "\n",
      "Model architecture:\n",
      "\n",
      "DetectionModel(\n",
      "  (model): Sequential(\n",
      "    (0): Conv(\n",
      "      (conv): Conv2d(3, 32, kernel_size=(6, 6), stride=(2, 2), padding=(2, 2), bias=False)\n",
      "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (1): Conv(\n",
      "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (2): C3(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv3): Conv(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Conv(\n",
      "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (4): C3(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv3): Conv(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Conv(\n",
      "      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (6): C3(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv3): Conv(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (1): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (2): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (7): Conv(\n",
      "      (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (8): C3(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv3): Conv(\n",
      "        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (9): SPPF(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (10): Conv(\n",
      "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (11): Upsample(scale_factor=2.0, mode='nearest')\n",
      "    (12): Concat()\n",
      "    (13): C3(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv3): Conv(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (14): Conv(\n",
      "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (15): Upsample(scale_factor=2.0, mode='nearest')\n",
      "    (16): Concat()\n",
      "    (17): C3(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv3): Conv(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (18): Conv(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (19): Concat()\n",
      "    (20): C3(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv3): Conv(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (21): Conv(\n",
      "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (22): Concat()\n",
      "    (23): C3(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv3): Conv(\n",
      "        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): Sequential(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (24): YOLOv5WithClassification(\n",
      "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc): Linear(in_features=128, out_features=3, bias=True)\n",
      "    )\n",
      "    (25): Detect(\n",
      "      (m): ModuleList(\n",
      "        (0): Conv2d(128, 27, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(256, 27, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (2): Conv2d(512, 27, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "End of model architecture.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\darks\\Desktop\\yolov5test\\Regurgitation-YOLODataset-1new\\train\\labels.cache... 1042 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1042/1042 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.4GB ram): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1042/1042 [00:00<00:00, 2173.19it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\darks\\Desktop\\yolov5test\\Regurgitation-YOLODataset-1new\\valid\\labels.cache... 183 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 183/183 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB ram): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 183/183 [00:00<00:00, 1451.85it/s]\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m3.17 anchors/target, 0.500 Best Possible Recall (BPR). Anchors are a poor fit to dataset , attempting to improve...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mWARNING  Extremely small objects found: 1040 of 2082 labels are <3 pixels in size\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 1042 points...\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.8851: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:00<00:00, 1767.24it/s]\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.23: 0.5005 best possible recall, 4.49 anchors past thr\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=416, metric_all=0.335/0.443-mean/best, past_thr=0.672-mean: 43,43, 51,61, 73,47, 65,57, 66,72, 86,59, 84,75, 74,94, 117,65\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone  (original anchors better than new anchors, proceeding with original anchors)\n",
      "Plotting labels to runs\\train\\yolov5s_test274\\labels.jpg... \n",
      "Image sizes 416 train, 416 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\train\\yolov5s_test274\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 131/131 [00:01<00:00, 66.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([2, 256, 26, 26]), torch.Size([2, 256, 26, 26])]\n",
      "Concat layer inputs: [torch.Size([2, 128, 52, 52]), torch.Size([2, 128, 52, 52])]\n",
      "Concat layer inputs: [torch.Size([2, 128, 26, 26]), torch.Size([2, 128, 26, 26])]\n",
      "Concat layer inputs: [torch.Size([2, 256, 13, 13]), torch.Size([2, 256, 13, 13])]\n",
      "detections[0].shape = torch.Size([2, 3, 52, 52, 9])\n",
      "detections[1].shape = torch.Size([2, 3, 26, 26, 9])\n",
      "detections[2].shape = torch.Size([2, 3, 13, 13, 9])\n",
      "detection_loss = 0.31155478954315186\n",
      "total_loss = 0.31155478954315186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 20, 28]), torch.Size([16, 256, 20, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 40, 56]), torch.Size([16, 128, 40, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 20, 28]), torch.Size([16, 128, 20, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 10, 14]), torch.Size([16, 256, 10, 14])]\n",
      "\n",
      "[_make_grid Debug] i=0, nx=56, ny=40\n",
      "[_make_grid Debug] stride: tensor([ 8., 16., 32.])\n",
      "[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],\n",
      "         [ 2.00000,  3.75000],\n",
      "         [ 4.12500,  2.87500]],\n",
      "\n",
      "        [[ 1.87500,  3.81250],\n",
      "         [ 3.87500,  2.81250],\n",
      "         [ 3.68750,  7.43750]],\n",
      "\n",
      "        [[ 3.62500,  2.81250],\n",
      "         [ 4.87500,  6.18750],\n",
      "         [11.65625, 10.18750]]])\n",
      "[_make_grid Debug] anchor index i => anchors[i]: tensor([[1.25000, 1.62500],\n",
      "        [2.00000, 3.75000],\n",
      "        [4.12500, 2.87500]])\n",
      "self.anchors[i]: tensor([[1.25000, 1.62500],\n",
      "        [2.00000, 3.75000],\n",
      "        [4.12500, 2.87500]])\n",
      "self.stride[i]: tensor(8.)\n",
      "\n",
      "[_make_grid Debug] i=1, nx=28, ny=20\n",
      "[_make_grid Debug] stride: tensor([ 8., 16., 32.])\n",
      "[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],\n",
      "         [ 2.00000,  3.75000],\n",
      "         [ 4.12500,  2.87500]],\n",
      "\n",
      "        [[ 1.87500,  3.81250],\n",
      "         [ 3.87500,  2.81250],\n",
      "         [ 3.68750,  7.43750]],\n",
      "\n",
      "        [[ 3.62500,  2.81250],\n",
      "         [ 4.87500,  6.18750],\n",
      "         [11.65625, 10.18750]]])\n",
      "[_make_grid Debug] anchor index i => anchors[i]: tensor([[1.87500, 3.81250],\n",
      "        [3.87500, 2.81250],\n",
      "        [3.68750, 7.43750]])\n",
      "self.anchors[i]: tensor([[1.87500, 3.81250],\n",
      "        [3.87500, 2.81250],\n",
      "        [3.68750, 7.43750]])\n",
      "self.stride[i]: tensor(16.)\n",
      "\n",
      "[_make_grid Debug] i=2, nx=14, ny=10\n",
      "[_make_grid Debug] stride: tensor([ 8., 16., 32.])\n",
      "[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],\n",
      "         [ 2.00000,  3.75000],\n",
      "         [ 4.12500,  2.87500]],\n",
      "\n",
      "        [[ 1.87500,  3.81250],\n",
      "         [ 3.87500,  2.81250],\n",
      "         [ 3.68750,  7.43750]],\n",
      "\n",
      "        [[ 3.62500,  2.81250],\n",
      "         [ 4.87500,  6.18750],\n",
      "         [11.65625, 10.18750]]])\n",
      "[_make_grid Debug] anchor index i => anchors[i]: tensor([[ 3.62500,  2.81250],\n",
      "        [ 4.87500,  6.18750],\n",
      "        [11.65625, 10.18750]])\n",
      "self.anchors[i]: tensor([[ 3.62500,  2.81250],\n",
      "        [ 4.87500,  6.18750],\n",
      "        [11.65625, 10.18750]])\n",
      "self.stride[i]: tensor(32.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   8%|â–Š         | 1/12 [00:01<00:15,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n",
      "\n",
      "[_make_grid Debug] i=0, nx=56, ny=44\n",
      "[_make_grid Debug] stride: tensor([ 8., 16., 32.])\n",
      "[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],\n",
      "         [ 2.00000,  3.75000],\n",
      "         [ 4.12500,  2.87500]],\n",
      "\n",
      "        [[ 1.87500,  3.81250],\n",
      "         [ 3.87500,  2.81250],\n",
      "         [ 3.68750,  7.43750]],\n",
      "\n",
      "        [[ 3.62500,  2.81250],\n",
      "         [ 4.87500,  6.18750],\n",
      "         [11.65625, 10.18750]]])\n",
      "[_make_grid Debug] anchor index i => anchors[i]: tensor([[1.25000, 1.62500],\n",
      "        [2.00000, 3.75000],\n",
      "        [4.12500, 2.87500]])\n",
      "self.anchors[i]: tensor([[1.25000, 1.62500],\n",
      "        [2.00000, 3.75000],\n",
      "        [4.12500, 2.87500]])\n",
      "self.stride[i]: tensor(8.)\n",
      "\n",
      "[_make_grid Debug] i=1, nx=28, ny=22\n",
      "[_make_grid Debug] stride: tensor([ 8., 16., 32.])\n",
      "[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],\n",
      "         [ 2.00000,  3.75000],\n",
      "         [ 4.12500,  2.87500]],\n",
      "\n",
      "        [[ 1.87500,  3.81250],\n",
      "         [ 3.87500,  2.81250],\n",
      "         [ 3.68750,  7.43750]],\n",
      "\n",
      "        [[ 3.62500,  2.81250],\n",
      "         [ 4.87500,  6.18750],\n",
      "         [11.65625, 10.18750]]])\n",
      "[_make_grid Debug] anchor index i => anchors[i]: tensor([[1.87500, 3.81250],\n",
      "        [3.87500, 2.81250],\n",
      "        [3.68750, 7.43750]])\n",
      "self.anchors[i]: tensor([[1.87500, 3.81250],\n",
      "        [3.87500, 2.81250],\n",
      "        [3.68750, 7.43750]])\n",
      "self.stride[i]: tensor(16.)\n",
      "\n",
      "[_make_grid Debug] i=2, nx=14, ny=11\n",
      "[_make_grid Debug] stride: tensor([ 8., 16., 32.])\n",
      "[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],\n",
      "         [ 2.00000,  3.75000],\n",
      "         [ 4.12500,  2.87500]],\n",
      "\n",
      "        [[ 1.87500,  3.81250],\n",
      "         [ 3.87500,  2.81250],\n",
      "         [ 3.68750,  7.43750]],\n",
      "\n",
      "        [[ 3.62500,  2.81250],\n",
      "         [ 4.87500,  6.18750],\n",
      "         [11.65625, 10.18750]]])\n",
      "[_make_grid Debug] anchor index i => anchors[i]: tensor([[ 3.62500,  2.81250],\n",
      "        [ 4.87500,  6.18750],\n",
      "        [11.65625, 10.18750]])\n",
      "self.anchors[i]: tensor([[ 3.62500,  2.81250],\n",
      "        [ 4.87500,  6.18750],\n",
      "        [11.65625, 10.18750]])\n",
      "self.stride[i]: tensor(32.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  17%|â–ˆâ–‹        | 2/12 [00:03<00:15,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  25%|â–ˆâ–ˆâ–Œ       | 3/12 [00:04<00:15,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 4/12 [00:06<00:13,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 5/12 [00:08<00:12,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 6/12 [00:10<00:10,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 7/12 [00:12<00:09,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 8/12 [00:14<00:07,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 9/12 [00:15<00:05,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 10/12 [00:17<00:03,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 11/12 [00:19<00:01,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([7, 256, 22, 28]), torch.Size([7, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([7, 128, 44, 56]), torch.Size([7, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([7, 128, 22, 28]), torch.Size([7, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([7, 256, 11, 14]), torch.Size([7, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:20<00:00,  1.70s/it]\n",
      "                   all        183        366   0.000116     0.0503   7.09e-05   7.82e-06\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 131/131 [00:02<00:00, 64.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([2, 256, 26, 26]), torch.Size([2, 256, 26, 26])]\n",
      "Concat layer inputs: [torch.Size([2, 128, 52, 52]), torch.Size([2, 128, 52, 52])]\n",
      "Concat layer inputs: [torch.Size([2, 128, 26, 26]), torch.Size([2, 128, 26, 26])]\n",
      "Concat layer inputs: [torch.Size([2, 256, 13, 13]), torch.Size([2, 256, 13, 13])]\n",
      "detections[0].shape = torch.Size([2, 3, 52, 52, 9])\n",
      "detections[1].shape = torch.Size([2, 3, 26, 26, 9])\n",
      "detections[2].shape = torch.Size([2, 3, 13, 13, 9])\n",
      "detection_loss = 0.3135240077972412\n",
      "total_loss = 0.3135240077972412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 20, 28]), torch.Size([16, 256, 20, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 40, 56]), torch.Size([16, 128, 40, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 20, 28]), torch.Size([16, 128, 20, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 10, 14]), torch.Size([16, 256, 10, 14])]\n",
      "\n",
      "[_make_grid Debug] i=0, nx=56, ny=40\n",
      "[_make_grid Debug] stride: tensor([ 8., 16., 32.])\n",
      "[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],\n",
      "         [ 2.00000,  3.75000],\n",
      "         [ 4.12500,  2.87500]],\n",
      "\n",
      "        [[ 1.87500,  3.81250],\n",
      "         [ 3.87500,  2.81250],\n",
      "         [ 3.68750,  7.43750]],\n",
      "\n",
      "        [[ 3.62500,  2.81250],\n",
      "         [ 4.87500,  6.18750],\n",
      "         [11.65625, 10.18750]]])\n",
      "[_make_grid Debug] anchor index i => anchors[i]: tensor([[1.25000, 1.62500],\n",
      "        [2.00000, 3.75000],\n",
      "        [4.12500, 2.87500]])\n",
      "self.anchors[i]: tensor([[1.25000, 1.62500],\n",
      "        [2.00000, 3.75000],\n",
      "        [4.12500, 2.87500]])\n",
      "self.stride[i]: tensor(8.)\n",
      "\n",
      "[_make_grid Debug] i=1, nx=28, ny=20\n",
      "[_make_grid Debug] stride: tensor([ 8., 16., 32.])\n",
      "[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],\n",
      "         [ 2.00000,  3.75000],\n",
      "         [ 4.12500,  2.87500]],\n",
      "\n",
      "        [[ 1.87500,  3.81250],\n",
      "         [ 3.87500,  2.81250],\n",
      "         [ 3.68750,  7.43750]],\n",
      "\n",
      "        [[ 3.62500,  2.81250],\n",
      "         [ 4.87500,  6.18750],\n",
      "         [11.65625, 10.18750]]])\n",
      "[_make_grid Debug] anchor index i => anchors[i]: tensor([[1.87500, 3.81250],\n",
      "        [3.87500, 2.81250],\n",
      "        [3.68750, 7.43750]])\n",
      "self.anchors[i]: tensor([[1.87500, 3.81250],\n",
      "        [3.87500, 2.81250],\n",
      "        [3.68750, 7.43750]])\n",
      "self.stride[i]: tensor(16.)\n",
      "\n",
      "[_make_grid Debug] i=2, nx=14, ny=10\n",
      "[_make_grid Debug] stride: tensor([ 8., 16., 32.])\n",
      "[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],\n",
      "         [ 2.00000,  3.75000],\n",
      "         [ 4.12500,  2.87500]],\n",
      "\n",
      "        [[ 1.87500,  3.81250],\n",
      "         [ 3.87500,  2.81250],\n",
      "         [ 3.68750,  7.43750]],\n",
      "\n",
      "        [[ 3.62500,  2.81250],\n",
      "         [ 4.87500,  6.18750],\n",
      "         [11.65625, 10.18750]]])\n",
      "[_make_grid Debug] anchor index i => anchors[i]: tensor([[ 3.62500,  2.81250],\n",
      "        [ 4.87500,  6.18750],\n",
      "        [11.65625, 10.18750]])\n",
      "self.anchors[i]: tensor([[ 3.62500,  2.81250],\n",
      "        [ 4.87500,  6.18750],\n",
      "        [11.65625, 10.18750]])\n",
      "self.stride[i]: tensor(32.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   8%|â–Š         | 1/12 [00:01<00:16,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n",
      "\n",
      "[_make_grid Debug] i=0, nx=56, ny=44\n",
      "[_make_grid Debug] stride: tensor([ 8., 16., 32.])\n",
      "[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],\n",
      "         [ 2.00000,  3.75000],\n",
      "         [ 4.12500,  2.87500]],\n",
      "\n",
      "        [[ 1.87500,  3.81250],\n",
      "         [ 3.87500,  2.81250],\n",
      "         [ 3.68750,  7.43750]],\n",
      "\n",
      "        [[ 3.62500,  2.81250],\n",
      "         [ 4.87500,  6.18750],\n",
      "         [11.65625, 10.18750]]])\n",
      "[_make_grid Debug] anchor index i => anchors[i]: tensor([[1.25000, 1.62500],\n",
      "        [2.00000, 3.75000],\n",
      "        [4.12500, 2.87500]])\n",
      "self.anchors[i]: tensor([[1.25000, 1.62500],\n",
      "        [2.00000, 3.75000],\n",
      "        [4.12500, 2.87500]])\n",
      "self.stride[i]: tensor(8.)\n",
      "\n",
      "[_make_grid Debug] i=1, nx=28, ny=22\n",
      "[_make_grid Debug] stride: tensor([ 8., 16., 32.])\n",
      "[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],\n",
      "         [ 2.00000,  3.75000],\n",
      "         [ 4.12500,  2.87500]],\n",
      "\n",
      "        [[ 1.87500,  3.81250],\n",
      "         [ 3.87500,  2.81250],\n",
      "         [ 3.68750,  7.43750]],\n",
      "\n",
      "        [[ 3.62500,  2.81250],\n",
      "         [ 4.87500,  6.18750],\n",
      "         [11.65625, 10.18750]]])\n",
      "[_make_grid Debug] anchor index i => anchors[i]: tensor([[1.87500, 3.81250],\n",
      "        [3.87500, 2.81250],\n",
      "        [3.68750, 7.43750]])\n",
      "self.anchors[i]: tensor([[1.87500, 3.81250],\n",
      "        [3.87500, 2.81250],\n",
      "        [3.68750, 7.43750]])\n",
      "self.stride[i]: tensor(16.)\n",
      "\n",
      "[_make_grid Debug] i=2, nx=14, ny=11\n",
      "[_make_grid Debug] stride: tensor([ 8., 16., 32.])\n",
      "[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],\n",
      "         [ 2.00000,  3.75000],\n",
      "         [ 4.12500,  2.87500]],\n",
      "\n",
      "        [[ 1.87500,  3.81250],\n",
      "         [ 3.87500,  2.81250],\n",
      "         [ 3.68750,  7.43750]],\n",
      "\n",
      "        [[ 3.62500,  2.81250],\n",
      "         [ 4.87500,  6.18750],\n",
      "         [11.65625, 10.18750]]])\n",
      "[_make_grid Debug] anchor index i => anchors[i]: tensor([[ 3.62500,  2.81250],\n",
      "        [ 4.87500,  6.18750],\n",
      "        [11.65625, 10.18750]])\n",
      "self.anchors[i]: tensor([[ 3.62500,  2.81250],\n",
      "        [ 4.87500,  6.18750],\n",
      "        [11.65625, 10.18750]])\n",
      "self.stride[i]: tensor(32.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  17%|â–ˆâ–‹        | 2/12 [00:03<00:17,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  25%|â–ˆâ–ˆâ–Œ       | 3/12 [00:05<00:17,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 4/12 [00:07<00:16,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 5/12 [00:09<00:14,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 6/12 [00:12<00:12,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 7/12 [00:14<00:10,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 8/12 [00:16<00:08,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 9/12 [00:18<00:06,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 10/12 [00:20<00:04,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 11/12 [00:22<00:01,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([7, 256, 22, 28]), torch.Size([7, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([7, 128, 44, 56]), torch.Size([7, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([7, 128, 22, 28]), torch.Size([7, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([7, 256, 11, 14]), torch.Size([7, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:22<00:00,  1.91s/it]\n",
      "                   all        183        366   7.73e-05     0.0272    5.1e-05   1.18e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 131/131 [00:01<00:00, 67.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([2, 256, 26, 26]), torch.Size([2, 256, 26, 26])]\n",
      "Concat layer inputs: [torch.Size([2, 128, 52, 52]), torch.Size([2, 128, 52, 52])]\n",
      "Concat layer inputs: [torch.Size([2, 128, 26, 26]), torch.Size([2, 128, 26, 26])]\n",
      "Concat layer inputs: [torch.Size([2, 256, 13, 13]), torch.Size([2, 256, 13, 13])]\n",
      "detections[0].shape = torch.Size([2, 3, 52, 52, 9])\n",
      "detections[1].shape = torch.Size([2, 3, 26, 26, 9])\n",
      "detections[2].shape = torch.Size([2, 3, 13, 13, 9])\n",
      "detection_loss = 0.2897293269634247\n",
      "total_loss = 0.2897293269634247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 20, 28]), torch.Size([16, 256, 20, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 40, 56]), torch.Size([16, 128, 40, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 20, 28]), torch.Size([16, 128, 20, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 10, 14]), torch.Size([16, 256, 10, 14])]\n",
      "\n",
      "[_make_grid Debug] i=0, nx=56, ny=40\n",
      "[_make_grid Debug] stride: tensor([ 8., 16., 32.])\n",
      "[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],\n",
      "         [ 2.00000,  3.75000],\n",
      "         [ 4.12500,  2.87500]],\n",
      "\n",
      "        [[ 1.87500,  3.81250],\n",
      "         [ 3.87500,  2.81250],\n",
      "         [ 3.68750,  7.43750]],\n",
      "\n",
      "        [[ 3.62500,  2.81250],\n",
      "         [ 4.87500,  6.18750],\n",
      "         [11.65625, 10.18750]]])\n",
      "[_make_grid Debug] anchor index i => anchors[i]: tensor([[1.25000, 1.62500],\n",
      "        [2.00000, 3.75000],\n",
      "        [4.12500, 2.87500]])\n",
      "self.anchors[i]: tensor([[1.25000, 1.62500],\n",
      "        [2.00000, 3.75000],\n",
      "        [4.12500, 2.87500]])\n",
      "self.stride[i]: tensor(8.)\n",
      "\n",
      "[_make_grid Debug] i=1, nx=28, ny=20\n",
      "[_make_grid Debug] stride: tensor([ 8., 16., 32.])\n",
      "[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],\n",
      "         [ 2.00000,  3.75000],\n",
      "         [ 4.12500,  2.87500]],\n",
      "\n",
      "        [[ 1.87500,  3.81250],\n",
      "         [ 3.87500,  2.81250],\n",
      "         [ 3.68750,  7.43750]],\n",
      "\n",
      "        [[ 3.62500,  2.81250],\n",
      "         [ 4.87500,  6.18750],\n",
      "         [11.65625, 10.18750]]])\n",
      "[_make_grid Debug] anchor index i => anchors[i]: tensor([[1.87500, 3.81250],\n",
      "        [3.87500, 2.81250],\n",
      "        [3.68750, 7.43750]])\n",
      "self.anchors[i]: tensor([[1.87500, 3.81250],\n",
      "        [3.87500, 2.81250],\n",
      "        [3.68750, 7.43750]])\n",
      "self.stride[i]: tensor(16.)\n",
      "\n",
      "[_make_grid Debug] i=2, nx=14, ny=10\n",
      "[_make_grid Debug] stride: tensor([ 8., 16., 32.])\n",
      "[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],\n",
      "         [ 2.00000,  3.75000],\n",
      "         [ 4.12500,  2.87500]],\n",
      "\n",
      "        [[ 1.87500,  3.81250],\n",
      "         [ 3.87500,  2.81250],\n",
      "         [ 3.68750,  7.43750]],\n",
      "\n",
      "        [[ 3.62500,  2.81250],\n",
      "         [ 4.87500,  6.18750],\n",
      "         [11.65625, 10.18750]]])\n",
      "[_make_grid Debug] anchor index i => anchors[i]: tensor([[ 3.62500,  2.81250],\n",
      "        [ 4.87500,  6.18750],\n",
      "        [11.65625, 10.18750]])\n",
      "self.anchors[i]: tensor([[ 3.62500,  2.81250],\n",
      "        [ 4.87500,  6.18750],\n",
      "        [11.65625, 10.18750]])\n",
      "self.stride[i]: tensor(32.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   8%|â–Š         | 1/12 [00:01<00:15,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n",
      "\n",
      "[_make_grid Debug] i=0, nx=56, ny=44\n",
      "[_make_grid Debug] stride: tensor([ 8., 16., 32.])\n",
      "[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],\n",
      "         [ 2.00000,  3.75000],\n",
      "         [ 4.12500,  2.87500]],\n",
      "\n",
      "        [[ 1.87500,  3.81250],\n",
      "         [ 3.87500,  2.81250],\n",
      "         [ 3.68750,  7.43750]],\n",
      "\n",
      "        [[ 3.62500,  2.81250],\n",
      "         [ 4.87500,  6.18750],\n",
      "         [11.65625, 10.18750]]])\n",
      "[_make_grid Debug] anchor index i => anchors[i]: tensor([[1.25000, 1.62500],\n",
      "        [2.00000, 3.75000],\n",
      "        [4.12500, 2.87500]])\n",
      "self.anchors[i]: tensor([[1.25000, 1.62500],\n",
      "        [2.00000, 3.75000],\n",
      "        [4.12500, 2.87500]])\n",
      "self.stride[i]: tensor(8.)\n",
      "\n",
      "[_make_grid Debug] i=1, nx=28, ny=22\n",
      "[_make_grid Debug] stride: tensor([ 8., 16., 32.])\n",
      "[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],\n",
      "         [ 2.00000,  3.75000],\n",
      "         [ 4.12500,  2.87500]],\n",
      "\n",
      "        [[ 1.87500,  3.81250],\n",
      "         [ 3.87500,  2.81250],\n",
      "         [ 3.68750,  7.43750]],\n",
      "\n",
      "        [[ 3.62500,  2.81250],\n",
      "         [ 4.87500,  6.18750],\n",
      "         [11.65625, 10.18750]]])\n",
      "[_make_grid Debug] anchor index i => anchors[i]: tensor([[1.87500, 3.81250],\n",
      "        [3.87500, 2.81250],\n",
      "        [3.68750, 7.43750]])\n",
      "self.anchors[i]: tensor([[1.87500, 3.81250],\n",
      "        [3.87500, 2.81250],\n",
      "        [3.68750, 7.43750]])\n",
      "self.stride[i]: tensor(16.)\n",
      "\n",
      "[_make_grid Debug] i=2, nx=14, ny=11\n",
      "[_make_grid Debug] stride: tensor([ 8., 16., 32.])\n",
      "[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],\n",
      "         [ 2.00000,  3.75000],\n",
      "         [ 4.12500,  2.87500]],\n",
      "\n",
      "        [[ 1.87500,  3.81250],\n",
      "         [ 3.87500,  2.81250],\n",
      "         [ 3.68750,  7.43750]],\n",
      "\n",
      "        [[ 3.62500,  2.81250],\n",
      "         [ 4.87500,  6.18750],\n",
      "         [11.65625, 10.18750]]])\n",
      "[_make_grid Debug] anchor index i => anchors[i]: tensor([[ 3.62500,  2.81250],\n",
      "        [ 4.87500,  6.18750],\n",
      "        [11.65625, 10.18750]])\n",
      "self.anchors[i]: tensor([[ 3.62500,  2.81250],\n",
      "        [ 4.87500,  6.18750],\n",
      "        [11.65625, 10.18750]])\n",
      "self.stride[i]: tensor(32.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  17%|â–ˆâ–‹        | 2/12 [00:03<00:16,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  25%|â–ˆâ–ˆâ–Œ       | 3/12 [00:05<00:15,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 4/12 [00:06<00:14,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 5/12 [00:08<00:12,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 6/12 [00:10<00:10,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 7/12 [00:12<00:09,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 8/12 [00:14<00:07,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 9/12 [00:16<00:05,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 10/12 [00:18<00:03,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 11/12 [00:20<00:01,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([7, 256, 22, 28]), torch.Size([7, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([7, 128, 44, 56]), torch.Size([7, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([7, 128, 22, 28]), torch.Size([7, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([7, 256, 11, 14]), torch.Size([7, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:21<00:00,  1.77s/it]\n",
      "                   all        183        366   0.000205     0.0575   0.000132   3.17e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 131/131 [00:01<00:00, 69.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([2, 256, 26, 26]), torch.Size([2, 256, 26, 26])]\n",
      "Concat layer inputs: [torch.Size([2, 128, 52, 52]), torch.Size([2, 128, 52, 52])]\n",
      "Concat layer inputs: [torch.Size([2, 128, 26, 26]), torch.Size([2, 128, 26, 26])]\n",
      "Concat layer inputs: [torch.Size([2, 256, 13, 13]), torch.Size([2, 256, 13, 13])]\n",
      "detections[0].shape = torch.Size([2, 3, 52, 52, 9])\n",
      "detections[1].shape = torch.Size([2, 3, 26, 26, 9])\n",
      "detections[2].shape = torch.Size([2, 3, 13, 13, 9])\n",
      "detection_loss = 0.3030201494693756\n",
      "total_loss = 0.3030201494693756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 20, 28]), torch.Size([16, 256, 20, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 40, 56]), torch.Size([16, 128, 40, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 20, 28]), torch.Size([16, 128, 20, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 10, 14]), torch.Size([16, 256, 10, 14])]\n",
      "\n",
      "[_make_grid Debug] i=0, nx=56, ny=40\n",
      "[_make_grid Debug] stride: tensor([ 8., 16., 32.])\n",
      "[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],\n",
      "         [ 2.00000,  3.75000],\n",
      "         [ 4.12500,  2.87500]],\n",
      "\n",
      "        [[ 1.87500,  3.81250],\n",
      "         [ 3.87500,  2.81250],\n",
      "         [ 3.68750,  7.43750]],\n",
      "\n",
      "        [[ 3.62500,  2.81250],\n",
      "         [ 4.87500,  6.18750],\n",
      "         [11.65625, 10.18750]]])\n",
      "[_make_grid Debug] anchor index i => anchors[i]: tensor([[1.25000, 1.62500],\n",
      "        [2.00000, 3.75000],\n",
      "        [4.12500, 2.87500]])\n",
      "self.anchors[i]: tensor([[1.25000, 1.62500],\n",
      "        [2.00000, 3.75000],\n",
      "        [4.12500, 2.87500]])\n",
      "self.stride[i]: tensor(8.)\n",
      "\n",
      "[_make_grid Debug] i=1, nx=28, ny=20\n",
      "[_make_grid Debug] stride: tensor([ 8., 16., 32.])\n",
      "[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],\n",
      "         [ 2.00000,  3.75000],\n",
      "         [ 4.12500,  2.87500]],\n",
      "\n",
      "        [[ 1.87500,  3.81250],\n",
      "         [ 3.87500,  2.81250],\n",
      "         [ 3.68750,  7.43750]],\n",
      "\n",
      "        [[ 3.62500,  2.81250],\n",
      "         [ 4.87500,  6.18750],\n",
      "         [11.65625, 10.18750]]])\n",
      "[_make_grid Debug] anchor index i => anchors[i]: tensor([[1.87500, 3.81250],\n",
      "        [3.87500, 2.81250],\n",
      "        [3.68750, 7.43750]])\n",
      "self.anchors[i]: tensor([[1.87500, 3.81250],\n",
      "        [3.87500, 2.81250],\n",
      "        [3.68750, 7.43750]])\n",
      "self.stride[i]: tensor(16.)\n",
      "\n",
      "[_make_grid Debug] i=2, nx=14, ny=10\n",
      "[_make_grid Debug] stride: tensor([ 8., 16., 32.])\n",
      "[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],\n",
      "         [ 2.00000,  3.75000],\n",
      "         [ 4.12500,  2.87500]],\n",
      "\n",
      "        [[ 1.87500,  3.81250],\n",
      "         [ 3.87500,  2.81250],\n",
      "         [ 3.68750,  7.43750]],\n",
      "\n",
      "        [[ 3.62500,  2.81250],\n",
      "         [ 4.87500,  6.18750],\n",
      "         [11.65625, 10.18750]]])\n",
      "[_make_grid Debug] anchor index i => anchors[i]: tensor([[ 3.62500,  2.81250],\n",
      "        [ 4.87500,  6.18750],\n",
      "        [11.65625, 10.18750]])\n",
      "self.anchors[i]: tensor([[ 3.62500,  2.81250],\n",
      "        [ 4.87500,  6.18750],\n",
      "        [11.65625, 10.18750]])\n",
      "self.stride[i]: tensor(32.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   8%|â–Š         | 1/12 [00:01<00:15,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n",
      "\n",
      "[_make_grid Debug] i=0, nx=56, ny=44\n",
      "[_make_grid Debug] stride: tensor([ 8., 16., 32.])\n",
      "[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],\n",
      "         [ 2.00000,  3.75000],\n",
      "         [ 4.12500,  2.87500]],\n",
      "\n",
      "        [[ 1.87500,  3.81250],\n",
      "         [ 3.87500,  2.81250],\n",
      "         [ 3.68750,  7.43750]],\n",
      "\n",
      "        [[ 3.62500,  2.81250],\n",
      "         [ 4.87500,  6.18750],\n",
      "         [11.65625, 10.18750]]])\n",
      "[_make_grid Debug] anchor index i => anchors[i]: tensor([[1.25000, 1.62500],\n",
      "        [2.00000, 3.75000],\n",
      "        [4.12500, 2.87500]])\n",
      "self.anchors[i]: tensor([[1.25000, 1.62500],\n",
      "        [2.00000, 3.75000],\n",
      "        [4.12500, 2.87500]])\n",
      "self.stride[i]: tensor(8.)\n",
      "\n",
      "[_make_grid Debug] i=1, nx=28, ny=22\n",
      "[_make_grid Debug] stride: tensor([ 8., 16., 32.])\n",
      "[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],\n",
      "         [ 2.00000,  3.75000],\n",
      "         [ 4.12500,  2.87500]],\n",
      "\n",
      "        [[ 1.87500,  3.81250],\n",
      "         [ 3.87500,  2.81250],\n",
      "         [ 3.68750,  7.43750]],\n",
      "\n",
      "        [[ 3.62500,  2.81250],\n",
      "         [ 4.87500,  6.18750],\n",
      "         [11.65625, 10.18750]]])\n",
      "[_make_grid Debug] anchor index i => anchors[i]: tensor([[1.87500, 3.81250],\n",
      "        [3.87500, 2.81250],\n",
      "        [3.68750, 7.43750]])\n",
      "self.anchors[i]: tensor([[1.87500, 3.81250],\n",
      "        [3.87500, 2.81250],\n",
      "        [3.68750, 7.43750]])\n",
      "self.stride[i]: tensor(16.)\n",
      "\n",
      "[_make_grid Debug] i=2, nx=14, ny=11\n",
      "[_make_grid Debug] stride: tensor([ 8., 16., 32.])\n",
      "[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],\n",
      "         [ 2.00000,  3.75000],\n",
      "         [ 4.12500,  2.87500]],\n",
      "\n",
      "        [[ 1.87500,  3.81250],\n",
      "         [ 3.87500,  2.81250],\n",
      "         [ 3.68750,  7.43750]],\n",
      "\n",
      "        [[ 3.62500,  2.81250],\n",
      "         [ 4.87500,  6.18750],\n",
      "         [11.65625, 10.18750]]])\n",
      "[_make_grid Debug] anchor index i => anchors[i]: tensor([[ 3.62500,  2.81250],\n",
      "        [ 4.87500,  6.18750],\n",
      "        [11.65625, 10.18750]])\n",
      "self.anchors[i]: tensor([[ 3.62500,  2.81250],\n",
      "        [ 4.87500,  6.18750],\n",
      "        [11.65625, 10.18750]])\n",
      "self.stride[i]: tensor(32.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  17%|â–ˆâ–‹        | 2/12 [00:03<00:15,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  25%|â–ˆâ–ˆâ–Œ       | 3/12 [00:05<00:15,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 4/12 [00:06<00:14,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 5/12 [00:09<00:13,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 6/12 [00:11<00:11,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 7/12 [00:13<00:09,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 8/12 [00:15<00:07,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 9/12 [00:17<00:06,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 10/12 [00:19<00:03,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 11/12 [00:20<00:01,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([7, 256, 22, 28]), torch.Size([7, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([7, 128, 44, 56]), torch.Size([7, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([7, 128, 22, 28]), torch.Size([7, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([7, 256, 11, 14]), torch.Size([7, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:21<00:00,  1.82s/it]\n",
      "                   all        183        366   0.000227     0.0589   0.000127   3.57e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 131/131 [00:01<00:00, 68.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([2, 256, 26, 26]), torch.Size([2, 256, 26, 26])]\n",
      "Concat layer inputs: [torch.Size([2, 128, 52, 52]), torch.Size([2, 128, 52, 52])]\n",
      "Concat layer inputs: [torch.Size([2, 128, 26, 26]), torch.Size([2, 128, 26, 26])]\n",
      "Concat layer inputs: [torch.Size([2, 256, 13, 13]), torch.Size([2, 256, 13, 13])]\n",
      "detections[0].shape = torch.Size([2, 3, 52, 52, 9])\n",
      "detections[1].shape = torch.Size([2, 3, 26, 26, 9])\n",
      "detections[2].shape = torch.Size([2, 3, 13, 13, 9])\n",
      "detection_loss = 0.28264716267585754\n",
      "total_loss = 0.28264716267585754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 20, 28]), torch.Size([16, 256, 20, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 40, 56]), torch.Size([16, 128, 40, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 20, 28]), torch.Size([16, 128, 20, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 10, 14]), torch.Size([16, 256, 10, 14])]\n",
      "\n",
      "[_make_grid Debug] i=0, nx=56, ny=40\n",
      "[_make_grid Debug] stride: tensor([ 8., 16., 32.])\n",
      "[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],\n",
      "         [ 2.00000,  3.75000],\n",
      "         [ 4.12500,  2.87500]],\n",
      "\n",
      "        [[ 1.87500,  3.81250],\n",
      "         [ 3.87500,  2.81250],\n",
      "         [ 3.68750,  7.43750]],\n",
      "\n",
      "        [[ 3.62500,  2.81250],\n",
      "         [ 4.87500,  6.18750],\n",
      "         [11.65625, 10.18750]]])\n",
      "[_make_grid Debug] anchor index i => anchors[i]: tensor([[1.25000, 1.62500],\n",
      "        [2.00000, 3.75000],\n",
      "        [4.12500, 2.87500]])\n",
      "self.anchors[i]: tensor([[1.25000, 1.62500],\n",
      "        [2.00000, 3.75000],\n",
      "        [4.12500, 2.87500]])\n",
      "self.stride[i]: tensor(8.)\n",
      "\n",
      "[_make_grid Debug] i=1, nx=28, ny=20\n",
      "[_make_grid Debug] stride: tensor([ 8., 16., 32.])\n",
      "[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],\n",
      "         [ 2.00000,  3.75000],\n",
      "         [ 4.12500,  2.87500]],\n",
      "\n",
      "        [[ 1.87500,  3.81250],\n",
      "         [ 3.87500,  2.81250],\n",
      "         [ 3.68750,  7.43750]],\n",
      "\n",
      "        [[ 3.62500,  2.81250],\n",
      "         [ 4.87500,  6.18750],\n",
      "         [11.65625, 10.18750]]])\n",
      "[_make_grid Debug] anchor index i => anchors[i]: tensor([[1.87500, 3.81250],\n",
      "        [3.87500, 2.81250],\n",
      "        [3.68750, 7.43750]])\n",
      "self.anchors[i]: tensor([[1.87500, 3.81250],\n",
      "        [3.87500, 2.81250],\n",
      "        [3.68750, 7.43750]])\n",
      "self.stride[i]: tensor(16.)\n",
      "\n",
      "[_make_grid Debug] i=2, nx=14, ny=10\n",
      "[_make_grid Debug] stride: tensor([ 8., 16., 32.])\n",
      "[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],\n",
      "         [ 2.00000,  3.75000],\n",
      "         [ 4.12500,  2.87500]],\n",
      "\n",
      "        [[ 1.87500,  3.81250],\n",
      "         [ 3.87500,  2.81250],\n",
      "         [ 3.68750,  7.43750]],\n",
      "\n",
      "        [[ 3.62500,  2.81250],\n",
      "         [ 4.87500,  6.18750],\n",
      "         [11.65625, 10.18750]]])\n",
      "[_make_grid Debug] anchor index i => anchors[i]: tensor([[ 3.62500,  2.81250],\n",
      "        [ 4.87500,  6.18750],\n",
      "        [11.65625, 10.18750]])\n",
      "self.anchors[i]: tensor([[ 3.62500,  2.81250],\n",
      "        [ 4.87500,  6.18750],\n",
      "        [11.65625, 10.18750]])\n",
      "self.stride[i]: tensor(32.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   8%|â–Š         | 1/12 [00:01<00:16,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n",
      "\n",
      "[_make_grid Debug] i=0, nx=56, ny=44\n",
      "[_make_grid Debug] stride: tensor([ 8., 16., 32.])\n",
      "[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],\n",
      "         [ 2.00000,  3.75000],\n",
      "         [ 4.12500,  2.87500]],\n",
      "\n",
      "        [[ 1.87500,  3.81250],\n",
      "         [ 3.87500,  2.81250],\n",
      "         [ 3.68750,  7.43750]],\n",
      "\n",
      "        [[ 3.62500,  2.81250],\n",
      "         [ 4.87500,  6.18750],\n",
      "         [11.65625, 10.18750]]])\n",
      "[_make_grid Debug] anchor index i => anchors[i]: tensor([[1.25000, 1.62500],\n",
      "        [2.00000, 3.75000],\n",
      "        [4.12500, 2.87500]])\n",
      "self.anchors[i]: tensor([[1.25000, 1.62500],\n",
      "        [2.00000, 3.75000],\n",
      "        [4.12500, 2.87500]])\n",
      "self.stride[i]: tensor(8.)\n",
      "\n",
      "[_make_grid Debug] i=1, nx=28, ny=22\n",
      "[_make_grid Debug] stride: tensor([ 8., 16., 32.])\n",
      "[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],\n",
      "         [ 2.00000,  3.75000],\n",
      "         [ 4.12500,  2.87500]],\n",
      "\n",
      "        [[ 1.87500,  3.81250],\n",
      "         [ 3.87500,  2.81250],\n",
      "         [ 3.68750,  7.43750]],\n",
      "\n",
      "        [[ 3.62500,  2.81250],\n",
      "         [ 4.87500,  6.18750],\n",
      "         [11.65625, 10.18750]]])\n",
      "[_make_grid Debug] anchor index i => anchors[i]: tensor([[1.87500, 3.81250],\n",
      "        [3.87500, 2.81250],\n",
      "        [3.68750, 7.43750]])\n",
      "self.anchors[i]: tensor([[1.87500, 3.81250],\n",
      "        [3.87500, 2.81250],\n",
      "        [3.68750, 7.43750]])\n",
      "self.stride[i]: tensor(16.)\n",
      "\n",
      "[_make_grid Debug] i=2, nx=14, ny=11\n",
      "[_make_grid Debug] stride: tensor([ 8., 16., 32.])\n",
      "[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],\n",
      "         [ 2.00000,  3.75000],\n",
      "         [ 4.12500,  2.87500]],\n",
      "\n",
      "        [[ 1.87500,  3.81250],\n",
      "         [ 3.87500,  2.81250],\n",
      "         [ 3.68750,  7.43750]],\n",
      "\n",
      "        [[ 3.62500,  2.81250],\n",
      "         [ 4.87500,  6.18750],\n",
      "         [11.65625, 10.18750]]])\n",
      "[_make_grid Debug] anchor index i => anchors[i]: tensor([[ 3.62500,  2.81250],\n",
      "        [ 4.87500,  6.18750],\n",
      "        [11.65625, 10.18750]])\n",
      "self.anchors[i]: tensor([[ 3.62500,  2.81250],\n",
      "        [ 4.87500,  6.18750],\n",
      "        [11.65625, 10.18750]])\n",
      "self.stride[i]: tensor(32.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  17%|â–ˆâ–‹        | 2/12 [00:03<00:16,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  25%|â–ˆâ–ˆâ–Œ       | 3/12 [00:05<00:15,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 4/12 [00:07<00:14,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 5/12 [00:09<00:13,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 6/12 [00:11<00:12,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING  NMS time limit 1.300s exceeded\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 7/12 [00:13<00:10,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 8/12 [00:16<00:08,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 9/12 [00:18<00:06,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 10/12 [00:19<00:04,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 11/12 [00:21<00:01,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([7, 256, 22, 28]), torch.Size([7, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([7, 128, 44, 56]), torch.Size([7, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([7, 128, 22, 28]), torch.Size([7, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([7, 256, 11, 14]), torch.Size([7, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:22<00:00,  1.89s/it]\n",
      "                   all        183        366    0.00035     0.0572   0.000203    3.7e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 131/131 [00:01<00:00, 69.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([2, 256, 26, 26]), torch.Size([2, 256, 26, 26])]\n",
      "Concat layer inputs: [torch.Size([2, 128, 52, 52]), torch.Size([2, 128, 52, 52])]\n",
      "Concat layer inputs: [torch.Size([2, 128, 26, 26]), torch.Size([2, 128, 26, 26])]\n",
      "Concat layer inputs: [torch.Size([2, 256, 13, 13]), torch.Size([2, 256, 13, 13])]\n",
      "detections[0].shape = torch.Size([2, 3, 52, 52, 9])\n",
      "detections[1].shape = torch.Size([2, 3, 26, 26, 9])\n",
      "detections[2].shape = torch.Size([2, 3, 13, 13, 9])\n",
      "detection_loss = 0.22245143353939056\n",
      "total_loss = 0.22245143353939056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 20, 28]), torch.Size([16, 256, 20, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 40, 56]), torch.Size([16, 128, 40, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 20, 28]), torch.Size([16, 128, 20, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 10, 14]), torch.Size([16, 256, 10, 14])]\n",
      "\n",
      "[_make_grid Debug] i=0, nx=56, ny=40\n",
      "[_make_grid Debug] stride: tensor([ 8., 16., 32.])\n",
      "[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],\n",
      "         [ 2.00000,  3.75000],\n",
      "         [ 4.12500,  2.87500]],\n",
      "\n",
      "        [[ 1.87500,  3.81250],\n",
      "         [ 3.87500,  2.81250],\n",
      "         [ 3.68750,  7.43750]],\n",
      "\n",
      "        [[ 3.62500,  2.81250],\n",
      "         [ 4.87500,  6.18750],\n",
      "         [11.65625, 10.18750]]])\n",
      "[_make_grid Debug] anchor index i => anchors[i]: tensor([[1.25000, 1.62500],\n",
      "        [2.00000, 3.75000],\n",
      "        [4.12500, 2.87500]])\n",
      "self.anchors[i]: tensor([[1.25000, 1.62500],\n",
      "        [2.00000, 3.75000],\n",
      "        [4.12500, 2.87500]])\n",
      "self.stride[i]: tensor(8.)\n",
      "\n",
      "[_make_grid Debug] i=1, nx=28, ny=20\n",
      "[_make_grid Debug] stride: tensor([ 8., 16., 32.])\n",
      "[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],\n",
      "         [ 2.00000,  3.75000],\n",
      "         [ 4.12500,  2.87500]],\n",
      "\n",
      "        [[ 1.87500,  3.81250],\n",
      "         [ 3.87500,  2.81250],\n",
      "         [ 3.68750,  7.43750]],\n",
      "\n",
      "        [[ 3.62500,  2.81250],\n",
      "         [ 4.87500,  6.18750],\n",
      "         [11.65625, 10.18750]]])\n",
      "[_make_grid Debug] anchor index i => anchors[i]: tensor([[1.87500, 3.81250],\n",
      "        [3.87500, 2.81250],\n",
      "        [3.68750, 7.43750]])\n",
      "self.anchors[i]: tensor([[1.87500, 3.81250],\n",
      "        [3.87500, 2.81250],\n",
      "        [3.68750, 7.43750]])\n",
      "self.stride[i]: tensor(16.)\n",
      "\n",
      "[_make_grid Debug] i=2, nx=14, ny=10\n",
      "[_make_grid Debug] stride: tensor([ 8., 16., 32.])\n",
      "[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],\n",
      "         [ 2.00000,  3.75000],\n",
      "         [ 4.12500,  2.87500]],\n",
      "\n",
      "        [[ 1.87500,  3.81250],\n",
      "         [ 3.87500,  2.81250],\n",
      "         [ 3.68750,  7.43750]],\n",
      "\n",
      "        [[ 3.62500,  2.81250],\n",
      "         [ 4.87500,  6.18750],\n",
      "         [11.65625, 10.18750]]])\n",
      "[_make_grid Debug] anchor index i => anchors[i]: tensor([[ 3.62500,  2.81250],\n",
      "        [ 4.87500,  6.18750],\n",
      "        [11.65625, 10.18750]])\n",
      "self.anchors[i]: tensor([[ 3.62500,  2.81250],\n",
      "        [ 4.87500,  6.18750],\n",
      "        [11.65625, 10.18750]])\n",
      "self.stride[i]: tensor(32.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   8%|â–Š         | 1/12 [00:01<00:15,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n",
      "\n",
      "[_make_grid Debug] i=0, nx=56, ny=44\n",
      "[_make_grid Debug] stride: tensor([ 8., 16., 32.])\n",
      "[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],\n",
      "         [ 2.00000,  3.75000],\n",
      "         [ 4.12500,  2.87500]],\n",
      "\n",
      "        [[ 1.87500,  3.81250],\n",
      "         [ 3.87500,  2.81250],\n",
      "         [ 3.68750,  7.43750]],\n",
      "\n",
      "        [[ 3.62500,  2.81250],\n",
      "         [ 4.87500,  6.18750],\n",
      "         [11.65625, 10.18750]]])\n",
      "[_make_grid Debug] anchor index i => anchors[i]: tensor([[1.25000, 1.62500],\n",
      "        [2.00000, 3.75000],\n",
      "        [4.12500, 2.87500]])\n",
      "self.anchors[i]: tensor([[1.25000, 1.62500],\n",
      "        [2.00000, 3.75000],\n",
      "        [4.12500, 2.87500]])\n",
      "self.stride[i]: tensor(8.)\n",
      "\n",
      "[_make_grid Debug] i=1, nx=28, ny=22\n",
      "[_make_grid Debug] stride: tensor([ 8., 16., 32.])\n",
      "[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],\n",
      "         [ 2.00000,  3.75000],\n",
      "         [ 4.12500,  2.87500]],\n",
      "\n",
      "        [[ 1.87500,  3.81250],\n",
      "         [ 3.87500,  2.81250],\n",
      "         [ 3.68750,  7.43750]],\n",
      "\n",
      "        [[ 3.62500,  2.81250],\n",
      "         [ 4.87500,  6.18750],\n",
      "         [11.65625, 10.18750]]])\n",
      "[_make_grid Debug] anchor index i => anchors[i]: tensor([[1.87500, 3.81250],\n",
      "        [3.87500, 2.81250],\n",
      "        [3.68750, 7.43750]])\n",
      "self.anchors[i]: tensor([[1.87500, 3.81250],\n",
      "        [3.87500, 2.81250],\n",
      "        [3.68750, 7.43750]])\n",
      "self.stride[i]: tensor(16.)\n",
      "\n",
      "[_make_grid Debug] i=2, nx=14, ny=11\n",
      "[_make_grid Debug] stride: tensor([ 8., 16., 32.])\n",
      "[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],\n",
      "         [ 2.00000,  3.75000],\n",
      "         [ 4.12500,  2.87500]],\n",
      "\n",
      "        [[ 1.87500,  3.81250],\n",
      "         [ 3.87500,  2.81250],\n",
      "         [ 3.68750,  7.43750]],\n",
      "\n",
      "        [[ 3.62500,  2.81250],\n",
      "         [ 4.87500,  6.18750],\n",
      "         [11.65625, 10.18750]]])\n",
      "[_make_grid Debug] anchor index i => anchors[i]: tensor([[ 3.62500,  2.81250],\n",
      "        [ 4.87500,  6.18750],\n",
      "        [11.65625, 10.18750]])\n",
      "self.anchors[i]: tensor([[ 3.62500,  2.81250],\n",
      "        [ 4.87500,  6.18750],\n",
      "        [11.65625, 10.18750]])\n",
      "self.stride[i]: tensor(32.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  17%|â–ˆâ–‹        | 2/12 [00:03<00:15,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  25%|â–ˆâ–ˆâ–Œ       | 3/12 [00:05<00:15,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 4/12 [00:07<00:14,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 5/12 [00:09<00:13,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 6/12 [00:10<00:11,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 7/12 [00:12<00:09,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 8/12 [00:15<00:07,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 9/12 [00:17<00:05,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 10/12 [00:19<00:04,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 11/12 [00:20<00:01,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([7, 256, 22, 28]), torch.Size([7, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([7, 128, 44, 56]), torch.Size([7, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([7, 128, 22, 28]), torch.Size([7, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([7, 256, 11, 14]), torch.Size([7, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:21<00:00,  1.82s/it]\n",
      "                   all        183        366   0.000469     0.0677     0.0003   6.05e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 131/131 [00:01<00:00, 67.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([2, 256, 26, 26]), torch.Size([2, 256, 26, 26])]\n",
      "Concat layer inputs: [torch.Size([2, 128, 52, 52]), torch.Size([2, 128, 52, 52])]\n",
      "Concat layer inputs: [torch.Size([2, 128, 26, 26]), torch.Size([2, 128, 26, 26])]\n",
      "Concat layer inputs: [torch.Size([2, 256, 13, 13]), torch.Size([2, 256, 13, 13])]\n",
      "detections[0].shape = torch.Size([2, 3, 52, 52, 9])\n",
      "detections[1].shape = torch.Size([2, 3, 26, 26, 9])\n",
      "detections[2].shape = torch.Size([2, 3, 13, 13, 9])\n",
      "detection_loss = 0.2713871896266937\n",
      "total_loss = 0.2713871896266937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 20, 28]), torch.Size([16, 256, 20, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 40, 56]), torch.Size([16, 128, 40, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 20, 28]), torch.Size([16, 128, 20, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 10, 14]), torch.Size([16, 256, 10, 14])]\n",
      "\n",
      "[_make_grid Debug] i=0, nx=56, ny=40\n",
      "[_make_grid Debug] stride: tensor([ 8., 16., 32.])\n",
      "[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],\n",
      "         [ 2.00000,  3.75000],\n",
      "         [ 4.12500,  2.87500]],\n",
      "\n",
      "        [[ 1.87500,  3.81250],\n",
      "         [ 3.87500,  2.81250],\n",
      "         [ 3.68750,  7.43750]],\n",
      "\n",
      "        [[ 3.62500,  2.81250],\n",
      "         [ 4.87500,  6.18750],\n",
      "         [11.65625, 10.18750]]])\n",
      "[_make_grid Debug] anchor index i => anchors[i]: tensor([[1.25000, 1.62500],\n",
      "        [2.00000, 3.75000],\n",
      "        [4.12500, 2.87500]])\n",
      "self.anchors[i]: tensor([[1.25000, 1.62500],\n",
      "        [2.00000, 3.75000],\n",
      "        [4.12500, 2.87500]])\n",
      "self.stride[i]: tensor(8.)\n",
      "\n",
      "[_make_grid Debug] i=1, nx=28, ny=20\n",
      "[_make_grid Debug] stride: tensor([ 8., 16., 32.])\n",
      "[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],\n",
      "         [ 2.00000,  3.75000],\n",
      "         [ 4.12500,  2.87500]],\n",
      "\n",
      "        [[ 1.87500,  3.81250],\n",
      "         [ 3.87500,  2.81250],\n",
      "         [ 3.68750,  7.43750]],\n",
      "\n",
      "        [[ 3.62500,  2.81250],\n",
      "         [ 4.87500,  6.18750],\n",
      "         [11.65625, 10.18750]]])\n",
      "[_make_grid Debug] anchor index i => anchors[i]: tensor([[1.87500, 3.81250],\n",
      "        [3.87500, 2.81250],\n",
      "        [3.68750, 7.43750]])\n",
      "self.anchors[i]: tensor([[1.87500, 3.81250],\n",
      "        [3.87500, 2.81250],\n",
      "        [3.68750, 7.43750]])\n",
      "self.stride[i]: tensor(16.)\n",
      "\n",
      "[_make_grid Debug] i=2, nx=14, ny=10\n",
      "[_make_grid Debug] stride: tensor([ 8., 16., 32.])\n",
      "[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],\n",
      "         [ 2.00000,  3.75000],\n",
      "         [ 4.12500,  2.87500]],\n",
      "\n",
      "        [[ 1.87500,  3.81250],\n",
      "         [ 3.87500,  2.81250],\n",
      "         [ 3.68750,  7.43750]],\n",
      "\n",
      "        [[ 3.62500,  2.81250],\n",
      "         [ 4.87500,  6.18750],\n",
      "         [11.65625, 10.18750]]])\n",
      "[_make_grid Debug] anchor index i => anchors[i]: tensor([[ 3.62500,  2.81250],\n",
      "        [ 4.87500,  6.18750],\n",
      "        [11.65625, 10.18750]])\n",
      "self.anchors[i]: tensor([[ 3.62500,  2.81250],\n",
      "        [ 4.87500,  6.18750],\n",
      "        [11.65625, 10.18750]])\n",
      "self.stride[i]: tensor(32.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   8%|â–Š         | 1/12 [00:01<00:15,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n",
      "\n",
      "[_make_grid Debug] i=0, nx=56, ny=44\n",
      "[_make_grid Debug] stride: tensor([ 8., 16., 32.])\n",
      "[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],\n",
      "         [ 2.00000,  3.75000],\n",
      "         [ 4.12500,  2.87500]],\n",
      "\n",
      "        [[ 1.87500,  3.81250],\n",
      "         [ 3.87500,  2.81250],\n",
      "         [ 3.68750,  7.43750]],\n",
      "\n",
      "        [[ 3.62500,  2.81250],\n",
      "         [ 4.87500,  6.18750],\n",
      "         [11.65625, 10.18750]]])\n",
      "[_make_grid Debug] anchor index i => anchors[i]: tensor([[1.25000, 1.62500],\n",
      "        [2.00000, 3.75000],\n",
      "        [4.12500, 2.87500]])\n",
      "self.anchors[i]: tensor([[1.25000, 1.62500],\n",
      "        [2.00000, 3.75000],\n",
      "        [4.12500, 2.87500]])\n",
      "self.stride[i]: tensor(8.)\n",
      "\n",
      "[_make_grid Debug] i=1, nx=28, ny=22\n",
      "[_make_grid Debug] stride: tensor([ 8., 16., 32.])\n",
      "[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],\n",
      "         [ 2.00000,  3.75000],\n",
      "         [ 4.12500,  2.87500]],\n",
      "\n",
      "        [[ 1.87500,  3.81250],\n",
      "         [ 3.87500,  2.81250],\n",
      "         [ 3.68750,  7.43750]],\n",
      "\n",
      "        [[ 3.62500,  2.81250],\n",
      "         [ 4.87500,  6.18750],\n",
      "         [11.65625, 10.18750]]])\n",
      "[_make_grid Debug] anchor index i => anchors[i]: tensor([[1.87500, 3.81250],\n",
      "        [3.87500, 2.81250],\n",
      "        [3.68750, 7.43750]])\n",
      "self.anchors[i]: tensor([[1.87500, 3.81250],\n",
      "        [3.87500, 2.81250],\n",
      "        [3.68750, 7.43750]])\n",
      "self.stride[i]: tensor(16.)\n",
      "\n",
      "[_make_grid Debug] i=2, nx=14, ny=11\n",
      "[_make_grid Debug] stride: tensor([ 8., 16., 32.])\n",
      "[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],\n",
      "         [ 2.00000,  3.75000],\n",
      "         [ 4.12500,  2.87500]],\n",
      "\n",
      "        [[ 1.87500,  3.81250],\n",
      "         [ 3.87500,  2.81250],\n",
      "         [ 3.68750,  7.43750]],\n",
      "\n",
      "        [[ 3.62500,  2.81250],\n",
      "         [ 4.87500,  6.18750],\n",
      "         [11.65625, 10.18750]]])\n",
      "[_make_grid Debug] anchor index i => anchors[i]: tensor([[ 3.62500,  2.81250],\n",
      "        [ 4.87500,  6.18750],\n",
      "        [11.65625, 10.18750]])\n",
      "self.anchors[i]: tensor([[ 3.62500,  2.81250],\n",
      "        [ 4.87500,  6.18750],\n",
      "        [11.65625, 10.18750]])\n",
      "self.stride[i]: tensor(32.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  17%|â–ˆâ–‹        | 2/12 [00:03<00:16,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  25%|â–ˆâ–ˆâ–Œ       | 3/12 [00:05<00:15,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 4/12 [00:06<00:14,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 5/12 [00:09<00:13,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 6/12 [00:10<00:11,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 7/12 [00:13<00:09,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 8/12 [00:15<00:08,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 9/12 [00:17<00:06,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 10/12 [00:19<00:04,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 11/12 [00:21<00:01,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([7, 256, 22, 28]), torch.Size([7, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([7, 128, 44, 56]), torch.Size([7, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([7, 128, 22, 28]), torch.Size([7, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([7, 256, 11, 14]), torch.Size([7, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:22<00:00,  1.84s/it]\n",
      "                   all        183        366   0.000387     0.0907   0.000237   5.46e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 131/131 [00:01<00:00, 69.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([2, 256, 26, 26]), torch.Size([2, 256, 26, 26])]\n",
      "Concat layer inputs: [torch.Size([2, 128, 52, 52]), torch.Size([2, 128, 52, 52])]\n",
      "Concat layer inputs: [torch.Size([2, 128, 26, 26]), torch.Size([2, 128, 26, 26])]\n",
      "Concat layer inputs: [torch.Size([2, 256, 13, 13]), torch.Size([2, 256, 13, 13])]\n",
      "detections[0].shape = torch.Size([2, 3, 52, 52, 9])\n",
      "detections[1].shape = torch.Size([2, 3, 26, 26, 9])\n",
      "detections[2].shape = torch.Size([2, 3, 13, 13, 9])\n",
      "detection_loss = 0.23588421940803528\n",
      "total_loss = 0.23588421940803528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 20, 28]), torch.Size([16, 256, 20, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 40, 56]), torch.Size([16, 128, 40, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 20, 28]), torch.Size([16, 128, 20, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 10, 14]), torch.Size([16, 256, 10, 14])]\n",
      "\n",
      "[_make_grid Debug] i=0, nx=56, ny=40\n",
      "[_make_grid Debug] stride: tensor([ 8., 16., 32.])\n",
      "[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],\n",
      "         [ 2.00000,  3.75000],\n",
      "         [ 4.12500,  2.87500]],\n",
      "\n",
      "        [[ 1.87500,  3.81250],\n",
      "         [ 3.87500,  2.81250],\n",
      "         [ 3.68750,  7.43750]],\n",
      "\n",
      "        [[ 3.62500,  2.81250],\n",
      "         [ 4.87500,  6.18750],\n",
      "         [11.65625, 10.18750]]])\n",
      "[_make_grid Debug] anchor index i => anchors[i]: tensor([[1.25000, 1.62500],\n",
      "        [2.00000, 3.75000],\n",
      "        [4.12500, 2.87500]])\n",
      "self.anchors[i]: tensor([[1.25000, 1.62500],\n",
      "        [2.00000, 3.75000],\n",
      "        [4.12500, 2.87500]])\n",
      "self.stride[i]: tensor(8.)\n",
      "\n",
      "[_make_grid Debug] i=1, nx=28, ny=20\n",
      "[_make_grid Debug] stride: tensor([ 8., 16., 32.])\n",
      "[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],\n",
      "         [ 2.00000,  3.75000],\n",
      "         [ 4.12500,  2.87500]],\n",
      "\n",
      "        [[ 1.87500,  3.81250],\n",
      "         [ 3.87500,  2.81250],\n",
      "         [ 3.68750,  7.43750]],\n",
      "\n",
      "        [[ 3.62500,  2.81250],\n",
      "         [ 4.87500,  6.18750],\n",
      "         [11.65625, 10.18750]]])\n",
      "[_make_grid Debug] anchor index i => anchors[i]: tensor([[1.87500, 3.81250],\n",
      "        [3.87500, 2.81250],\n",
      "        [3.68750, 7.43750]])\n",
      "self.anchors[i]: tensor([[1.87500, 3.81250],\n",
      "        [3.87500, 2.81250],\n",
      "        [3.68750, 7.43750]])\n",
      "self.stride[i]: tensor(16.)\n",
      "\n",
      "[_make_grid Debug] i=2, nx=14, ny=10\n",
      "[_make_grid Debug] stride: tensor([ 8., 16., 32.])\n",
      "[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],\n",
      "         [ 2.00000,  3.75000],\n",
      "         [ 4.12500,  2.87500]],\n",
      "\n",
      "        [[ 1.87500,  3.81250],\n",
      "         [ 3.87500,  2.81250],\n",
      "         [ 3.68750,  7.43750]],\n",
      "\n",
      "        [[ 3.62500,  2.81250],\n",
      "         [ 4.87500,  6.18750],\n",
      "         [11.65625, 10.18750]]])\n",
      "[_make_grid Debug] anchor index i => anchors[i]: tensor([[ 3.62500,  2.81250],\n",
      "        [ 4.87500,  6.18750],\n",
      "        [11.65625, 10.18750]])\n",
      "self.anchors[i]: tensor([[ 3.62500,  2.81250],\n",
      "        [ 4.87500,  6.18750],\n",
      "        [11.65625, 10.18750]])\n",
      "self.stride[i]: tensor(32.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   8%|â–Š         | 1/12 [00:01<00:16,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n",
      "\n",
      "[_make_grid Debug] i=0, nx=56, ny=44\n",
      "[_make_grid Debug] stride: tensor([ 8., 16., 32.])\n",
      "[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],\n",
      "         [ 2.00000,  3.75000],\n",
      "         [ 4.12500,  2.87500]],\n",
      "\n",
      "        [[ 1.87500,  3.81250],\n",
      "         [ 3.87500,  2.81250],\n",
      "         [ 3.68750,  7.43750]],\n",
      "\n",
      "        [[ 3.62500,  2.81250],\n",
      "         [ 4.87500,  6.18750],\n",
      "         [11.65625, 10.18750]]])\n",
      "[_make_grid Debug] anchor index i => anchors[i]: tensor([[1.25000, 1.62500],\n",
      "        [2.00000, 3.75000],\n",
      "        [4.12500, 2.87500]])\n",
      "self.anchors[i]: tensor([[1.25000, 1.62500],\n",
      "        [2.00000, 3.75000],\n",
      "        [4.12500, 2.87500]])\n",
      "self.stride[i]: tensor(8.)\n",
      "\n",
      "[_make_grid Debug] i=1, nx=28, ny=22\n",
      "[_make_grid Debug] stride: tensor([ 8., 16., 32.])\n",
      "[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],\n",
      "         [ 2.00000,  3.75000],\n",
      "         [ 4.12500,  2.87500]],\n",
      "\n",
      "        [[ 1.87500,  3.81250],\n",
      "         [ 3.87500,  2.81250],\n",
      "         [ 3.68750,  7.43750]],\n",
      "\n",
      "        [[ 3.62500,  2.81250],\n",
      "         [ 4.87500,  6.18750],\n",
      "         [11.65625, 10.18750]]])\n",
      "[_make_grid Debug] anchor index i => anchors[i]: tensor([[1.87500, 3.81250],\n",
      "        [3.87500, 2.81250],\n",
      "        [3.68750, 7.43750]])\n",
      "self.anchors[i]: tensor([[1.87500, 3.81250],\n",
      "        [3.87500, 2.81250],\n",
      "        [3.68750, 7.43750]])\n",
      "self.stride[i]: tensor(16.)\n",
      "\n",
      "[_make_grid Debug] i=2, nx=14, ny=11\n",
      "[_make_grid Debug] stride: tensor([ 8., 16., 32.])\n",
      "[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],\n",
      "         [ 2.00000,  3.75000],\n",
      "         [ 4.12500,  2.87500]],\n",
      "\n",
      "        [[ 1.87500,  3.81250],\n",
      "         [ 3.87500,  2.81250],\n",
      "         [ 3.68750,  7.43750]],\n",
      "\n",
      "        [[ 3.62500,  2.81250],\n",
      "         [ 4.87500,  6.18750],\n",
      "         [11.65625, 10.18750]]])\n",
      "[_make_grid Debug] anchor index i => anchors[i]: tensor([[ 3.62500,  2.81250],\n",
      "        [ 4.87500,  6.18750],\n",
      "        [11.65625, 10.18750]])\n",
      "self.anchors[i]: tensor([[ 3.62500,  2.81250],\n",
      "        [ 4.87500,  6.18750],\n",
      "        [11.65625, 10.18750]])\n",
      "self.stride[i]: tensor(32.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  17%|â–ˆâ–‹        | 2/12 [00:03<00:16,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  25%|â–ˆâ–ˆâ–Œ       | 3/12 [00:05<00:16,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 4/12 [00:07<00:15,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 5/12 [00:09<00:13,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 6/12 [00:11<00:11,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 7/12 [00:13<00:10,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 8/12 [00:15<00:08,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 9/12 [00:17<00:06,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 10/12 [00:19<00:04,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 11/12 [00:21<00:02,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([7, 256, 22, 28]), torch.Size([7, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([7, 128, 44, 56]), torch.Size([7, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([7, 128, 22, 28]), torch.Size([7, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([7, 256, 11, 14]), torch.Size([7, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:22<00:00,  1.90s/it]\n",
      "                   all        183        366   0.000494        0.1   0.000308   8.63e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 131/131 [00:01<00:00, 68.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([2, 256, 26, 26]), torch.Size([2, 256, 26, 26])]\n",
      "Concat layer inputs: [torch.Size([2, 128, 52, 52]), torch.Size([2, 128, 52, 52])]\n",
      "Concat layer inputs: [torch.Size([2, 128, 26, 26]), torch.Size([2, 128, 26, 26])]\n",
      "Concat layer inputs: [torch.Size([2, 256, 13, 13]), torch.Size([2, 256, 13, 13])]\n",
      "detections[0].shape = torch.Size([2, 3, 52, 52, 9])\n",
      "detections[1].shape = torch.Size([2, 3, 26, 26, 9])\n",
      "detections[2].shape = torch.Size([2, 3, 13, 13, 9])\n",
      "detection_loss = 0.24208484590053558\n",
      "total_loss = 0.24208484590053558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 20, 28]), torch.Size([16, 256, 20, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 40, 56]), torch.Size([16, 128, 40, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 20, 28]), torch.Size([16, 128, 20, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 10, 14]), torch.Size([16, 256, 10, 14])]\n",
      "\n",
      "[_make_grid Debug] i=0, nx=56, ny=40\n",
      "[_make_grid Debug] stride: tensor([ 8., 16., 32.])\n",
      "[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],\n",
      "         [ 2.00000,  3.75000],\n",
      "         [ 4.12500,  2.87500]],\n",
      "\n",
      "        [[ 1.87500,  3.81250],\n",
      "         [ 3.87500,  2.81250],\n",
      "         [ 3.68750,  7.43750]],\n",
      "\n",
      "        [[ 3.62500,  2.81250],\n",
      "         [ 4.87500,  6.18750],\n",
      "         [11.65625, 10.18750]]])\n",
      "[_make_grid Debug] anchor index i => anchors[i]: tensor([[1.25000, 1.62500],\n",
      "        [2.00000, 3.75000],\n",
      "        [4.12500, 2.87500]])\n",
      "self.anchors[i]: tensor([[1.25000, 1.62500],\n",
      "        [2.00000, 3.75000],\n",
      "        [4.12500, 2.87500]])\n",
      "self.stride[i]: tensor(8.)\n",
      "\n",
      "[_make_grid Debug] i=1, nx=28, ny=20\n",
      "[_make_grid Debug] stride: tensor([ 8., 16., 32.])\n",
      "[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],\n",
      "         [ 2.00000,  3.75000],\n",
      "         [ 4.12500,  2.87500]],\n",
      "\n",
      "        [[ 1.87500,  3.81250],\n",
      "         [ 3.87500,  2.81250],\n",
      "         [ 3.68750,  7.43750]],\n",
      "\n",
      "        [[ 3.62500,  2.81250],\n",
      "         [ 4.87500,  6.18750],\n",
      "         [11.65625, 10.18750]]])\n",
      "[_make_grid Debug] anchor index i => anchors[i]: tensor([[1.87500, 3.81250],\n",
      "        [3.87500, 2.81250],\n",
      "        [3.68750, 7.43750]])\n",
      "self.anchors[i]: tensor([[1.87500, 3.81250],\n",
      "        [3.87500, 2.81250],\n",
      "        [3.68750, 7.43750]])\n",
      "self.stride[i]: tensor(16.)\n",
      "\n",
      "[_make_grid Debug] i=2, nx=14, ny=10\n",
      "[_make_grid Debug] stride: tensor([ 8., 16., 32.])\n",
      "[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],\n",
      "         [ 2.00000,  3.75000],\n",
      "         [ 4.12500,  2.87500]],\n",
      "\n",
      "        [[ 1.87500,  3.81250],\n",
      "         [ 3.87500,  2.81250],\n",
      "         [ 3.68750,  7.43750]],\n",
      "\n",
      "        [[ 3.62500,  2.81250],\n",
      "         [ 4.87500,  6.18750],\n",
      "         [11.65625, 10.18750]]])\n",
      "[_make_grid Debug] anchor index i => anchors[i]: tensor([[ 3.62500,  2.81250],\n",
      "        [ 4.87500,  6.18750],\n",
      "        [11.65625, 10.18750]])\n",
      "self.anchors[i]: tensor([[ 3.62500,  2.81250],\n",
      "        [ 4.87500,  6.18750],\n",
      "        [11.65625, 10.18750]])\n",
      "self.stride[i]: tensor(32.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   8%|â–Š         | 1/12 [00:01<00:16,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n",
      "\n",
      "[_make_grid Debug] i=0, nx=56, ny=44\n",
      "[_make_grid Debug] stride: tensor([ 8., 16., 32.])\n",
      "[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],\n",
      "         [ 2.00000,  3.75000],\n",
      "         [ 4.12500,  2.87500]],\n",
      "\n",
      "        [[ 1.87500,  3.81250],\n",
      "         [ 3.87500,  2.81250],\n",
      "         [ 3.68750,  7.43750]],\n",
      "\n",
      "        [[ 3.62500,  2.81250],\n",
      "         [ 4.87500,  6.18750],\n",
      "         [11.65625, 10.18750]]])\n",
      "[_make_grid Debug] anchor index i => anchors[i]: tensor([[1.25000, 1.62500],\n",
      "        [2.00000, 3.75000],\n",
      "        [4.12500, 2.87500]])\n",
      "self.anchors[i]: tensor([[1.25000, 1.62500],\n",
      "        [2.00000, 3.75000],\n",
      "        [4.12500, 2.87500]])\n",
      "self.stride[i]: tensor(8.)\n",
      "\n",
      "[_make_grid Debug] i=1, nx=28, ny=22\n",
      "[_make_grid Debug] stride: tensor([ 8., 16., 32.])\n",
      "[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],\n",
      "         [ 2.00000,  3.75000],\n",
      "         [ 4.12500,  2.87500]],\n",
      "\n",
      "        [[ 1.87500,  3.81250],\n",
      "         [ 3.87500,  2.81250],\n",
      "         [ 3.68750,  7.43750]],\n",
      "\n",
      "        [[ 3.62500,  2.81250],\n",
      "         [ 4.87500,  6.18750],\n",
      "         [11.65625, 10.18750]]])\n",
      "[_make_grid Debug] anchor index i => anchors[i]: tensor([[1.87500, 3.81250],\n",
      "        [3.87500, 2.81250],\n",
      "        [3.68750, 7.43750]])\n",
      "self.anchors[i]: tensor([[1.87500, 3.81250],\n",
      "        [3.87500, 2.81250],\n",
      "        [3.68750, 7.43750]])\n",
      "self.stride[i]: tensor(16.)\n",
      "\n",
      "[_make_grid Debug] i=2, nx=14, ny=11\n",
      "[_make_grid Debug] stride: tensor([ 8., 16., 32.])\n",
      "[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],\n",
      "         [ 2.00000,  3.75000],\n",
      "         [ 4.12500,  2.87500]],\n",
      "\n",
      "        [[ 1.87500,  3.81250],\n",
      "         [ 3.87500,  2.81250],\n",
      "         [ 3.68750,  7.43750]],\n",
      "\n",
      "        [[ 3.62500,  2.81250],\n",
      "         [ 4.87500,  6.18750],\n",
      "         [11.65625, 10.18750]]])\n",
      "[_make_grid Debug] anchor index i => anchors[i]: tensor([[ 3.62500,  2.81250],\n",
      "        [ 4.87500,  6.18750],\n",
      "        [11.65625, 10.18750]])\n",
      "self.anchors[i]: tensor([[ 3.62500,  2.81250],\n",
      "        [ 4.87500,  6.18750],\n",
      "        [11.65625, 10.18750]])\n",
      "self.stride[i]: tensor(32.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  17%|â–ˆâ–‹        | 2/12 [00:03<00:16,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  25%|â–ˆâ–ˆâ–Œ       | 3/12 [00:05<00:16,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 4/12 [00:07<00:15,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 5/12 [00:09<00:13,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 6/12 [00:11<00:11,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 7/12 [00:13<00:10,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 8/12 [00:15<00:08,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 9/12 [00:17<00:06,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 10/12 [00:19<00:04,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 11/12 [00:21<00:02,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([7, 256, 22, 28]), torch.Size([7, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([7, 128, 44, 56]), torch.Size([7, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([7, 128, 22, 28]), torch.Size([7, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([7, 256, 11, 14]), torch.Size([7, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:22<00:00,  1.91s/it]\n",
      "                   all        183        366   0.000455      0.107   0.000287   6.57e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 131/131 [00:01<00:00, 67.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([2, 256, 26, 26]), torch.Size([2, 256, 26, 26])]\n",
      "Concat layer inputs: [torch.Size([2, 128, 52, 52]), torch.Size([2, 128, 52, 52])]\n",
      "Concat layer inputs: [torch.Size([2, 128, 26, 26]), torch.Size([2, 128, 26, 26])]\n",
      "Concat layer inputs: [torch.Size([2, 256, 13, 13]), torch.Size([2, 256, 13, 13])]\n",
      "detections[0].shape = torch.Size([2, 3, 52, 52, 9])\n",
      "detections[1].shape = torch.Size([2, 3, 26, 26, 9])\n",
      "detections[2].shape = torch.Size([2, 3, 13, 13, 9])\n",
      "detection_loss = 0.21314695477485657\n",
      "total_loss = 0.21314695477485657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 20, 28]), torch.Size([16, 256, 20, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 40, 56]), torch.Size([16, 128, 40, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 20, 28]), torch.Size([16, 128, 20, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 10, 14]), torch.Size([16, 256, 10, 14])]\n",
      "\n",
      "[_make_grid Debug] i=0, nx=56, ny=40\n",
      "[_make_grid Debug] stride: tensor([ 8., 16., 32.])\n",
      "[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],\n",
      "         [ 2.00000,  3.75000],\n",
      "         [ 4.12500,  2.87500]],\n",
      "\n",
      "        [[ 1.87500,  3.81250],\n",
      "         [ 3.87500,  2.81250],\n",
      "         [ 3.68750,  7.43750]],\n",
      "\n",
      "        [[ 3.62500,  2.81250],\n",
      "         [ 4.87500,  6.18750],\n",
      "         [11.65625, 10.18750]]])\n",
      "[_make_grid Debug] anchor index i => anchors[i]: tensor([[1.25000, 1.62500],\n",
      "        [2.00000, 3.75000],\n",
      "        [4.12500, 2.87500]])\n",
      "self.anchors[i]: tensor([[1.25000, 1.62500],\n",
      "        [2.00000, 3.75000],\n",
      "        [4.12500, 2.87500]])\n",
      "self.stride[i]: tensor(8.)\n",
      "\n",
      "[_make_grid Debug] i=1, nx=28, ny=20\n",
      "[_make_grid Debug] stride: tensor([ 8., 16., 32.])\n",
      "[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],\n",
      "         [ 2.00000,  3.75000],\n",
      "         [ 4.12500,  2.87500]],\n",
      "\n",
      "        [[ 1.87500,  3.81250],\n",
      "         [ 3.87500,  2.81250],\n",
      "         [ 3.68750,  7.43750]],\n",
      "\n",
      "        [[ 3.62500,  2.81250],\n",
      "         [ 4.87500,  6.18750],\n",
      "         [11.65625, 10.18750]]])\n",
      "[_make_grid Debug] anchor index i => anchors[i]: tensor([[1.87500, 3.81250],\n",
      "        [3.87500, 2.81250],\n",
      "        [3.68750, 7.43750]])\n",
      "self.anchors[i]: tensor([[1.87500, 3.81250],\n",
      "        [3.87500, 2.81250],\n",
      "        [3.68750, 7.43750]])\n",
      "self.stride[i]: tensor(16.)\n",
      "\n",
      "[_make_grid Debug] i=2, nx=14, ny=10\n",
      "[_make_grid Debug] stride: tensor([ 8., 16., 32.])\n",
      "[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],\n",
      "         [ 2.00000,  3.75000],\n",
      "         [ 4.12500,  2.87500]],\n",
      "\n",
      "        [[ 1.87500,  3.81250],\n",
      "         [ 3.87500,  2.81250],\n",
      "         [ 3.68750,  7.43750]],\n",
      "\n",
      "        [[ 3.62500,  2.81250],\n",
      "         [ 4.87500,  6.18750],\n",
      "         [11.65625, 10.18750]]])\n",
      "[_make_grid Debug] anchor index i => anchors[i]: tensor([[ 3.62500,  2.81250],\n",
      "        [ 4.87500,  6.18750],\n",
      "        [11.65625, 10.18750]])\n",
      "self.anchors[i]: tensor([[ 3.62500,  2.81250],\n",
      "        [ 4.87500,  6.18750],\n",
      "        [11.65625, 10.18750]])\n",
      "self.stride[i]: tensor(32.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   8%|â–Š         | 1/12 [00:01<00:18,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n",
      "\n",
      "[_make_grid Debug] i=0, nx=56, ny=44\n",
      "[_make_grid Debug] stride: tensor([ 8., 16., 32.])\n",
      "[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],\n",
      "         [ 2.00000,  3.75000],\n",
      "         [ 4.12500,  2.87500]],\n",
      "\n",
      "        [[ 1.87500,  3.81250],\n",
      "         [ 3.87500,  2.81250],\n",
      "         [ 3.68750,  7.43750]],\n",
      "\n",
      "        [[ 3.62500,  2.81250],\n",
      "         [ 4.87500,  6.18750],\n",
      "         [11.65625, 10.18750]]])\n",
      "[_make_grid Debug] anchor index i => anchors[i]: tensor([[1.25000, 1.62500],\n",
      "        [2.00000, 3.75000],\n",
      "        [4.12500, 2.87500]])\n",
      "self.anchors[i]: tensor([[1.25000, 1.62500],\n",
      "        [2.00000, 3.75000],\n",
      "        [4.12500, 2.87500]])\n",
      "self.stride[i]: tensor(8.)\n",
      "\n",
      "[_make_grid Debug] i=1, nx=28, ny=22\n",
      "[_make_grid Debug] stride: tensor([ 8., 16., 32.])\n",
      "[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],\n",
      "         [ 2.00000,  3.75000],\n",
      "         [ 4.12500,  2.87500]],\n",
      "\n",
      "        [[ 1.87500,  3.81250],\n",
      "         [ 3.87500,  2.81250],\n",
      "         [ 3.68750,  7.43750]],\n",
      "\n",
      "        [[ 3.62500,  2.81250],\n",
      "         [ 4.87500,  6.18750],\n",
      "         [11.65625, 10.18750]]])\n",
      "[_make_grid Debug] anchor index i => anchors[i]: tensor([[1.87500, 3.81250],\n",
      "        [3.87500, 2.81250],\n",
      "        [3.68750, 7.43750]])\n",
      "self.anchors[i]: tensor([[1.87500, 3.81250],\n",
      "        [3.87500, 2.81250],\n",
      "        [3.68750, 7.43750]])\n",
      "self.stride[i]: tensor(16.)\n",
      "\n",
      "[_make_grid Debug] i=2, nx=14, ny=11\n",
      "[_make_grid Debug] stride: tensor([ 8., 16., 32.])\n",
      "[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],\n",
      "         [ 2.00000,  3.75000],\n",
      "         [ 4.12500,  2.87500]],\n",
      "\n",
      "        [[ 1.87500,  3.81250],\n",
      "         [ 3.87500,  2.81250],\n",
      "         [ 3.68750,  7.43750]],\n",
      "\n",
      "        [[ 3.62500,  2.81250],\n",
      "         [ 4.87500,  6.18750],\n",
      "         [11.65625, 10.18750]]])\n",
      "[_make_grid Debug] anchor index i => anchors[i]: tensor([[ 3.62500,  2.81250],\n",
      "        [ 4.87500,  6.18750],\n",
      "        [11.65625, 10.18750]])\n",
      "self.anchors[i]: tensor([[ 3.62500,  2.81250],\n",
      "        [ 4.87500,  6.18750],\n",
      "        [11.65625, 10.18750]])\n",
      "self.stride[i]: tensor(32.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  17%|â–ˆâ–‹        | 2/12 [00:03<00:17,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  25%|â–ˆâ–ˆâ–Œ       | 3/12 [00:05<00:16,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 4/12 [00:07<00:15,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 5/12 [00:09<00:13,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 6/12 [00:11<00:11,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 7/12 [00:13<00:09,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 8/12 [00:15<00:08,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 9/12 [00:17<00:06,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 10/12 [00:20<00:04,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 11/12 [00:21<00:02,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([7, 256, 22, 28]), torch.Size([7, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([7, 128, 44, 56]), torch.Size([7, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([7, 128, 22, 28]), torch.Size([7, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([7, 256, 11, 14]), torch.Size([7, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:22<00:00,  1.91s/it]\n",
      "                   all        183        366   0.000481      0.099   0.000298   6.43e-05\n",
      "\n",
      "10 epochs completed in 0.071 hours.\n",
      "Optimizer stripped from runs\\train\\yolov5s_test274\\weights\\last.pt, 14.3MB\n",
      "Optimizer stripped from runs\\train\\yolov5s_test274\\weights\\best.pt, 14.3MB\n",
      "\n",
      "Validating runs\\train\\yolov5s_test274\\weights\\best.pt...\n",
      "Fusing layers... \n",
      "YOLOv5sc summary: 161 layers, 7021300 parameters, 0 gradients, 15.8 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([1, 256, 2, 2]), torch.Size([1, 256, 2, 2])]\n",
      "Concat layer inputs: [torch.Size([1, 128, 4, 4]), torch.Size([1, 128, 4, 4])]\n",
      "Concat layer inputs: [torch.Size([1, 128, 2, 2]), torch.Size([1, 128, 2, 2])]\n",
      "Concat layer inputs: [torch.Size([1, 256, 1, 1]), torch.Size([1, 256, 1, 1])]\n",
      "\n",
      "[_make_grid Debug] i=0, nx=4, ny=4\n",
      "[_make_grid Debug] stride: tensor([ 8., 16., 32.])\n",
      "[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],\n",
      "         [ 2.00000,  3.75000],\n",
      "         [ 4.12500,  2.87500]],\n",
      "\n",
      "        [[ 1.87500,  3.81250],\n",
      "         [ 3.87500,  2.81250],\n",
      "         [ 3.68750,  7.43750]],\n",
      "\n",
      "        [[ 3.62500,  2.81250],\n",
      "         [ 4.87500,  6.18750],\n",
      "         [11.65625, 10.18750]]])\n",
      "[_make_grid Debug] anchor index i => anchors[i]: tensor([[1.25000, 1.62500],\n",
      "        [2.00000, 3.75000],\n",
      "        [4.12500, 2.87500]])\n",
      "self.anchors[i]: tensor([[1.25000, 1.62500],\n",
      "        [2.00000, 3.75000],\n",
      "        [4.12500, 2.87500]])\n",
      "self.stride[i]: tensor(8.)\n",
      "\n",
      "[_make_grid Debug] i=1, nx=2, ny=2\n",
      "[_make_grid Debug] stride: tensor([ 8., 16., 32.])\n",
      "[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],\n",
      "         [ 2.00000,  3.75000],\n",
      "         [ 4.12500,  2.87500]],\n",
      "\n",
      "        [[ 1.87500,  3.81250],\n",
      "         [ 3.87500,  2.81250],\n",
      "         [ 3.68750,  7.43750]],\n",
      "\n",
      "        [[ 3.62500,  2.81250],\n",
      "         [ 4.87500,  6.18750],\n",
      "         [11.65625, 10.18750]]])\n",
      "[_make_grid Debug] anchor index i => anchors[i]: tensor([[1.87500, 3.81250],\n",
      "        [3.87500, 2.81250],\n",
      "        [3.68750, 7.43750]])\n",
      "self.anchors[i]: tensor([[1.87500, 3.81250],\n",
      "        [3.87500, 2.81250],\n",
      "        [3.68750, 7.43750]])\n",
      "self.stride[i]: tensor(16.)\n",
      "\n",
      "[_make_grid Debug] i=2, nx=1, ny=1\n",
      "[_make_grid Debug] stride: tensor([ 8., 16., 32.])\n",
      "[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],\n",
      "         [ 2.00000,  3.75000],\n",
      "         [ 4.12500,  2.87500]],\n",
      "\n",
      "        [[ 1.87500,  3.81250],\n",
      "         [ 3.87500,  2.81250],\n",
      "         [ 3.68750,  7.43750]],\n",
      "\n",
      "        [[ 3.62500,  2.81250],\n",
      "         [ 4.87500,  6.18750],\n",
      "         [11.65625, 10.18750]]])\n",
      "[_make_grid Debug] anchor index i => anchors[i]: tensor([[ 3.62500,  2.81250],\n",
      "        [ 4.87500,  6.18750],\n",
      "        [11.65625, 10.18750]])\n",
      "self.anchors[i]: tensor([[ 3.62500,  2.81250],\n",
      "        [ 4.87500,  6.18750],\n",
      "        [11.65625, 10.18750]])\n",
      "self.stride[i]: tensor(32.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 20, 28]), torch.Size([16, 256, 20, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 40, 56]), torch.Size([16, 128, 40, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 20, 28]), torch.Size([16, 128, 20, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 10, 14]), torch.Size([16, 256, 10, 14])]\n",
      "\n",
      "[_make_grid Debug] i=0, nx=56, ny=40\n",
      "[_make_grid Debug] stride: tensor([ 8., 16., 32.])\n",
      "[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],\n",
      "         [ 2.00000,  3.75000],\n",
      "         [ 4.12500,  2.87500]],\n",
      "\n",
      "        [[ 1.87500,  3.81250],\n",
      "         [ 3.87500,  2.81250],\n",
      "         [ 3.68750,  7.43750]],\n",
      "\n",
      "        [[ 3.62500,  2.81250],\n",
      "         [ 4.87500,  6.18750],\n",
      "         [11.65625, 10.18750]]])\n",
      "[_make_grid Debug] anchor index i => anchors[i]: tensor([[1.25000, 1.62500],\n",
      "        [2.00000, 3.75000],\n",
      "        [4.12500, 2.87500]])\n",
      "self.anchors[i]: tensor([[1.25000, 1.62500],\n",
      "        [2.00000, 3.75000],\n",
      "        [4.12500, 2.87500]])\n",
      "self.stride[i]: tensor(8.)\n",
      "\n",
      "[_make_grid Debug] i=1, nx=28, ny=20\n",
      "[_make_grid Debug] stride: tensor([ 8., 16., 32.])\n",
      "[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],\n",
      "         [ 2.00000,  3.75000],\n",
      "         [ 4.12500,  2.87500]],\n",
      "\n",
      "        [[ 1.87500,  3.81250],\n",
      "         [ 3.87500,  2.81250],\n",
      "         [ 3.68750,  7.43750]],\n",
      "\n",
      "        [[ 3.62500,  2.81250],\n",
      "         [ 4.87500,  6.18750],\n",
      "         [11.65625, 10.18750]]])\n",
      "[_make_grid Debug] anchor index i => anchors[i]: tensor([[1.87500, 3.81250],\n",
      "        [3.87500, 2.81250],\n",
      "        [3.68750, 7.43750]])\n",
      "self.anchors[i]: tensor([[1.87500, 3.81250],\n",
      "        [3.87500, 2.81250],\n",
      "        [3.68750, 7.43750]])\n",
      "self.stride[i]: tensor(16.)\n",
      "\n",
      "[_make_grid Debug] i=2, nx=14, ny=10\n",
      "[_make_grid Debug] stride: tensor([ 8., 16., 32.])\n",
      "[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],\n",
      "         [ 2.00000,  3.75000],\n",
      "         [ 4.12500,  2.87500]],\n",
      "\n",
      "        [[ 1.87500,  3.81250],\n",
      "         [ 3.87500,  2.81250],\n",
      "         [ 3.68750,  7.43750]],\n",
      "\n",
      "        [[ 3.62500,  2.81250],\n",
      "         [ 4.87500,  6.18750],\n",
      "         [11.65625, 10.18750]]])\n",
      "[_make_grid Debug] anchor index i => anchors[i]: tensor([[ 3.62500,  2.81250],\n",
      "        [ 4.87500,  6.18750],\n",
      "        [11.65625, 10.18750]])\n",
      "self.anchors[i]: tensor([[ 3.62500,  2.81250],\n",
      "        [ 4.87500,  6.18750],\n",
      "        [11.65625, 10.18750]])\n",
      "self.stride[i]: tensor(32.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   8%|â–Š         | 1/12 [00:01<00:16,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n",
      "\n",
      "[_make_grid Debug] i=0, nx=56, ny=44\n",
      "[_make_grid Debug] stride: tensor([ 8., 16., 32.])\n",
      "[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],\n",
      "         [ 2.00000,  3.75000],\n",
      "         [ 4.12500,  2.87500]],\n",
      "\n",
      "        [[ 1.87500,  3.81250],\n",
      "         [ 3.87500,  2.81250],\n",
      "         [ 3.68750,  7.43750]],\n",
      "\n",
      "        [[ 3.62500,  2.81250],\n",
      "         [ 4.87500,  6.18750],\n",
      "         [11.65625, 10.18750]]])\n",
      "[_make_grid Debug] anchor index i => anchors[i]: tensor([[1.25000, 1.62500],\n",
      "        [2.00000, 3.75000],\n",
      "        [4.12500, 2.87500]])\n",
      "self.anchors[i]: tensor([[1.25000, 1.62500],\n",
      "        [2.00000, 3.75000],\n",
      "        [4.12500, 2.87500]])\n",
      "self.stride[i]: tensor(8.)\n",
      "\n",
      "[_make_grid Debug] i=1, nx=28, ny=22\n",
      "[_make_grid Debug] stride: tensor([ 8., 16., 32.])\n",
      "[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],\n",
      "         [ 2.00000,  3.75000],\n",
      "         [ 4.12500,  2.87500]],\n",
      "\n",
      "        [[ 1.87500,  3.81250],\n",
      "         [ 3.87500,  2.81250],\n",
      "         [ 3.68750,  7.43750]],\n",
      "\n",
      "        [[ 3.62500,  2.81250],\n",
      "         [ 4.87500,  6.18750],\n",
      "         [11.65625, 10.18750]]])\n",
      "[_make_grid Debug] anchor index i => anchors[i]: tensor([[1.87500, 3.81250],\n",
      "        [3.87500, 2.81250],\n",
      "        [3.68750, 7.43750]])\n",
      "self.anchors[i]: tensor([[1.87500, 3.81250],\n",
      "        [3.87500, 2.81250],\n",
      "        [3.68750, 7.43750]])\n",
      "self.stride[i]: tensor(16.)\n",
      "\n",
      "[_make_grid Debug] i=2, nx=14, ny=11\n",
      "[_make_grid Debug] stride: tensor([ 8., 16., 32.])\n",
      "[_make_grid Debug] anchors: tensor([[[ 1.25000,  1.62500],\n",
      "         [ 2.00000,  3.75000],\n",
      "         [ 4.12500,  2.87500]],\n",
      "\n",
      "        [[ 1.87500,  3.81250],\n",
      "         [ 3.87500,  2.81250],\n",
      "         [ 3.68750,  7.43750]],\n",
      "\n",
      "        [[ 3.62500,  2.81250],\n",
      "         [ 4.87500,  6.18750],\n",
      "         [11.65625, 10.18750]]])\n",
      "[_make_grid Debug] anchor index i => anchors[i]: tensor([[ 3.62500,  2.81250],\n",
      "        [ 4.87500,  6.18750],\n",
      "        [11.65625, 10.18750]])\n",
      "self.anchors[i]: tensor([[ 3.62500,  2.81250],\n",
      "        [ 4.87500,  6.18750],\n",
      "        [11.65625, 10.18750]])\n",
      "self.stride[i]: tensor(32.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  17%|â–ˆâ–‹        | 2/12 [00:03<00:15,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  25%|â–ˆâ–ˆâ–Œ       | 3/12 [00:05<00:15,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 4/12 [00:06<00:14,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 5/12 [00:08<00:13,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 6/12 [00:10<00:11,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 7/12 [00:12<00:09,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 8/12 [00:14<00:07,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 9/12 [00:16<00:05,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 10/12 [00:18<00:03,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([16, 256, 22, 28]), torch.Size([16, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 44, 56]), torch.Size([16, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([16, 128, 22, 28]), torch.Size([16, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([16, 256, 11, 14]), torch.Size([16, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 11/12 [00:20<00:01,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat layer inputs: [torch.Size([7, 256, 22, 28]), torch.Size([7, 256, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([7, 128, 44, 56]), torch.Size([7, 128, 44, 56])]\n",
      "Concat layer inputs: [torch.Size([7, 128, 22, 28]), torch.Size([7, 128, 22, 28])]\n",
      "Concat layer inputs: [torch.Size([7, 256, 11, 14]), torch.Size([7, 256, 11, 14])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:21<00:00,  1.79s/it]\n",
      "                   all        183        366   0.000474     0.0971   0.000296   8.38e-05\n",
      "                     0        183        221    0.00117     0.0633   0.000681   0.000157\n",
      "                     1        183         83   0.000317     0.0482   0.000168   5.04e-05\n",
      "                     2        183         14    0.00017      0.214   0.000178   8.55e-05\n",
      "                     3        183         48   0.000237     0.0625   0.000155   4.25e-05\n",
      "Confusion matrix saved to runs\\train\\yolov5s_test274/detection_confusion_matrix.png\n",
      "No classification data available for confusion matrix. Use 'process_classification_batch' to collect data.\n",
      "Results saved to \u001b[1mruns\\train\\yolov5s_test274\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%run -d train.py --img 416 --batch 8 --epochs 10 --data ../Regurgitation-YOLODataset-1new/data.yaml --cfg ./models/yolov5sc.yaml --hyp data/hyps/hyp.custom.yaml --name yolov5s_test --cache\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfbb7d7-e1be-4390-ac57-d5a0817986cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
