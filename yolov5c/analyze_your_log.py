#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åˆ†ææ‚¨æä¾›çš„è¨“ç·´æ—¥èªŒ
"""

import re
import json
from pathlib import Path
import matplotlib.pyplot as plt
import numpy as np
from datetime import datetime

def analyze_training_log():
    """åˆ†ææ‚¨æä¾›çš„è¨“ç·´æ—¥èªŒ"""
    
    # æ‚¨æä¾›çš„è¨“ç·´æ—¥èªŒ
    log_text = """
Epoch 23/40, Batch 0/83, Loss: 3.1771 (Bbox: 0.0026, Cls: 0.3968)
Epoch 23/40, Batch 20/83, Loss: 1.2542 (Bbox: 0.0036, Cls: 0.1563)
Epoch 23/40, Batch 40/83, Loss: 2.5399 (Bbox: 0.0033, Cls: 0.3171)
Epoch 23/40, Batch 60/83, Loss: 1.6488 (Bbox: 0.0037, Cls: 0.2056)
Epoch 23/40, Batch 80/83, Loss: 1.0560 (Bbox: 0.0029, Cls: 0.1316)
Epoch 23:
  Train Loss: 2.0978 (Bbox: 0.0029, Cls: 0.2619)
  Val Loss: 1.5627 (Bbox: 0.0030, Cls: 0.1950)
  Val Cls Accuracy: 0.6490
  Best Val Cls Accuracy: 0.8125
"""
    
    # è§£ææ•¸æ“š
    batch_data = []
    epoch_data = None
    
    lines = log_text.strip().split('\n')
    for line in lines:
        # è§£æbatchæ•¸æ“š
        batch_match = re.search(r'Epoch (\d+)/(\d+), Batch (\d+)/(\d+), Loss: ([\d.]+) \(Bbox: ([\d.]+), Cls: ([\d.]+)\)', line)
        if batch_match:
            batch_data.append({
                'epoch': int(batch_match.group(1)),
                'batch': int(batch_match.group(3)),
                'total_batches': int(batch_match.group(4)),
                'total_loss': float(batch_match.group(5)),
                'bbox_loss': float(batch_match.group(6)),
                'cls_loss': float(batch_match.group(7))
            })
        
        # è§£æepochç¸½çµ
        if line.strip().startswith('Epoch 23:'):
            # è§£ææ¥ä¸‹ä¾†çš„å¹¾è¡Œ
            train_loss_match = re.search(r'Train Loss: ([\d.]+) \(Bbox: ([\d.]+), Cls: ([\d.]+)\)', lines[lines.index(line) + 1])
            val_loss_match = re.search(r'Val Loss: ([\d.]+) \(Bbox: ([\d.]+), Cls: ([\d.]+)\)', lines[lines.index(line) + 2])
            val_acc_match = re.search(r'Val Cls Accuracy: ([\d.]+)', lines[lines.index(line) + 3])
            best_acc_match = re.search(r'Best Val Cls Accuracy: ([\d.]+)', lines[lines.index(line) + 4])
            
            if train_loss_match and val_loss_match and val_acc_match and best_acc_match:
                epoch_data = {
                    'epoch': 23,
                    'train_loss': float(train_loss_match.group(1)),
                    'train_bbox_loss': float(train_loss_match.group(2)),
                    'train_cls_loss': float(train_loss_match.group(3)),
                    'val_loss': float(val_loss_match.group(1)),
                    'val_bbox_loss': float(val_loss_match.group(2)),
                    'val_cls_loss': float(val_loss_match.group(3)),
                    'val_cls_accuracy': float(val_acc_match.group(1)),
                    'best_val_cls_accuracy': float(best_acc_match.group(1))
                }
    
    # åˆ†æçµæœ
    if epoch_data:
        analysis = {
            'current_epoch': epoch_data['epoch'],
            'total_epochs': 40,
            'progress': f"{epoch_data['epoch']}/40 ({epoch_data['epoch']/40*100:.1f}%)",
            
            # æå¤±åˆ†æ
            'train_loss': epoch_data['train_loss'],
            'val_loss': epoch_data['val_loss'],
            'loss_gap': epoch_data['train_loss'] - epoch_data['val_loss'],
            
            # åˆ†é¡æº–ç¢ºç‡
            'current_accuracy': epoch_data['val_cls_accuracy'],
            'best_accuracy': epoch_data['best_val_cls_accuracy'],
            'accuracy_trend': 'declining' if epoch_data['val_cls_accuracy'] < epoch_data['best_val_cls_accuracy'] else 'improving',
            
            # éæ“¬åˆåˆ†æ
            'overfitting_risk': 'high' if epoch_data['train_loss'] > epoch_data['val_loss'] else 'low',
            
            # å»ºè­°
            'recommendations': []
        }
        
        # ç”Ÿæˆå»ºè­°
        if epoch_data['train_loss'] > epoch_data['val_loss']:
            analysis['recommendations'].append("âš ï¸ æª¢æ¸¬åˆ°éæ“¬åˆé¢¨éšªï¼šè¨“ç·´æå¤± > é©—è­‰æå¤±")
            analysis['recommendations'].append("å»ºè­°ï¼šæ¸›å°‘è¨“ç·´è¼ªæ•¸æˆ–å¢åŠ æ­£å‰‡åŒ–")
        
        if epoch_data['val_cls_accuracy'] < epoch_data['best_val_cls_accuracy']:
            analysis['recommendations'].append("âš ï¸ åˆ†é¡æº–ç¢ºç‡ä¸‹é™ï¼šç•¶å‰ < æœ€ä½³")
            analysis['recommendations'].append("å»ºè­°ï¼šæª¢æŸ¥å­¸ç¿’ç‡æˆ–æ•¸æ“šè³ªé‡")
        
        if epoch_data['val_cls_accuracy'] < 0.7:
            analysis['recommendations'].append("âš ï¸ åˆ†é¡æº–ç¢ºç‡åä½ (< 70%)")
            analysis['recommendations'].append("å»ºè­°ï¼šå¢åŠ è¨“ç·´æ•¸æ“šæˆ–èª¿æ•´æ¨¡å‹æ¶æ§‹")
        
        if epoch_data['epoch'] < 20:
            analysis['recommendations'].append("â„¹ï¸ è¨“ç·´è¼ªæ•¸è¼ƒå°‘ï¼Œå»ºè­°ç¹¼çºŒè¨“ç·´")
        
        # ç”Ÿæˆå ±å‘Š
        generate_report(analysis, batch_data, epoch_data)
        
        return analysis
    else:
        print("âŒ ç„¡æ³•è§£æè¨“ç·´æ—¥èªŒæ•¸æ“š")
        return None

def generate_report(analysis, batch_data, epoch_data):
    """ç”Ÿæˆåˆ†æå ±å‘Š"""
    save_dir = Path('runs/analysis')
    save_dir.mkdir(parents=True, exist_ok=True)
    
    # ç”Ÿæˆåœ–è¡¨
    generate_plots(batch_data, epoch_data, save_dir)
    
    # ç”Ÿæˆå ±å‘Š
    report = f"""
# ğŸ“Š è¨“ç·´æ—¥èªŒåˆ†æå ±å‘Š

## ğŸ¯ ç•¶å‰ç‹€æ…‹
- **è¨“ç·´é€²åº¦**: {analysis['progress']}
- **ç•¶å‰Epoch**: {analysis['current_epoch']}/40

## ğŸ“ˆ æ€§èƒ½æŒ‡æ¨™

### æå¤±å‡½æ•¸
- **è¨“ç·´æå¤±**: {analysis['train_loss']:.4f}
- **é©—è­‰æå¤±**: {analysis['val_loss']:.4f}
- **æå¤±å·®è·**: {analysis['loss_gap']:.4f} ({'éæ“¬åˆé¢¨éšª' if analysis['loss_gap'] > 0 else 'æ­£å¸¸'})

### åˆ†é¡æ€§èƒ½
- **ç•¶å‰æº–ç¢ºç‡**: {analysis['current_accuracy']:.4f} ({analysis['current_accuracy']*100:.1f}%)
- **æœ€ä½³æº–ç¢ºç‡**: {analysis['best_accuracy']:.4f} ({analysis['best_accuracy']*100:.1f}%)
- **æº–ç¢ºç‡è¶¨å‹¢**: {analysis['accuracy_trend']}

### é¢¨éšªè©•ä¼°
- **éæ“¬åˆé¢¨éšª**: {analysis['overfitting_risk']}

## ğŸ“Š Batchç´šåˆ¥åˆ†æ

### æå¤±è®ŠåŒ–è¶¨å‹¢
"""
    
    if batch_data:
        losses = [b['total_loss'] for b in batch_data]
        bbox_losses = [b['bbox_loss'] for b in batch_data]
        cls_losses = [b['cls_loss'] for b in batch_data]
        
        report += f"""
- **ç¸½æå¤±ç¯„åœ**: {min(losses):.4f} - {max(losses):.4f}
- **é‚Šç•Œæ¡†æå¤±ç¯„åœ**: {min(bbox_losses):.4f} - {max(bbox_losses):.4f}
- **åˆ†é¡æå¤±ç¯„åœ**: {min(cls_losses):.4f} - {max(cls_losses):.4f}
- **æå¤±ç©©å®šæ€§**: {'ç©©å®š' if max(losses) - min(losses) < 1.0 else 'ä¸ç©©å®š'}
"""

    report += f"""
## ğŸ¯ å»ºè­°

"""
    
    for rec in analysis['recommendations']:
        report += f"{rec}\n"
    
    report += f"""
## ğŸ“ˆ è©³ç´°æ•¸æ“š

### Epoch 23 è©³ç´°æŒ‡æ¨™
- **è¨“ç·´æå¤±**: {epoch_data['train_loss']:.4f} (Bbox: {epoch_data['train_bbox_loss']:.4f}, Cls: {epoch_data['train_cls_loss']:.4f})
- **é©—è­‰æå¤±**: {epoch_data['val_loss']:.4f} (Bbox: {epoch_data['val_bbox_loss']:.4f}, Cls: {epoch_data['val_cls_loss']:.4f})
- **åˆ†é¡æº–ç¢ºç‡**: {epoch_data['val_cls_accuracy']:.4f} (æœ€ä½³: {epoch_data['best_val_cls_accuracy']:.4f})

### Batchç´šåˆ¥æ•¸æ“š
"""
    
    for i, batch in enumerate(batch_data):
        report += f"""
**Batch {batch['batch']}**:
- ç¸½æå¤±: {batch['total_loss']:.4f}
- é‚Šç•Œæ¡†æå¤±: {batch['bbox_loss']:.4f}
- åˆ†é¡æå¤±: {batch['cls_loss']:.4f}
"""
    
    report += f"""
## ğŸ” é—œéµç™¼ç¾

1. **éæ“¬åˆè­¦å‘Š**: è¨“ç·´æå¤± ({epoch_data['train_loss']:.4f}) > é©—è­‰æå¤± ({epoch_data['val_loss']:.4f})
2. **æº–ç¢ºç‡ä¸‹é™**: ç•¶å‰æº–ç¢ºç‡ ({epoch_data['val_cls_accuracy']:.4f}) < æœ€ä½³æº–ç¢ºç‡ ({epoch_data['best_val_cls_accuracy']:.4f})
3. **é‚Šç•Œæ¡†æ€§èƒ½**: é‚Šç•Œæ¡†æå¤±å¾ˆä½ ({epoch_data['train_bbox_loss']:.4f})ï¼Œè¡¨ç¤ºå®šä½æº–ç¢º
4. **åˆ†é¡æŒ‘æˆ°**: åˆ†é¡æå¤± ({epoch_data['train_cls_loss']:.4f}) ç›¸å°è¼ƒé«˜ï¼Œéœ€è¦æ”¹å–„

## ğŸš€ ç«‹å³è¡Œå‹•å»ºè­°

1. **èª¿æ•´å­¸ç¿’ç‡**: è€ƒæ…®é™ä½å­¸ç¿’ç‡ä»¥ç©©å®šè¨“ç·´
2. **å¢åŠ æ­£å‰‡åŒ–**: æ·»åŠ Dropoutæˆ–Weight Decay
3. **æ—©åœæ©Ÿåˆ¶**: ç›£æ§é©—è­‰æå¤±ï¼Œé¿å…éæ“¬åˆ
4. **æ•¸æ“šå¢å¼·**: å¢åŠ è¨“ç·´æ•¸æ“šçš„å¤šæ¨£æ€§
5. **æ¨¡å‹æª¢æŸ¥**: è€ƒæ…®ä½¿ç”¨æ›´å°çš„æ¨¡å‹æˆ–èª¿æ•´æ¶æ§‹

---
*å ±å‘Šç”Ÿæˆæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
"""
    
    # ä¿å­˜å ±å‘Š
    with open(save_dir / 'training_log_analysis.md', 'w', encoding='utf-8') as f:
        f.write(report)
    
    # ä¿å­˜JSONæ•¸æ“š
    with open(save_dir / 'training_log_data.json', 'w') as f:
        json.dump({
            'analysis': analysis,
            'batch_data': batch_data,
            'epoch_data': epoch_data
        }, f, indent=2)
    
    print(f"ğŸ“„ åˆ†æå ±å‘Šå·²ä¿å­˜åˆ°: {save_dir / 'training_log_analysis.md'}")
    print(f"ğŸ“Š æ•¸æ“šæ–‡ä»¶å·²ä¿å­˜åˆ°: {save_dir / 'training_log_data.json'}")

def generate_plots(batch_data, epoch_data, save_dir):
    """ç”Ÿæˆåˆ†æåœ–è¡¨"""
    if not batch_data or not epoch_data:
        return
    
    # å‰µå»ºåœ–è¡¨
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    
    # 1. Batchæå¤±è®ŠåŒ–
    batch_nums = [b['batch'] for b in batch_data]
    total_losses = [b['total_loss'] for b in batch_data]
    bbox_losses = [b['bbox_loss'] for b in batch_data]
    cls_losses = [b['cls_loss'] for b in batch_data]
    
    axes[0, 0].plot(batch_nums, total_losses, 'b-', label='Total Loss', linewidth=2, marker='o')
    axes[0, 0].plot(batch_nums, bbox_losses, 'orange', label='Bbox Loss', linewidth=2, marker='s')
    axes[0, 0].plot(batch_nums, cls_losses, 'purple', label='Cls Loss', linewidth=2, marker='^')
    axes[0, 0].set_title('Batch Loss Progression (Epoch 23)')
    axes[0, 0].set_xlabel('Batch Number')
    axes[0, 0].set_ylabel('Loss')
    axes[0, 0].legend()
    axes[0, 0].grid(True, alpha=0.3)
    
    # 2. æå¤±çµ„ä»¶æ¯”è¼ƒ
    components = ['Total', 'Bbox', 'Cls']
    train_values = [epoch_data['train_loss'], epoch_data['train_bbox_loss'], epoch_data['train_cls_loss']]
    val_values = [epoch_data['val_loss'], epoch_data['val_bbox_loss'], epoch_data['val_cls_loss']]
    
    x = np.arange(len(components))
    width = 0.35
    
    axes[0, 1].bar(x - width/2, train_values, width, label='Train', alpha=0.8)
    axes[0, 1].bar(x + width/2, val_values, width, label='Validation', alpha=0.8)
    axes[0, 1].set_title('Loss Components Comparison')
    axes[0, 1].set_xlabel('Loss Type')
    axes[0, 1].set_ylabel('Loss Value')
    axes[0, 1].set_xticks(x)
    axes[0, 1].set_xticklabels(components)
    axes[0, 1].legend()
    axes[0, 1].grid(True, alpha=0.3)
    
    # 3. æº–ç¢ºç‡åˆ†æ
    accuracies = [epoch_data['val_cls_accuracy'], epoch_data['best_val_cls_accuracy']]
    labels = ['Current', 'Best']
    colors = ['red' if epoch_data['val_cls_accuracy'] < epoch_data['best_val_cls_accuracy'] else 'green', 'blue']
    
    axes[1, 0].bar(labels, accuracies, color=colors, alpha=0.7)
    axes[1, 0].set_title('Classification Accuracy')
    axes[1, 0].set_ylabel('Accuracy')
    axes[1, 0].set_ylim(0, 1)
    for i, v in enumerate(accuracies):
        axes[1, 0].text(i, v + 0.01, f'{v:.3f}', ha='center', va='bottom')
    axes[1, 0].grid(True, alpha=0.3)
    
    # 4. éæ“¬åˆæŒ‡æ¨™
    train_val_gap = epoch_data['train_loss'] - epoch_data['val_loss']
    colors = ['red' if train_val_gap > 0 else 'green']
    
    axes[1, 1].bar(['Train-Val Gap'], [train_val_gap], color=colors, alpha=0.7)
    axes[1, 1].axhline(y=0, color='black', linestyle='--', alpha=0.5)
    axes[1, 1].set_title('Overfitting Indicator')
    axes[1, 1].set_ylabel('Loss Gap')
    axes[1, 1].text(0, train_val_gap + (0.1 if train_val_gap > 0 else -0.1), 
                   f'{train_val_gap:.3f}', ha='center', va='bottom' if train_val_gap > 0 else 'top')
    axes[1, 1].grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(save_dir / 'training_log_analysis.png', dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"ğŸ“Š åˆ†æåœ–è¡¨å·²ä¿å­˜åˆ°: {save_dir / 'training_log_analysis.png'}")

if __name__ == "__main__":
    print("ğŸ” é–‹å§‹åˆ†ææ‚¨çš„è¨“ç·´æ—¥èªŒ...")
    analysis = analyze_training_log()
    
    if analysis:
        print("\n" + "="*60)
        print("ğŸ“Š åˆ†æçµæœæ‘˜è¦")
        print("="*60)
        print(f"ğŸ¯ è¨“ç·´é€²åº¦: {analysis['progress']}")
        print(f"ğŸ“ˆ è¨“ç·´æå¤±: {analysis['train_loss']:.4f}")
        print(f"ğŸ“‰ é©—è­‰æå¤±: {analysis['val_loss']:.4f}")
        print(f"ğŸ¯ ç•¶å‰æº–ç¢ºç‡: {analysis['current_accuracy']:.4f} ({analysis['current_accuracy']*100:.1f}%)")
        print(f"ğŸ† æœ€ä½³æº–ç¢ºç‡: {analysis['best_accuracy']:.4f} ({analysis['best_accuracy']*100:.1f}%)")
        print(f"âš ï¸ éæ“¬åˆé¢¨éšª: {analysis['overfitting_risk']}")
        
        print("\nğŸ¯ å»ºè­°:")
        for rec in analysis['recommendations']:
            print(f"  {rec}")
        
        print("\nâœ… åˆ†æå®Œæˆï¼è©³ç´°å ±å‘Šå·²ä¿å­˜åˆ° runs/analysis/ ç›®éŒ„")
    else:
        print("âŒ åˆ†æå¤±æ•—") 