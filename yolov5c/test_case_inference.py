#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Test Case Inference
æ¸¬è©¦æ¡ˆä¾‹æ¨ç†è…³æœ¬ - ç”¨æ–¼å–®å€‹åœ–åƒçš„æ¨ç†
"""

import os
import sys
import argparse
import numpy as np
import torch
import yaml
from pathlib import Path
from PIL import Image
import matplotlib.pyplot as plt
import matplotlib.patches as patches

# æ·»åŠ é …ç›®è·¯å¾‘
sys.path.append(str(Path(__file__).parent))

try:
    from train_joint_ultimate import UltimateJointModel
except ImportError:
    print("ç„¡æ³•å°å…¥UltimateJointModelï¼Œä½¿ç”¨åŸºç¤æ¨¡å‹")
    from train_joint_simple import SimpleJointModel as UltimateJointModel


class TestCaseInference:
    def __init__(self, data_yaml, weights_path):
        self.data_yaml = Path(data_yaml)
        self.weights_path = Path(weights_path)
        
        # è¼‰å…¥æ•¸æ“šé…ç½®
        self.load_data_config()
        
        # è¼‰å…¥æ¨¡å‹
        self.load_model()
        
        # è¨­ç½®è¨­å‚™
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model.to(self.device)
        
    def load_data_config(self):
        """è¼‰å…¥æ•¸æ“šé…ç½®"""
        with open(self.data_yaml, 'r') as f:
            config = yaml.safe_load(f)
        
        self.detection_classes = config.get('names', [])
        self.classification_classes = ['PSAX', 'PLAX', 'A4C']
        self.num_detection_classes = len(self.detection_classes)
        
        print(f"âœ… æ•¸æ“šé…ç½®è¼‰å…¥å®Œæˆ:")
        print(f"   - æª¢æ¸¬é¡åˆ¥: {self.detection_classes}")
        print(f"   - åˆ†é¡é¡åˆ¥: {self.classification_classes}")
    
    def load_model(self):
        """è¼‰å…¥è¨“ç·´å¥½çš„æ¨¡å‹"""
        if not self.weights_path.exists():
            raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {self.weights_path}")
        
        # å‰µå»ºæ¨¡å‹å¯¦ä¾‹
        self.model = UltimateJointModel(num_classes=self.num_detection_classes)
        
        # è¼‰å…¥æ¬Šé‡
        checkpoint = torch.load(self.weights_path, map_location='cpu')
        if 'model_state_dict' in checkpoint:
            self.model.load_state_dict(checkpoint['model_state_dict'])
        else:
            self.model.load_state_dict(checkpoint)
        
        self.model.eval()
        print(f"âœ… æ¨¡å‹è¼‰å…¥å®Œæˆ: {self.weights_path}")
    
    def preprocess_image(self, image_path):
        """é è™•ç†åœ–åƒ"""
        # è¼‰å…¥åœ–åƒ
        image = Image.open(image_path).convert('RGB')
        
        # è½‰æ›ç‚ºtensor
        image_tensor = torch.from_numpy(np.array(image)).float()
        image_tensor = image_tensor.permute(2, 0, 1).unsqueeze(0)  # BCHW
        
        # èª¿æ•´å¤§å°åˆ° 224x224
        image_tensor = torch.nn.functional.interpolate(image_tensor, size=(224, 224), mode='bilinear', align_corners=False)
        
        # æ­£è¦åŒ–
        image_tensor = image_tensor / 255.0
        
        return image_tensor, image
    
    def inference(self, image_path):
        """åŸ·è¡Œæ¨ç†"""
        print(f"\nğŸ” é–‹å§‹æ¨ç†: {image_path}")
        
        # é è™•ç†åœ–åƒ
        image_tensor, original_image = self.preprocess_image(image_path)
        image_tensor = image_tensor.to(self.device)
        
        # æ¨ç†
        with torch.no_grad():
            bbox_preds, cls_preds = self.model(image_tensor)
        
        # å¾Œè™•ç†çµæœ
        bbox_pred = bbox_preds[0].cpu().numpy()
        cls_pred = cls_preds[0].cpu().numpy()
        
        # ç²å–æª¢æ¸¬çµæœ
        detection_class_idx = np.argmax(bbox_pred[:4])  # å‰4å€‹æ˜¯æª¢æ¸¬é¡åˆ¥
        detection_class = self.detection_classes[detection_class_idx]
        detection_confidence = np.max(bbox_pred[:4])
        
        # ç²å–åˆ†é¡çµæœ
        classification_class_idx = np.argmax(cls_pred)
        classification_class = self.classification_classes[classification_class_idx]
        classification_confidence = np.max(cls_pred)
        
        # ç²å–bboxåº§æ¨™
        bbox_coords = bbox_pred[4:8]  # å‡è¨­å¾Œ4å€‹æ˜¯bboxåº§æ¨™
        
        results = {
            'detection': {
                'class': detection_class,
                'confidence': detection_confidence,
                'bbox': bbox_coords
            },
            'classification': {
                'class': classification_class,
                'confidence': classification_confidence
            },
            'original_image': original_image
        }
        
        return results
    
    def visualize_results(self, results, output_path=None):
        """å¯è¦–åŒ–æ¨ç†çµæœ"""
        image = results['original_image']
        
        # å‰µå»ºåœ–è¡¨
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
        
        # åŸå§‹åœ–åƒ
        ax1.imshow(image)
        ax1.set_title('åŸå§‹åœ–åƒ', fontsize=14)
        ax1.axis('off')
        
        # æ¨ç†çµæœ
        ax2.imshow(image)
        
        # ç¹ªè£½bbox
        bbox = results['detection']['bbox']
        if len(bbox) >= 4:
            # å‡è¨­bboxæ ¼å¼ç‚º [x_center, y_center, width, height]
            x_center, y_center, width, height = bbox[:4]
            x1 = (x_center - width/2) * image.width
            y1 = (y_center - height/2) * image.height
            rect = patches.Rectangle((x1, y1), width * image.width, height * image.height, 
                                   linewidth=2, edgecolor='red', facecolor='none')
            ax2.add_patch(rect)
        
        # æ·»åŠ æ–‡å­—æ¨™ç±¤
        detection_text = f"æª¢æ¸¬: {results['detection']['class']} ({results['detection']['confidence']:.3f})"
        classification_text = f"åˆ†é¡: {results['classification']['class']} ({results['classification']['confidence']:.3f})"
        
        ax2.text(10, 30, detection_text, fontsize=12, color='red', 
                bbox=dict(boxstyle="round,pad=0.3", facecolor="white", alpha=0.8))
        ax2.text(10, 60, classification_text, fontsize=12, color='blue',
                bbox=dict(boxstyle="round,pad=0.3", facecolor="white", alpha=0.8))
        
        ax2.set_title('æ¨ç†çµæœ', fontsize=14)
        ax2.axis('off')
        
        plt.tight_layout()
        
        if output_path:
            plt.savefig(output_path, dpi=300, bbox_inches='tight')
            print(f"âœ… å¯è¦–åŒ–çµæœå·²ä¿å­˜åˆ°: {output_path}")
        
        plt.show()
    
    def print_results(self, results):
        """æ‰“å°æ¨ç†çµæœ"""
        print(f"\nğŸ“Š æ¨ç†çµæœ:")
        print(f"   - æª¢æ¸¬é¡åˆ¥: {results['detection']['class']}")
        print(f"   - æª¢æ¸¬ç½®ä¿¡åº¦: {results['detection']['confidence']:.4f}")
        print(f"   - åˆ†é¡é¡åˆ¥: {results['classification']['class']}")
        print(f"   - åˆ†é¡ç½®ä¿¡åº¦: {results['classification']['confidence']:.4f}")
        print(f"   - Bboxåº§æ¨™: {results['detection']['bbox']}")
        
        # æ€§èƒ½è©•ä¼°
        detection_conf = results['detection']['confidence']
        classification_conf = results['classification']['confidence']
        
        print(f"\nğŸ¯ æ€§èƒ½è©•ä¼°:")
        print(f"   - æª¢æ¸¬ç½®ä¿¡åº¦ > 0.5: {'âœ… é«˜ç½®ä¿¡åº¦' if detection_conf > 0.5 else 'âš ï¸ ä½ç½®ä¿¡åº¦'}")
        print(f"   - åˆ†é¡ç½®ä¿¡åº¦ > 0.5: {'âœ… é«˜ç½®ä¿¡åº¦' if classification_conf > 0.5 else 'âš ï¸ ä½ç½®ä¿¡åº¦'}")
        
        if detection_conf > 0.7 and classification_conf > 0.7:
            print(f"   - æ•´é«”è©•ä¼°: âœ… å„ªç§€")
        elif detection_conf > 0.5 and classification_conf > 0.5:
            print(f"   - æ•´é«”è©•ä¼°: âš ï¸ ä¸­ç­‰")
        else:
            print(f"   - æ•´é«”è©•ä¼°: âŒ éœ€è¦æ”¹é€²")


def main():
    """ä¸»å‡½æ•¸"""
    parser = argparse.ArgumentParser(description='æ¸¬è©¦æ¡ˆä¾‹æ¨ç†')
    parser.add_argument('--data', type=str, required=True, help='æ•¸æ“šé…ç½®æ–‡ä»¶è·¯å¾‘')
    parser.add_argument('--weights', type=str, required=True, help='æ¨¡å‹æ¬Šé‡æ–‡ä»¶è·¯å¾‘')
    parser.add_argument('--image', type=str, required=True, help='æ¸¬è©¦åœ–åƒè·¯å¾‘')
    parser.add_argument('--output', type=str, help='è¼¸å‡ºå¯è¦–åŒ–æ–‡ä»¶è·¯å¾‘')
    
    args = parser.parse_args()
    
    try:
        # å‰µå»ºæ¨ç†å™¨
        inference = TestCaseInference(args.data, args.weights)
        
        # åŸ·è¡Œæ¨ç†
        results = inference.inference(args.image)
        
        # æ‰“å°çµæœ
        inference.print_results(results)
        
        # å¯è¦–åŒ–çµæœ
        if args.output:
            inference.visualize_results(results, args.output)
        else:
            inference.visualize_results(results)
        
        print(f"\nğŸ‰ æ¨ç†å®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ æ¨ç†å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main() 