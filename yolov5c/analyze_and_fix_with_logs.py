#!/usr/bin/env python3
"""
ğŸ”§ è¨“ç·´åˆ†æèˆ‡ä¿®å¾©å·¥å…· (å«è©³ç´°æ—¥èªŒ)
åˆ†æè¨“ç·´æ­·å²ä¸¦æä¾›ä¿®å¾©å»ºè­°
"""

import json
import matplotlib.pyplot as plt
import numpy as np
import os
import logging
from datetime import datetime
import argparse
from pathlib import Path

# è¨­ç½®æ—¥èªŒ
def setup_logging(log_file="training_analysis.log"):
    """è¨­ç½®è©³ç´°çš„æ—¥èªŒè¨˜éŒ„"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_file, encoding='utf-8'),
            logging.StreamHandler()
        ]
    )
    return logging.getLogger(__name__)

def analyze_training_history(history_file, logger):
    """åˆ†æè¨“ç·´æ­·å²æ•¸æ“š"""
    logger.info("ğŸ” é–‹å§‹åˆ†æè¨“ç·´æ­·å²æ•¸æ“š...")
    
    try:
        with open(history_file, 'r') as f:
            history = json.load(f)
        logger.info(f"âœ… æˆåŠŸè¼‰å…¥è¨“ç·´æ­·å²æ–‡ä»¶: {history_file}")
    except Exception as e:
        logger.error(f"âŒ è¼‰å…¥è¨“ç·´æ­·å²æ–‡ä»¶å¤±æ•—: {e}")
        return None
    
    # æå–æ•¸æ“š
    train_losses = history.get('train_losses', [])
    val_losses = history.get('val_losses', [])
    val_accuracies = history.get('val_accuracies', [])
    overfitting_flags = history.get('overfitting_flags', [])
    accuracy_drops = history.get('accuracy_drops', [])
    
    logger.info(f"ğŸ“Š æ•¸æ“šçµ±è¨ˆ:")
    logger.info(f"  - è¨“ç·´è¼ªæ•¸: {len(train_losses)}")
    logger.info(f"  - è¨“ç·´æå¤±ç¯„åœ: {min(train_losses):.4f} - {max(train_losses):.4f}")
    logger.info(f"  - é©—è­‰æå¤±ç¯„åœ: {min(val_losses):.4f} - {max(val_losses):.4f}")
    logger.info(f"  - é©—è­‰æº–ç¢ºç‡ç¯„åœ: {min(val_accuracies):.4f} - {max(val_accuracies):.4f}")
    
    return {
        'train_losses': train_losses,
        'val_losses': val_losses,
        'val_accuracies': val_accuracies,
        'overfitting_flags': overfitting_flags,
        'accuracy_drops': accuracy_drops
    }

def detect_issues(data, logger):
    """æª¢æ¸¬è¨“ç·´å•é¡Œ"""
    logger.info("ğŸ” é–‹å§‹æª¢æ¸¬è¨“ç·´å•é¡Œ...")
    
    issues = []
    
    # 1. éæ“¬åˆæª¢æ¸¬
    overfitting_count = sum(data['overfitting_flags'])
    if overfitting_count > 0:
        logger.warning(f"âš ï¸ æª¢æ¸¬åˆ° {overfitting_count} æ¬¡éæ“¬åˆå•é¡Œ")
        issues.append({
            'type': 'overfitting',
            'count': overfitting_count,
            'severity': 'high' if overfitting_count > 5 else 'medium'
        })
    else:
        logger.info("âœ… æœªæª¢æ¸¬åˆ°éæ“¬åˆå•é¡Œ")
    
    # 2. æº–ç¢ºç‡ä¸‹é™æª¢æ¸¬
    accuracy_drop_count = sum(data['accuracy_drops'])
    if accuracy_drop_count > 0:
        logger.warning(f"âš ï¸ æª¢æ¸¬åˆ° {accuracy_drop_count} æ¬¡æº–ç¢ºç‡ä¸‹é™å•é¡Œ")
        issues.append({
            'type': 'accuracy_drop',
            'count': accuracy_drop_count,
            'severity': 'high' if accuracy_drop_count > 20 else 'medium'
        })
    else:
        logger.info("âœ… æœªæª¢æ¸¬åˆ°æº–ç¢ºç‡ä¸‹é™å•é¡Œ")
    
    # 3. è¨“ç·´ä¸ç©©å®šæª¢æ¸¬
    train_loss_std = np.std(data['train_losses'])
    val_loss_std = np.std(data['val_losses'])
    
    if train_loss_std > 0.2:
        logger.warning(f"âš ï¸ è¨“ç·´æå¤±ä¸ç©©å®š (æ¨™æº–å·®: {train_loss_std:.4f})")
        issues.append({
            'type': 'unstable_training',
            'std': train_loss_std,
            'severity': 'medium'
        })
    
    if val_loss_std > 0.3:
        logger.warning(f"âš ï¸ é©—è­‰æå¤±ä¸ç©©å®š (æ¨™æº–å·®: {val_loss_std:.4f})")
        issues.append({
            'type': 'unstable_validation',
            'std': val_loss_std,
            'severity': 'high'
        })
    
    # 4. æœ€çµ‚æ€§èƒ½åˆ†æ
    final_accuracy = data['val_accuracies'][-1]
    best_accuracy = max(data['val_accuracies'])
    
    logger.info(f"ğŸ“ˆ æ€§èƒ½åˆ†æ:")
    logger.info(f"  - æœ€çµ‚æº–ç¢ºç‡: {final_accuracy:.4f}")
    logger.info(f"  - æœ€ä½³æº–ç¢ºç‡: {best_accuracy:.4f}")
    logger.info(f"  - æ€§èƒ½å·®è·: {best_accuracy - final_accuracy:.4f}")
    
    if final_accuracy < 0.7:
        logger.warning("âš ï¸ æœ€çµ‚æº–ç¢ºç‡åä½ (< 70%)")
        issues.append({
            'type': 'low_accuracy',
            'final_accuracy': final_accuracy,
            'severity': 'high'
        })
    
    return issues

def generate_fix_recommendations(issues, data, logger):
    """ç”Ÿæˆä¿®å¾©å»ºè­°"""
    logger.info("ğŸ”§ ç”Ÿæˆä¿®å¾©å»ºè­°...")
    
    recommendations = []
    
    for issue in issues:
        if issue['type'] == 'overfitting':
            logger.info("ğŸ”§ éæ“¬åˆä¿®å¾©å»ºè­°:")
            logger.info("  - å¢åŠ  Dropout ç‡ (0.3 -> 0.5)")
            logger.info("  - å¢åŠ  Weight Decay (1e-4 -> 5e-4)")
            logger.info("  - æ¸›å°‘å­¸ç¿’ç‡ (ç•¶å‰ * 0.8)")
            logger.info("  - å¢åŠ æ•¸æ“šå¢å¼·")
            recommendations.append({
                'issue': 'overfitting',
                'solutions': [
                    'increase_dropout',
                    'increase_weight_decay', 
                    'reduce_learning_rate',
                    'increase_data_augmentation'
                ]
            })
        
        elif issue['type'] == 'accuracy_drop':
            logger.info("ğŸ”§ æº–ç¢ºç‡ä¸‹é™ä¿®å¾©å»ºè­°:")
            logger.info("  - èª¿æ•´åˆ†é¡æå¤±æ¬Šé‡")
            logger.info("  - ä½¿ç”¨ Focal Loss")
            logger.info("  - å¯¦æ–½å­¸ç¿’ç‡èª¿åº¦")
            logger.info("  - æª¢æŸ¥æ•¸æ“šå¹³è¡¡")
            recommendations.append({
                'issue': 'accuracy_drop',
                'solutions': [
                    'adjust_classification_weight',
                    'use_focal_loss',
                    'implement_lr_scheduling',
                    'check_data_balance'
                ]
            })
        
        elif issue['type'] == 'unstable_training':
            logger.info("ğŸ”§ è¨“ç·´ä¸ç©©å®šä¿®å¾©å»ºè­°:")
            logger.info("  - é™ä½å­¸ç¿’ç‡")
            logger.info("  - å¢åŠ æ‰¹æ¬¡å¤§å°")
            logger.info("  - ä½¿ç”¨æ¢¯åº¦è£å‰ª")
            logger.info("  - æª¢æŸ¥æ•¸æ“šé è™•ç†")
            recommendations.append({
                'issue': 'unstable_training',
                'solutions': [
                    'reduce_learning_rate',
                    'increase_batch_size',
                    'use_gradient_clipping',
                    'check_data_preprocessing'
                ]
            })
        
        elif issue['type'] == 'low_accuracy':
            logger.info("ğŸ”§ ä½æº–ç¢ºç‡ä¿®å¾©å»ºè­°:")
            logger.info("  - å¢åŠ è¨“ç·´è¼ªæ•¸")
            logger.info("  - èª¿æ•´æ¨¡å‹æ¶æ§‹")
            logger.info("  - å„ªåŒ–æ•¸æ“šå¢å¼·")
            logger.info("  - æª¢æŸ¥æ¨™ç±¤è³ªé‡")
            recommendations.append({
                'issue': 'low_accuracy',
                'solutions': [
                    'increase_epochs',
                    'adjust_model_architecture',
                    'optimize_data_augmentation',
                    'check_label_quality'
                ]
            })
    
    return recommendations

def create_analysis_plots(data, output_dir, logger):
    """å‰µå»ºåˆ†æåœ–è¡¨"""
    logger.info("ğŸ“Š å‰µå»ºåˆ†æåœ–è¡¨...")
    
    try:
        # å‰µå»ºåœ–è¡¨
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle('è¨“ç·´åˆ†æå ±å‘Š', fontsize=16, fontweight='bold')
        
        epochs = range(1, len(data['train_losses']) + 1)
        
        # 1. æå¤±æ›²ç·š
        axes[0, 0].plot(epochs, data['train_losses'], 'b-', label='è¨“ç·´æå¤±', linewidth=2)
        axes[0, 0].plot(epochs, data['val_losses'], 'r-', label='é©—è­‰æå¤±', linewidth=2)
        axes[0, 0].set_title('æå¤±æ›²ç·š')
        axes[0, 0].set_xlabel('Epoch')
        axes[0, 0].set_ylabel('Loss')
        axes[0, 0].legend()
        axes[0, 0].grid(True, alpha=0.3)
        
        # 2. æº–ç¢ºç‡æ›²ç·š
        axes[0, 1].plot(epochs, data['val_accuracies'], 'g-', label='é©—è­‰æº–ç¢ºç‡', linewidth=2)
        axes[0, 1].set_title('æº–ç¢ºç‡æ›²ç·š')
        axes[0, 1].set_xlabel('Epoch')
        axes[0, 1].set_ylabel('Accuracy')
        axes[0, 1].legend()
        axes[0, 1].grid(True, alpha=0.3)
        
        # 3. å•é¡Œæª¢æ¸¬
        overfitting_epochs = [i+1 for i, flag in enumerate(data['overfitting_flags']) if flag]
        accuracy_drop_epochs = [i+1 for i, flag in enumerate(data['accuracy_drops']) if flag]
        
        axes[1, 0].plot(epochs, data['train_losses'], 'b-', label='è¨“ç·´æå¤±', alpha=0.7)
        axes[1, 0].plot(epochs, data['val_losses'], 'r-', label='é©—è­‰æå¤±', alpha=0.7)
        if overfitting_epochs:
            axes[1, 0].scatter(overfitting_epochs, [data['val_losses'][i-1] for i in overfitting_epochs], 
                              color='red', s=50, label='éæ“¬åˆ', zorder=5)
        axes[1, 0].set_title('å•é¡Œæª¢æ¸¬')
        axes[1, 0].set_xlabel('Epoch')
        axes[1, 0].set_ylabel('Loss')
        axes[1, 0].legend()
        axes[1, 0].grid(True, alpha=0.3)
        
        # 4. æº–ç¢ºç‡å•é¡Œ
        axes[1, 1].plot(epochs, data['val_accuracies'], 'g-', label='é©—è­‰æº–ç¢ºç‡', alpha=0.7)
        if accuracy_drop_epochs:
            axes[1, 1].scatter(accuracy_drop_epochs, [data['val_accuracies'][i-1] for i in accuracy_drop_epochs], 
                              color='orange', s=50, label='æº–ç¢ºç‡ä¸‹é™', zorder=5)
        axes[1, 1].set_title('æº–ç¢ºç‡å•é¡Œæª¢æ¸¬')
        axes[1, 1].set_xlabel('Epoch')
        axes[1, 1].set_ylabel('Accuracy')
        axes[1, 1].legend()
        axes[1, 1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        # ä¿å­˜åœ–è¡¨
        plot_file = os.path.join(output_dir, 'training_analysis_plots.png')
        plt.savefig(plot_file, dpi=300, bbox_inches='tight')
        logger.info(f"âœ… åˆ†æåœ–è¡¨å·²ä¿å­˜: {plot_file}")
        
        plt.close()
        
    except Exception as e:
        logger.error(f"âŒ å‰µå»ºåœ–è¡¨å¤±æ•—: {e}")

def generate_fix_script(recommendations, output_dir, logger):
    """ç”Ÿæˆä¿®å¾©è…³æœ¬"""
    logger.info("ğŸ”§ ç”Ÿæˆä¿®å¾©è…³æœ¬...")
    
    script_content = """#!/usr/bin/env python3
\"\"\"
ğŸ”§ è‡ªå‹•ä¿®å¾©è…³æœ¬
åŸºæ–¼åˆ†æçµæœç”Ÿæˆçš„ä¿®å¾©å»ºè­°
\"\"\"

import argparse
import os

def apply_fixes():
    \"\"\"æ‡‰ç”¨ä¿®å¾©å»ºè­°\"\"\"
    print("ğŸ”§ é–‹å§‹æ‡‰ç”¨ä¿®å¾©å»ºè­°...")
    
"""
    
    for rec in recommendations:
        if rec['issue'] == 'overfitting':
            script_content += """
    # éæ“¬åˆä¿®å¾©
    print("ğŸ”§ æ‡‰ç”¨éæ“¬åˆä¿®å¾©...")
    # 1. å¢åŠ  Dropout
    dropout_rate = 0.5  # å¾ 0.3 å¢åŠ åˆ° 0.5
    
    # 2. å¢åŠ  Weight Decay
    weight_decay = 5e-4  # å¾ 1e-4 å¢åŠ åˆ° 5e-4
    
    # 3. æ¸›å°‘å­¸ç¿’ç‡
    learning_rate = 0.0008  # å¾ 0.001 æ¸›å°‘åˆ° 0.0008
    
    print(f"  - Dropout ç‡: {dropout_rate}")
    print(f"  - Weight Decay: {weight_decay}")
    print(f"  - å­¸ç¿’ç‡: {learning_rate}")
"""
        
        elif rec['issue'] == 'accuracy_drop':
            script_content += """
    # æº–ç¢ºç‡ä¸‹é™ä¿®å¾©
    print("ğŸ”§ æ‡‰ç”¨æº–ç¢ºç‡ä¸‹é™ä¿®å¾©...")
    # 1. èª¿æ•´åˆ†é¡æå¤±æ¬Šé‡
    cls_weight = 8.0  # é©ä¸­æ¬Šé‡
    
    # 2. ä½¿ç”¨ Focal Loss
    use_focal_loss = True
    
    # 3. å­¸ç¿’ç‡èª¿åº¦
    use_lr_scheduler = True
    
    print(f"  - åˆ†é¡æå¤±æ¬Šé‡: {cls_weight}")
    print(f"  - ä½¿ç”¨ Focal Loss: {use_focal_loss}")
    print(f"  - å­¸ç¿’ç‡èª¿åº¦: {use_lr_scheduler}")
"""
        
        elif rec['issue'] == 'unstable_training':
            script_content += """
    # è¨“ç·´ä¸ç©©å®šä¿®å¾©
    print("ğŸ”§ æ‡‰ç”¨è¨“ç·´ä¸ç©©å®šä¿®å¾©...")
    # 1. é™ä½å­¸ç¿’ç‡
    learning_rate = 0.0005  # é€²ä¸€æ­¥é™ä½
    
    # 2. å¢åŠ æ‰¹æ¬¡å¤§å°
    batch_size = 32  # å¾ 16 å¢åŠ åˆ° 32
    
    # 3. æ¢¯åº¦è£å‰ª
    gradient_clip = 1.0
    
    print(f"  - å­¸ç¿’ç‡: {learning_rate}")
    print(f"  - æ‰¹æ¬¡å¤§å°: {batch_size}")
    print(f"  - æ¢¯åº¦è£å‰ª: {gradient_clip}")
"""
    
    script_content += """
    print("âœ… ä¿®å¾©å»ºè­°å·²ç”Ÿæˆ")
    print("ğŸ“ è«‹æ‰‹å‹•æ›´æ–°è¨“ç·´è…³æœ¬ä¸­çš„ç›¸æ‡‰åƒæ•¸")

if __name__ == "__main__":
    apply_fixes()
"""
    
    # ä¿å­˜è…³æœ¬
    script_file = os.path.join(output_dir, 'apply_fixes.py')
    with open(script_file, 'w', encoding='utf-8') as f:
        f.write(script_content)
    
    logger.info(f"âœ… ä¿®å¾©è…³æœ¬å·²ç”Ÿæˆ: {script_file}")

def generate_report(data, issues, recommendations, output_dir, logger):
    """ç”Ÿæˆè©³ç´°å ±å‘Š"""
    logger.info("ğŸ“ ç”Ÿæˆè©³ç´°å ±å‘Š...")
    
    report_content = f"""# ğŸ”§ è¨“ç·´åˆ†æèˆ‡ä¿®å¾©å ±å‘Š

## ğŸ“Š è¨“ç·´æ¦‚æ³
- **è¨“ç·´è¼ªæ•¸**: {len(data['train_losses'])}
- **æœ€çµ‚è¨“ç·´æå¤±**: {data['train_losses'][-1]:.4f}
- **æœ€çµ‚é©—è­‰æå¤±**: {data['val_losses'][-1]:.4f}
- **æœ€çµ‚é©—è­‰æº–ç¢ºç‡**: {data['val_accuracies'][-1]:.4f}
- **æœ€ä½³é©—è­‰æº–ç¢ºç‡**: {max(data['val_accuracies']):.4f}

## ğŸš¨ æª¢æ¸¬åˆ°çš„å•é¡Œ

"""
    
    if issues:
        for i, issue in enumerate(issues, 1):
            report_content += f"### {i}. {issue['type'].replace('_', ' ').title()}\n"
            report_content += f"- **åš´é‡ç¨‹åº¦**: {issue['severity']}\n"
            if 'count' in issue:
                report_content += f"- **ç™¼ç”Ÿæ¬¡æ•¸**: {issue['count']}\n"
            if 'std' in issue:
                report_content += f"- **æ¨™æº–å·®**: {issue['std']:.4f}\n"
            if 'final_accuracy' in issue:
                report_content += f"- **æœ€çµ‚æº–ç¢ºç‡**: {issue['final_accuracy']:.4f}\n"
            report_content += "\n"
    else:
        report_content += "âœ… æœªæª¢æ¸¬åˆ°åš´é‡å•é¡Œ\n\n"
    
    report_content += "## ğŸ”§ ä¿®å¾©å»ºè­°\n\n"
    
    for i, rec in enumerate(recommendations, 1):
        report_content += f"### {i}. {rec['issue'].replace('_', ' ').title()}\n"
        for solution in rec['solutions']:
            report_content += f"- {solution.replace('_', ' ').title()}\n"
        report_content += "\n"
    
    report_content += f"""
## ğŸ“ˆ æ€§èƒ½çµ±è¨ˆ
- **è¨“ç·´æå¤±ç¯„åœ**: {min(data['train_losses']):.4f} - {max(data['train_losses']):.4f}
- **é©—è­‰æå¤±ç¯„åœ**: {min(data['val_losses']):.4f} - {max(data['val_losses']):.4f}
- **é©—è­‰æº–ç¢ºç‡ç¯„åœ**: {min(data['val_accuracies']):.4f} - {max(data['val_accuracies']):.4f}
- **éæ“¬åˆæª¢æ¸¬æ¬¡æ•¸**: {sum(data['overfitting_flags'])}
- **æº–ç¢ºç‡ä¸‹é™æ¬¡æ•¸**: {sum(data['accuracy_drops'])}

## ğŸ¯ å»ºè­°è¡Œå‹•
1. æŸ¥çœ‹ç”Ÿæˆçš„ä¿®å¾©è…³æœ¬: `apply_fixes.py`
2. æ ¹æ“šå»ºè­°èª¿æ•´è¨“ç·´åƒæ•¸
3. é‡æ–°è¨“ç·´æ¨¡å‹
4. ç›£æ§æ–°çš„è¨“ç·´éç¨‹

---
*å ±å‘Šç”Ÿæˆæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
"""
    
    # ä¿å­˜å ±å‘Š
    report_file = os.path.join(output_dir, 'analysis_and_fix_report.md')
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(report_content)
    
    logger.info(f"âœ… è©³ç´°å ±å‘Šå·²ç”Ÿæˆ: {report_file}")

def main():
    parser = argparse.ArgumentParser(description='è¨“ç·´åˆ†æèˆ‡ä¿®å¾©å·¥å…·')
    parser.add_argument('--history', type=str, required=True, help='è¨“ç·´æ­·å²æ–‡ä»¶è·¯å¾‘')
    parser.add_argument('--output', type=str, default='analysis_output', help='è¼¸å‡ºç›®éŒ„')
    parser.add_argument('--log', type=str, default='training_analysis.log', help='æ—¥èªŒæ–‡ä»¶')
    
    args = parser.parse_args()
    
    # è¨­ç½®æ—¥èªŒ
    logger = setup_logging(args.log)
    logger.info("ğŸš€ é–‹å§‹è¨“ç·´åˆ†æèˆ‡ä¿®å¾©æµç¨‹...")
    
    # å‰µå»ºè¼¸å‡ºç›®éŒ„
    os.makedirs(args.output, exist_ok=True)
    logger.info(f"ğŸ“ è¼¸å‡ºç›®éŒ„: {args.output}")
    
    try:
        # 1. åˆ†æè¨“ç·´æ­·å²
        data = analyze_training_history(args.history, logger)
        if data is None:
            return
        
        # 2. æª¢æ¸¬å•é¡Œ
        issues = detect_issues(data, logger)
        
        # 3. ç”Ÿæˆä¿®å¾©å»ºè­°
        recommendations = generate_fix_recommendations(issues, data, logger)
        
        # 4. å‰µå»ºåœ–è¡¨
        create_analysis_plots(data, args.output, logger)
        
        # 5. ç”Ÿæˆä¿®å¾©è…³æœ¬
        generate_fix_script(recommendations, args.output, logger)
        
        # 6. ç”Ÿæˆå ±å‘Š
        generate_report(data, issues, recommendations, args.output, logger)
        
        logger.info("ğŸ‰ åˆ†æèˆ‡ä¿®å¾©æµç¨‹å®Œæˆ!")
        logger.info(f"ğŸ“ è¼¸å‡ºæ–‡ä»¶:")
        logger.info(f"  - åˆ†æåœ–è¡¨: {args.output}/training_analysis_plots.png")
        logger.info(f"  - ä¿®å¾©è…³æœ¬: {args.output}/apply_fixes.py")
        logger.info(f"  - è©³ç´°å ±å‘Š: {args.output}/analysis_and_fix_report.md")
        logger.info(f"  - æ—¥èªŒæ–‡ä»¶: {args.log}")
        
    except Exception as e:
        logger.error(f"âŒ åˆ†æéç¨‹å‡ºç¾éŒ¯èª¤: {e}")
        raise

if __name__ == "__main__":
    main() 