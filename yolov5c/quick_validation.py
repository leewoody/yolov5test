#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Quick Validation Analysis Script
å¿«é€Ÿåˆ†æè¨“ç·´æ—¥èªŒä¸¦æä¾›é©—è­‰æŒ‡æ¨™å»ºè­°
"""

import re
import json
from pathlib import Path
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from datetime import datetime


class TrainingLogAnalyzer:
    def __init__(self):
        self.epoch_data = []
        self.batch_data = []
        
    def parse_training_log(self, log_text):
        """è§£æè¨“ç·´æ—¥èªŒæ–‡æœ¬"""
        lines = log_text.strip().split('\n')
        
        for line in lines:
            # è§£æEpochè¡Œ
            epoch_match = re.search(r'Epoch (\d+)/(\d+), Batch (\d+)/(\d+), Loss: ([\d.]+) \(Bbox: ([\d.]+), Cls: ([\d.]+)\)', line)
            if epoch_match:
                epoch_num = int(epoch_match.group(1))
                total_epochs = int(epoch_match.group(2))
                batch_num = int(epoch_match.group(3))
                total_batches = int(epoch_match.group(4))
                total_loss = float(epoch_match.group(5))
                bbox_loss = float(epoch_match.group(6))
                cls_loss = float(epoch_match.group(7))
                
                self.batch_data.append({
                    'epoch': epoch_num,
                    'batch': batch_num,
                    'total_batches': total_batches,
                    'total_loss': total_loss,
                    'bbox_loss': bbox_loss,
                    'cls_loss': cls_loss
                })
            
            # è§£æEpochç¸½çµè¡Œ
            epoch_summary_match = re.search(r'Epoch (\d+):\s+Train Loss: ([\d.]+) \(Bbox: ([\d.]+), Cls: ([\d.]+)\)\s+Val Loss: ([\d.]+) \(Bbox: ([\d.]+), Cls: ([\d.]+)\)\s+Val Cls Accuracy: ([\d.]+)\s+Best Val Cls Accuracy: ([\d.]+)', line)
            if not epoch_summary_match:
                # å˜—è©¦æ›´å¯¬é¬†çš„åŒ¹é…æ¨¡å¼
                epoch_summary_match = re.search(r'Epoch (\d+):\s+Train Loss: ([\d.]+).*Val Loss: ([\d.]+).*Val Cls Accuracy: ([\d.]+).*Best Val Cls Accuracy: ([\d.]+)', line)
            if epoch_summary_match:
                epoch_num = int(epoch_summary_match.group(1))
                train_loss = float(epoch_summary_match.group(2))
                
                # æª¢æŸ¥æ˜¯å¦æœ‰è©³ç´°çš„bboxå’Œclsæå¤±ä¿¡æ¯
                if len(epoch_summary_match.groups()) >= 9:
                    train_bbox_loss = float(epoch_summary_match.group(3))
                    train_cls_loss = float(epoch_summary_match.group(4))
                    val_loss = float(epoch_summary_match.group(5))
                    val_bbox_loss = float(epoch_summary_match.group(6))
                    val_cls_loss = float(epoch_summary_match.group(7))
                    val_cls_accuracy = float(epoch_summary_match.group(8))
                    best_val_cls_accuracy = float(epoch_summary_match.group(9))
                else:
                    # ç°¡åŒ–æ¨¡å¼ï¼Œåªæœ‰ä¸»è¦æå¤±å’Œæº–ç¢ºç‡
                    val_loss = float(epoch_summary_match.group(3))
                    val_cls_accuracy = float(epoch_summary_match.group(4))
                    best_val_cls_accuracy = float(epoch_summary_match.group(5))
                    # è¨­ç½®é»˜èªå€¼
                    train_bbox_loss = train_cls_loss = val_bbox_loss = val_cls_loss = 0.0
                
                self.epoch_data.append({
                    'epoch': epoch_num,
                    'train_loss': train_loss,
                    'train_bbox_loss': train_bbox_loss,
                    'train_cls_loss': train_cls_loss,
                    'val_loss': val_loss,
                    'val_bbox_loss': val_bbox_loss,
                    'val_cls_loss': val_cls_loss,
                    'val_cls_accuracy': val_cls_accuracy,
                    'best_val_cls_accuracy': best_val_cls_accuracy
                })
    
    def analyze_training_status(self):
        """åˆ†æè¨“ç·´ç‹€æ…‹"""
        if not self.epoch_data:
            return "ç„¡æ³•è§£æè¨“ç·´æ—¥èªŒæ•¸æ“š"
        
        latest_epoch = self.epoch_data[-1]
        
        analysis = {
            'current_epoch': latest_epoch['epoch'],
            'total_epochs': 40,  # å¾æ—¥èªŒä¸­æ¨æ–·
            'progress': f"{latest_epoch['epoch']}/40 ({latest_epoch['epoch']/40*100:.1f}%)",
            
            # æå¤±åˆ†æ
            'train_loss': latest_epoch['train_loss'],
            'val_loss': latest_epoch['val_loss'],
            'loss_gap': latest_epoch['train_loss'] - latest_epoch['val_loss'],
            
            # åˆ†é¡æº–ç¢ºç‡
            'current_accuracy': latest_epoch['val_cls_accuracy'],
            'best_accuracy': latest_epoch['best_val_cls_accuracy'],
            'accuracy_trend': 'improving' if latest_epoch['val_cls_accuracy'] >= latest_epoch['best_val_cls_accuracy'] else 'declining',
            
            # éæ“¬åˆåˆ†æ
            'overfitting_risk': 'high' if latest_epoch['train_loss'] > latest_epoch['val_loss'] else 'low',
            
            # å»ºè­°
            'recommendations': []
        }
        
        # ç”Ÿæˆå»ºè­°
        if latest_epoch['train_loss'] > latest_epoch['val_loss']:
            analysis['recommendations'].append("âš ï¸ æª¢æ¸¬åˆ°éæ“¬åˆé¢¨éšªï¼šè¨“ç·´æå¤± > é©—è­‰æå¤±")
            analysis['recommendations'].append("å»ºè­°ï¼šæ¸›å°‘è¨“ç·´è¼ªæ•¸æˆ–å¢åŠ æ­£å‰‡åŒ–")
        
        if latest_epoch['val_cls_accuracy'] < latest_epoch['best_val_cls_accuracy']:
            analysis['recommendations'].append("âš ï¸ åˆ†é¡æº–ç¢ºç‡ä¸‹é™ï¼šç•¶å‰ < æœ€ä½³")
            analysis['recommendations'].append("å»ºè­°ï¼šæª¢æŸ¥å­¸ç¿’ç‡æˆ–æ•¸æ“šè³ªé‡")
        
        if latest_epoch['val_cls_accuracy'] < 0.7:
            analysis['recommendations'].append("âš ï¸ åˆ†é¡æº–ç¢ºç‡åä½ (< 70%)")
            analysis['recommendations'].append("å»ºè­°ï¼šå¢åŠ è¨“ç·´æ•¸æ“šæˆ–èª¿æ•´æ¨¡å‹æ¶æ§‹")
        
        if latest_epoch['epoch'] < 20:
            analysis['recommendations'].append("â„¹ï¸ è¨“ç·´è¼ªæ•¸è¼ƒå°‘ï¼Œå»ºè­°ç¹¼çºŒè¨“ç·´")
        
        return analysis
    
    def generate_plots(self, save_dir='runs/analysis'):
        """ç”Ÿæˆåˆ†æåœ–è¡¨"""
        if not self.epoch_data:
            return
        
        save_dir = Path(save_dir)
        save_dir.mkdir(parents=True, exist_ok=True)
        
        epochs = [d['epoch'] for d in self.epoch_data]
        
        # å‰µå»ºå­åœ–
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        
        # 1. æå¤±æ›²ç·š
        train_losses = [d['train_loss'] for d in self.epoch_data]
        val_losses = [d['val_loss'] for d in self.epoch_data]
        
        axes[0, 0].plot(epochs, train_losses, 'b-', label='Train Loss', linewidth=2)
        axes[0, 0].plot(epochs, val_losses, 'r-', label='Val Loss', linewidth=2)
        axes[0, 0].set_title('Training and Validation Loss')
        axes[0, 0].set_xlabel('Epoch')
        axes[0, 0].set_ylabel('Loss')
        axes[0, 0].legend()
        axes[0, 0].grid(True, alpha=0.3)
        
        # 2. åˆ†é¡æº–ç¢ºç‡
        accuracies = [d['val_cls_accuracy'] for d in self.epoch_data]
        best_accuracies = [d['best_val_cls_accuracy'] for d in self.epoch_data]
        
        axes[0, 1].plot(epochs, accuracies, 'g-', label='Current Accuracy', linewidth=2)
        axes[0, 1].plot(epochs, best_accuracies, 'g--', label='Best Accuracy', linewidth=2)
        axes[0, 1].set_title('Classification Accuracy')
        axes[0, 1].set_xlabel('Epoch')
        axes[0, 1].set_ylabel('Accuracy')
        axes[0, 1].legend()
        axes[0, 1].grid(True, alpha=0.3)
        
        # 3. é‚Šç•Œæ¡†å’Œåˆ†é¡æå¤±
        train_bbox_losses = [d['train_bbox_loss'] for d in self.epoch_data]
        train_cls_losses = [d['train_cls_loss'] for d in self.epoch_data]
        
        axes[1, 0].plot(epochs, train_bbox_losses, 'orange', label='Bbox Loss', linewidth=2)
        axes[1, 0].plot(epochs, train_cls_losses, 'purple', label='Cls Loss', linewidth=2)
        axes[1, 0].set_title('Training Loss Components')
        axes[1, 0].set_xlabel('Epoch')
        axes[1, 0].set_ylabel('Loss')
        axes[1, 0].legend()
        axes[1, 0].grid(True, alpha=0.3)
        
        # 4. æå¤±å·®è·ï¼ˆéæ“¬åˆæŒ‡æ¨™ï¼‰
        loss_gaps = [d['train_loss'] - d['val_loss'] for d in self.epoch_data]
        
        axes[1, 1].plot(epochs, loss_gaps, 'red', label='Train-Val Loss Gap', linewidth=2)
        axes[1, 1].axhline(y=0, color='black', linestyle='--', alpha=0.5)
        axes[1, 1].set_title('Overfitting Indicator (Train-Val Loss Gap)')
        axes[1, 1].set_xlabel('Epoch')
        axes[1, 1].set_ylabel('Loss Gap')
        axes[1, 1].legend()
        axes[1, 1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(save_dir / 'training_analysis.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"ğŸ“Š åˆ†æåœ–è¡¨å·²ä¿å­˜åˆ°: {save_dir / 'training_analysis.png'}")
    
    def generate_report(self, save_dir='runs/analysis'):
        """ç”Ÿæˆåˆ†æå ±å‘Š"""
        analysis = self.analyze_training_status()
        
        if isinstance(analysis, str):
            print(f"âŒ {analysis}")
            return
        
        save_dir = Path(save_dir)
        save_dir.mkdir(parents=True, exist_ok=True)
        
        report = f"""
# ğŸ“Š è¨“ç·´ç‹€æ…‹åˆ†æå ±å‘Š

## ğŸ¯ ç•¶å‰ç‹€æ…‹
- **è¨“ç·´é€²åº¦**: {analysis['progress']}
- **ç•¶å‰Epoch**: {analysis['current_epoch']}/40

## ğŸ“ˆ æ€§èƒ½æŒ‡æ¨™

### æå¤±å‡½æ•¸
- **è¨“ç·´æå¤±**: {analysis['train_loss']:.4f}
- **é©—è­‰æå¤±**: {analysis['val_loss']:.4f}
- **æå¤±å·®è·**: {analysis['loss_gap']:.4f} ({'éæ“¬åˆé¢¨éšª' if analysis['loss_gap'] > 0 else 'æ­£å¸¸'})

### åˆ†é¡æ€§èƒ½
- **ç•¶å‰æº–ç¢ºç‡**: {analysis['current_accuracy']:.4f} ({analysis['current_accuracy']*100:.1f}%)
- **æœ€ä½³æº–ç¢ºç‡**: {analysis['best_accuracy']:.4f} ({analysis['best_accuracy']*100:.1f}%)
- **æº–ç¢ºç‡è¶¨å‹¢**: {analysis['accuracy_trend']}

### é¢¨éšªè©•ä¼°
- **éæ“¬åˆé¢¨éšª**: {analysis['overfitting_risk']}

## ğŸ¯ å»ºè­°

"""
        
        for rec in analysis['recommendations']:
            report += f"{rec}\n"
        
        report += f"""
## ğŸ“Š è©³ç´°æ•¸æ“š

### Epochæ­·å²è¨˜éŒ„
"""
        
        # æ·»åŠ è©³ç´°çš„epochæ•¸æ“š
        for epoch_data in self.epoch_data:
            report += f"""
**Epoch {epoch_data['epoch']}**:
- è¨“ç·´æå¤±: {epoch_data['train_loss']:.4f} (Bbox: {epoch_data['train_bbox_loss']:.4f}, Cls: {epoch_data['train_cls_loss']:.4f})
- é©—è­‰æå¤±: {epoch_data['val_loss']:.4f} (Bbox: {epoch_data['val_bbox_loss']:.4f}, Cls: {epoch_data['val_cls_loss']:.4f})
- åˆ†é¡æº–ç¢ºç‡: {epoch_data['val_cls_accuracy']:.4f} (æœ€ä½³: {epoch_data['best_val_cls_accuracy']:.4f})
"""
        
        report += f"""
---
*å ±å‘Šç”Ÿæˆæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
"""
        
        # ä¿å­˜å ±å‘Š
        with open(save_dir / 'training_analysis_report.md', 'w', encoding='utf-8') as f:
            f.write(report)
        
        # ä¿å­˜JSONæ•¸æ“š
        with open(save_dir / 'training_data.json', 'w') as f:
            json.dump({
                'epoch_data': self.epoch_data,
                'batch_data': self.batch_data,
                'analysis': analysis
            }, f, indent=2)
        
        print(f"ğŸ“„ åˆ†æå ±å‘Šå·²ä¿å­˜åˆ°: {save_dir / 'training_analysis_report.md'}")
        print(f"ğŸ“Š æ•¸æ“šæ–‡ä»¶å·²ä¿å­˜åˆ°: {save_dir / 'training_data.json'}")


def analyze_log_from_text(log_text):
    """å¾æ–‡æœ¬åˆ†æè¨“ç·´æ—¥èªŒ"""
    analyzer = TrainingLogAnalyzer()
    analyzer.parse_training_log(log_text)
    
    # ç”Ÿæˆåˆ†æ
    analysis = analyzer.analyze_training_status()
    
    # ç”Ÿæˆåœ–è¡¨å’Œå ±å‘Š
    analyzer.generate_plots()
    analyzer.generate_report()
    
    return analysis


if __name__ == "__main__":
    # ç¤ºä¾‹ä½¿ç”¨
    sample_log = """
Epoch 23/40, Batch 0/83, Loss: 3.1771 (Bbox: 0.0026, Cls: 0.3968)
Epoch 23/40, Batch 20/83, Loss: 1.2542 (Bbox: 0.0036, Cls: 0.1563)
Epoch 23/40, Batch 40/83, Loss: 2.5399 (Bbox: 0.0033, Cls: 0.3171)
Epoch 23/40, Batch 60/83, Loss: 1.6488 (Bbox: 0.0037, Cls: 0.2056)
Epoch 23/40, Batch 80/83, Loss: 1.0560 (Bbox: 0.0029, Cls: 0.1316)
Epoch 23:
  Train Loss: 2.0978 (Bbox: 0.0029, Cls: 0.2619)
  Val Loss: 1.5627 (Bbox: 0.0030, Cls: 0.1950)
  Val Cls Accuracy: 0.6490
  Best Val Cls Accuracy: 0.8125
"""
    
    analysis = analyze_log_from_text(sample_log)
    print("âœ… åˆ†æå®Œæˆï¼") 